---
title: 'Grundlagen der Wirtschaftsinformatik'
author: "Author: Nguyen Minh Kien, Editor: Truong Hoang Tung"
output:
    pdf_document:
        number_sections: true
---
<style>body {
text-align:justify
}
</style>

\tableofcontents
\pagebreak

# Teil 1: Die Rolle von Informations und Kommunikationssystemen in Unternehmen

## Kapitel 1: Information, Kommunikation, Modell und System

Das erste Kapitel definiert grundlegende Begriffe, darunter Daten, Information und System. Es werden auch verschiedene Ansätze vorgestellt, mit denen man den Wert von Informationen ermitteln kann.

### Bedeutung von informationssystemen in organisationen

Gegenstand der **Wirtschaftsinformatik** sind *Informationssysteme* (IS) in Wirtschaft, Verwaltung und dem privaten Bereich.

IS sind algegenwärtig. Nicht nur in Unternehmen haben sie einen Einfluss auf die Organisation, auf Gruppen und Individuen. Auch privat kommt jeder Mensch direkt oder indirekt mit IS in Berührung.

Zur Beschreibung dieser Entwicklung hin zu immer stärker daten- bzw. informationsgetriebenen Strukturen sowie der integralen Rolle von IT für neue Geschäftsmodelle hat sich (neben seiner ursprünglichen Bedeutung als Umwandlung analoger Signale) der Begriff der Digitalisierung im Sinne einer gesellschaftlichen Transformation etabliert.

IS können zur Verbesserung des Leistungsangebots genutzt werden und zu großen Ersparnissen führen. Die Ausnutzung der Potenziale von IT ist keineswegs einfach. Die Komplexität der Aufgaben wird offenbar oft falsch eingeschätzt, was zu großen Zeitverzögerungen und Kostenüberschreitungen führen kann. Nicht nur die Entwicklung neuer Software, sondern auch die einführung und Anpassung bereits vielfach eingesetzter Standardsoftware kann misslingen. Für private Organisationen können Probleme mit IS existenzbedrohend sein.

### Informationen und Wissen

**Information** ist zusätzliches zweckorientiertes Wissen.

**Daten** stellen die physische Darstellung von Informationen dar.

*Beispiel zur Unterscheidung zwischen Daten und Information*: Die Wettervorhersage für den kommenden Sommer in Kanada stellt für die meisten Europäer Daten, aber keine Informationen dar. Wenn aber der Empfänger dieser Vorhersage ein Kapitalanleger, der mit Terminkontrakten für Weizen handelt, oder jemand ist, der seinen nächsten Sommerurlaub in Kanada verbringen möchte, ist das eine wichtige Information, für die sie vielleicht viel oder wenig zahlen würden. Ob und wie viel jemand für diese Information zahlen würde, hängt auch davon ab, für wie zuverlässig er die Information hält.

**Nachrichten** sind übermittelte Daten, unabhängig davon, ob sie durch Personen oder über Leitungen übermittelt werden.

**Kommunikation** ist Austausch von Nachrichten.

Die obige Definition von Information ist nicht leicht quantifizierbar. Deshalb (Shannon und Weaver 1949) sehen **Information als Mittel zur Reduktion von Unsicherheit** und messen dieses Reduktionspotenzial mit der **Entropiefunktion**, hier mit H bezeichnet:

\centerline{\includegraphics[width=0.8\textwidth]{img/Entropie.png}}

wobei $p_i$ die Wahrscheinlichkeit eines Ereignisses ist. Je höher der Wert von H ist, desto größer sind die Unsicherheit und damit die Möglichkeit, mithilfe von Informationen die Unsicherheit zu reduzieren. Wenn keine Unsicherheit besteht, also ein Ereignis mit Sicherheit von $p_i$ = 1 auftritt, dann ist H = 0 bzw. zusätzliche Informationen haben keinen Wert.

*Beispiele für Entropie bei fairen und unfairen Münzwurf:*

\centerline{\includegraphics[width=0.8\textwidth]{img/Bsp_fairer_Munzwurf.png}}
\centerline{\includegraphics[width=0.8\textwidth]{img/Bsp_unfairer_Munzwurf.png}}

Eine Information kann viele Eigenschaften haben, die ihren Wert beeinflussen. **Aktualität** bezieht sich auf die Frage, wie weit in der Zeit der Zustand zurückliegt, auf den sich die Information bezieht. **Korrektheit** bezieht sich auf den Wahrheitsgehalt der Information. **Genauigkeit** bezieht sich auf die Präzision der Information. Der **Aggregationsgrad** von Informationen sagt etwas über die Bezugsobjekte oder -ereignisse aus. Die **Präsentation** einer Information ist ebenso wichtig, da die volle Ausschöpfung des Informationswerts davon abhängt, dass der Empfänger die Information vollständig aufnimmt. Die **Kosten** einer Information sind insbesondere bei ex ante (von Anfang an) Betrachtungen wichtig, wenn über die Beschaffung der Information entschieden werden muss.

*Folgend sind einige Informationsattribute und ihre möglichen Ausprägungen dargestellt.*

\centerline{\includegraphics[width=0.94\textwidth]{img/Informationsattribute.png}}

### Problemlösungsprozess

Generell werden Informationen benötigt, um eine Entscheidung zu treffen oder eine Kontrolle vorzunehmen. Informationen sind als Rohstoff für Entscheidungs- und Kontrollprozesse zu betrachten.

\centerline{\includegraphics[width=0.4\textwidth]{img/problophasen.png}}
\centerline{\includegraphics[width=0.6\textwidth]{img/dimensionentscheiden.png}}

Wenn eine Entscheidungsträger hinsichtlich eines Problems zu jeder der Phasen ein geeignetes Vorgehen kennt, ist das Problem für ihn **wohlstrukturiert**. Im anderen Extremfall, wenn zu keiner der Phasen ein geeignetes Vorgehen bekannt ist, wird das Problem als **unstrukturiert** bezeichnet. Dazwischen sind die **semistrukturiertem** Probleme. Hier sind Lösungsansätze zwar für einige der Phasen, aber nicht für alle Phasen bekannt.

In der Entscheidungstheorie wird zwischen Entscheidungen unter **Sicherheit** und unter **Unsicherheit** unterschieden. Im ersten Fall liegen sämtliche Prognosedaten über die Entscheidungskonsequenzen der zu beurteilenden Alternativen in einwertiger Form vor. Bei Entscheidungen unter Unsicherheit werden die Konsequenzen mehrwertig notiert. Mehrwertigkeit liegt z.B. dann vor, wenn Vorhersagen für verschiedene Szenarien getroffen werden.

Die Persönlichkeit des Entscheidungsträgers drückt sich auch in seiner Risikoeinstellung aus. Diese kann aufgrund des **Nutzenerwartungswerts** bei einem zufallsbedingten Ereignis bestimmt werden:

\centerline{\includegraphics[width=0.8\textwidth]{img/nutzerwert.png}}

wobei $p_i$ die Eintrittswahrscheinlichkeit des Ereignisses $x_i$ ist und $N(x_i)$ der Nutzen, den der Entscheidungsträger dem Eintreten des Ereignisses $x_i$ beimisst. Der Nutzenerwartungswert kann mit einem sicheren Wert verglichen werden, dem sog. *Sicherheitsäquivalent*, den der Entscheider auswählt bzw. bei einem Glücksspiel als Spieleinsatz akzeptiert. Wenn die beiden Werte gleich sind, dann wird der Entscheider als **risikoneutral** bezeichnet. Wenn sich der Entscheider für ein ihm angbotenes Sicherheitsäquivalent entscheidet, das kleiner als der Nutzenerwartungswert ist, dann ist der Entscheider **risikoscheu**; wenn er sich für den höheren Nutzenerwartungswert entscheidet, ist er **risikofreudig**. Im letzteren Fall zieht er die Chance auf den Erhalt eines größeren Nutzens einem sicheren, kleineren Nutzen vor.

### Wert von Informationen
1. **Subjektiver Ansatz**:

Man befragt den Informationsbenutzer, wie viel ihm die Information wert ist. Dieser Ansatz wird insbesondere dann gewählt, wenn es sich um unstrukturierte Probleme unter Unsicherheit handelt. Seine Stärke, die nachfragebezogene Wertbestimmung, ist gleichzeitig auch seine Schwäche, nämlich die mangelnde Nachprüfbarkeit der Korrektheit. Es ist möglich, den Grad der Subjektivität zu verringern, indem mehrere Benutzer in einer Organisation befragt und die Antworten in geeigneter Weise zusammengefasst werden.

2. **Objecktiver Ansatz**:

Ein objecktiver Ansatz ist die Ermittlung des beobachtbaren Werts von Informationen. Dabei wird das Ergebnis eines Entscheidungsprozesses mit und ohne eine bestimmte Information betrachtet. Die Ergebnisdifferenz entspricht dem Informationswert, wenn man all anderen Einfüsse konstant halten kann (in dieser Bedingung verbirgt sich die Schwierigkeit des Ansatzes). Der Vorteil besteht darin, dass er die tatsächlich erreichten Ergebnisse berücksichtigt und damit die Fähigkeiten und Zielerreichungsbedürfnisse der Entscheidungsträger. Ein Nachteil ist, dass der Wert nur ex post ermittelt werden kann, wenn man die Information schon erworben hat. Die Wertermittlung kann jedoch auch für diesen Fall sinnvoll sein, um für den Wiederholungsfall zu lernen.

3. **Normativer Ansatz**:

Ein normativer Ansatz, der auch ex ante angewendet werden kann, ist die Bestimmung des normativen Werts der Information. Hier wird der Informationswert durch die Differenz des erwarteten Gewinns mit der betreffenden Information und dem erwarteten Gewinn ohne die Information gemessen. Der Nachteil dieses Verfahrens ist, dass die Güte der Information nicht leicht bestimmbar und nachprüfbar ist.

\begin{figure}
\centerline{\includegraphics[width=1\textwidth]{img/Nansatz1.png}}
\centerline{\includegraphics[width=1\textwidth]{img/Nansatz2.png}}
\end{figure}
\begin{figure}
\centerline{\includegraphics[width=1\textwidth]{img/Nansatz3.png}}
\centerline{\includegraphics[width=1\textwidth]{img/Nansatz4.png}}
\end{figure}

In der Praxis wird der Wert einer Information oft nicht im Kontext von "mit" oder "ohne" Information ermittelt, sondern es werden Informationen mit unterschiedlichen Ausprägungen eines oder mehrerer Attribute betrachtet, um eine zufriedenstellende Konstellation auszuwählen.

Abschließend ist festzuhalten, dass das Ergebnis eines Entscheidungsprozesses, in den Informationen eingeflossen sind, wiederum eine Information darstellt.

### System

Ein **System** besteht aus einer Menge von miteinander verknüpften Elementen, die sich insgesamt von ihrer Umgebung abgrenzen lassen.
\centerline{\includegraphics[width=1\textwidth]{img/systemdefi.png}}

Diese Grafik enthält zusätzlich Eingaben und Ausgaben, die das System mit der Umwelt austauscht. Diese sind in der Definition nicht enthalten, weil es geschlossene Systeme gibt, die mit ihrer Umwelt nichts austauschen.

Die Ermittlung der Grenzen eines Systems und der Beziehungen zwischen seinen Elementen können schwierig sein. Wenn man an den Elementen und ihren Beziehungen nicht interessiert ist, sondern nur an der Verwendung eines Systems, dann bezeichnet man das System als eine "Blackbox". Es reicht oft aus zu Wissen, welche Inputs zu welchen Outputs führen, um ein System zu nutzen. Ein Element eines Systems kann ebenfalls ein System sein (Subsystem).

\centerline{\includegraphics[width=0.8\textwidth]{img/systemcl.png}}

Ein System, dessen Verhalten exakt vorraussagbar ist, wird als **deterministisch** bezeichnet. Wenn das Verhalten (nur) einer Komponente eines Systems einer Wahrscheinlichkeitsverteilung folgt (z.B. bezüglich ihres Ausfalls), so ist das gesamte System **stochastisch**. Wenn ein Beobachter nicht einmal Wahrscheinlichkeiten für das Verhalten eines Systems kennt, verhält sich das System für ihn **zufällig**.

In vielen Organisationen werden die realisierten Ergebnisse regelmäßig mit angestrebten Zielen verglichen. Wenn die Übereinstimmung als nicht zufriedenstellend angesehen wird, werden die Systemeingaben und/oder das interne Systemverhalten geändert. Man spricht hier von **Rückkopplung**.

### Modell

Ein **Modell** ist das Ergebnis eines Konstruktionsprozesses, das die Wahrnehmung von Inhalten eines ausgewählten Gegenstands zweckorientiert repräsentiert. In Modellen werden die für nicht relevant angesehenen Eigenschaften eines Systems weggelassen. Mit einem Modell kan somit einfacher experimentiert werden, um das zu analysierende System bzw. das Original besser verstehen bzw. steuern zu können, ohne dieses selbst zu beeinflussen. Die Qualität des Modells ist daran zu beurteilen, inwiefern die Repräsentation geeignet ist, die Zwecke des Modellnutzers zu erfüllen.

\centerline{\includegraphics[width=0.8\textwidth, trim={0 0 0 60pt},clip]{img/modellcl.png}}

Der Zweck eines Modells kann sein, ein System zu beschreiben (**deskriptiv**) oder Handlungen zu empfehlen (**normativ**). Wenn das Modell Größen beinhaltet, die sich auf mehr als einen Zeitpunkt beziehen, wird von einem **dynamischen** (also **mehrperiodigen**) Modell gesprochen. In **statischen** (**einperiodigen**) Modellen beziehen sich alle Variablen auf den gleichen Zeitpunkt bzw. Zeitraum.

### Modelle von Unternehmungen

Aus der Sicht der Systemtheorie enthalten Organisationen i.d.R. maschinelle und natürliche Komponenten und sind meistens offene, adaptive Systeme mit Rückkopplung. Da eine Organisation viele Komponenten enthält, ist zwecks Erreichung der Organisationsziele eine Koordination dieser Komponenten notwendig. Diese Koordination wird durch eine Aufbausorganisation, die Aufgaben, Aufgabenträger und ihre formalen Beziehungen untereinander festgelegt, und durch eine Ablauforganisation, die Arbeitsabläufe bestimmt, unterstützt.

In vielen Organisationen herrscht hierarchische Koordination mit einer oder mehreren Leitungsebenen vor. Die Leitungs- oder Managementfunktionen werden oft in drei Ebenen unterteilt. Die Manager einer Ebene haben Mitarbeiterverantwortung für die unteren Ebenen. In der näschten Abbildung sind die Leitungsebenen um die Ausführungebenen ergänzt, damit die gesamte Unternehmung in dem Modell repräsentiert wird. Die Linien die die Pyramide vertikal unterteilen, trennen die verschiedenen funktionalen Bereiche, wie etwa Beschaffung, Produktion oder Vertrieb, voneinander ab.

\centerline{\includegraphics[width=0.7\textwidth]{img/orgaeben.png}}

Die unterschiedlichen Aufgaben der Manager auf den drei Ebenen führen zu unterschiedlichen Informationsbedürfnissen. Diese werden in der nächsten Tabelle dargestellt. Dabei sind die Einträge so zu interpretieren, dass z.B. bezüglich der Herkunft der Informationen die operative Ebene vorwiegend interne Informationen benötigt, die strategische Ebene vorwiegend externe Informationen und die taktische Ebene dazwischen liegt.

\centerline{\includegraphics[width=1\textwidth]{img/infobedarf.png}}

Heute wird versucht, "flache" Organisationen mit möglichst wenig Personal, das nur überwacht und informiert, zu entwickeln. Die Entwicklung solcher Organisationen unterstützen IS erheblich. Die vorher genannten planerischen Aufgaben existieren trotz Verflachung der Organisation weiter.

Das Handeln einer Unternehmung beeinflussen nicht nur ihre Mitarbeiter und ihre direkten Geschäftspartner, sondern eine Vielzahl an Interessengruppen. Diese Gruppen werden gleichzeitig durch das Handeln der Unternehmung beeinflusst. Das gezeigte Modell einer Unternehmung als Führungssicht versucht, die Komplexität ihrer Beziehungen durch sechs Grundkategorien einzufangen:

\centerline{\includegraphics[width=1\textwidth]{img/manamodell.png}}

1. *Umweltsphären* (Gesellschaft, Natur, Technologie, Wirtschaft) sind Rahmenbedingungen, die ständig auf Veränderungen beobachtet werden sollten und teilweise beeinflusst werden können.
2. *Anspruchsgruppen* (Kapitalgeber, Kunden, Mitarbeitende, usw.) stehen in beabsichtigten Austauschprozessen mit der Unternehmung oder werden von ihren Handlungen mehr oder weniger zufällig betroffen (z.B durch Umweltbelastung oder Sponsoring).
3. *Interaktionsthemen* (Ressourcen, Normen und Werte, Anliegen und Interessen) repräsentieren den Austausch zwischen der Unternehmung und den Anspruchsgruppen, der materieller (Güter) oder immaterieller (z.B. Rechte, Anliegen oder Normen) Art sein kann.
4. *Ordnungsmomente* (Strategie, Strukturen, Kultur) stellen das interne Rahmenwerk der Unternehmung dar, indem sie Ziele und formale/informale Kommunikationsstrukturen bestimmen.
5. *Prozesse* bilden die sachlichen und zeitlichen Bedingungen und Abfolgen der Leistungserbringung ab.
6. *Entwicklungsmodi* (schattierte Seitenfläche des Polyeders) zeigen Möglichkeiten der Weiterentwicklung auf, die aus der Verbesserung bestehender Prozesse (Optimierung) oder aus der Transformation unter Ausnutzung von Innovationen (Erneuerung) bestehen.

## Kapitel 2: Informationssysteme

Dieses Kapitel definiert zuerst auf Basis der im vorherigen Kapitel eingeführten Begriffe den Begriff Informationssystem und betrachtet danach die Evolution des Einsatzes von Informationssystemen in Unternehmen. Der Besprechung alternativer Möglichkeiten zur Gruppierung von Informationssystemen folgt die Erklärung ihrer einzelnen Arten. Das Kapitel wird durch die Betrachtung der Wechselwirkungen zwischen Organisationsformen und Informationstechnologie abgeschlossen.

### Definition von IS

Ein **Informationssystem** ist ein künstliches, konkretes System, das aus
maschinellen und menschlichen Elementen besteht und seine Nutzer
mit Informationen versorgt. Es ist gleichzeitig ein Modell und ein
Element einer Organisation oder verbundener Organisationen.

\centerline{\includegraphics[width=1\textwidth]{img/ISbegriff.png}}

### Evolution der IS

Effektivität kann auch umgeschrieben werden als "das Richtige zu tun", während es bei Effizienz darum geht, dass man das, was man tut, "richtige tut".

\centerline{\includegraphics[width=1\textwidth]{img/ISEvolution.png}}

### Arten von IS

\centerline{\includegraphics[width=1\textwidth, trim={0 0 0 120pt},clip]{img/ISklassan.png}}

\pagebreak
Eine Möglichkeit, IS zu klassifizieren, besteht in der Verwendung der Kriterien **Anwendungsbreite** und **Sektorspezifität**. *Individualsoftware* erstellt die Unternehmung selbst oder gibt deren Entwicklung speziell in Auftrag. *Standardsoftware* wird für viele Anwender(Organisationen) entwickelt. *Sektorspezifisch*: z.B. im industriellen Sektor die Branchen Elektrotechnik, Maschinenbau, Chemie und Nachrichtentechnik. *Sektorneutral*: z.B. Handel, Industrie, Banken/Versicherungen, Dienstleistungen allgemein.

\centerline{\includegraphics[width=1\textwidth]{img/ISArten.png}}

Jetzt werden die folgenden Kriterien zur klassifizierung von IS benutzt: **die durch das IS unterstützte Organisationsebene** mit den Ausprägungen Ausführungebene & Leitungsebene, und der generelle **Zweck der Datenverarbeitung** mit den Ausprägungen Transaktion, Information & Entscheidung.

1. **System of Record**

**Transaktionssysteme (Transaction Processing Systems, TPS)** unterstützen die Bearbeitung wiederkehrender Geschäftsvorgänge. Die Systeme helfen den Mitarbeitern auf der Ausführungebene effizienter zu arbeiten. Manchmal ermöglichen sie Transaktionen ohne weitere manuelle Eingriffe. Die Behandlung der Geschäftsvorgänge ist standardisiert. TPS wird auch zur Überprüfung der Korrektheiten von Prozessabläufen genutzt.

TPS wurden als erste IS eingesetzt; sie bilden oft die Basis für andere IS, indem sie die Datengrundlage für sie schaffen.

Beispiele: Enterprise Resource Planning (Programme, die verschiedene betriebwirtschaftliche Funktionen in einem integrierten Softwareprodukt unterstützen), Bankautomaten, Reservierungssysteme.

2. **System of Insight**

\centerline{\includegraphics[width=1\textwidth, trim={0 0 0 120pt},clip]{img/sysinsight.png}}

Für die operative und taktische Managementebene eignen sich die **Managementinformationssysteme (MIS)**, die Managern die Beobachtung des Ablaufs des Unternehmensprozesse, den Vergleich mit Planzahlen sowie die kurzfristige Geschäftsplanung erleichtern.

MIS können die Phase der Problemfindung dienen. Die Generierung und Bewertung von Alternativen müssen menschliche Entscheider allein durchführen. Die ersten für diese Phase entwickelten Systeme, werden als **Entscheidungsunterstützumgssysteme (Decision Support Systems, DSS)** bezeichnet. Sie stellen dem Menschen Daten, Methoden und Modelle zum Problemlösen über eine benutzerfreundliche Schnittstelle zur Verfügung.

**Künstliche Intelligenz** ist ein Gebiet der Informatik zur Entwicklung von Verfahren, mit denen das menschliche Problemlösungsverhalten nachgeahmt wird. Manchen Verfahren der KI versuchen, neue Lösungsansätze oder Zusammenhänge in Datenbanken zu entdecken, weswegen sie als Wissensentdeckungssysteme gelten. Dieser Forschungsbereich wird auch als **Knowledge Discovery in Database** bezeichnet. Es werden dazu z.B. künstliche, neuronale Netze (Artificial Neural Networks, ANN) gerechnet.

\centerline{\includegraphics[width=0.7\textwidth, trim={0 0 0 100pt},clip]{img/KI.png}}

Ein **künstliches, neuronales Netzwerk** besteht aus mehreren verbundenen Ebenen von Verarbeitungselementen, die in Analogie zur Informationsverarbeitung im menschlichen Gehirn als Neuronen bezeichnet werden. Die erste Ebene wird als Eingabe- und die letzte als Ausgabeebene bezeichnet. Dazwischen gibt es eine oder mehrere "versteckte" Zwischenebenen. Ein Neuron erhält numerische Eingaben, gewichtet, summiert sie, transformiert die Summe und gibt den transformierten Wert aus, entweder an Neuronen der nächsten Ebene oder als Endausgabe. Ein neuronales Netz kann lernen, indem es die verwendeten Gewichte so lange verändert, bis die gewünschte Güte des ANN erreicht ist. Die Güte kann z.B. danach beurteilt werden, wie stark die Ergebnisse der Berechnungen historischer Fälle mit bekannten Ergebnissen übereinstimmen. ANN werden zur Erkennung von Mustern und zur Klassifikation von Daten eingesetzt.

\centerline{\includegraphics[width=1\textwidth]{img/neuron.png}}
\centerline{\includegraphics[width=1\textwidth]{img/CNN.png}}

Der Prozess des **Data Mining** wird in einzelnen Phasen aufgeteilt : *Auswahl* der Daten aus geeigneten Datenquellen, *Exploration* der Daten mit den Methoden der Datenanalyse, *Stichprobenziehung* aus ausgewählten Datensätzen, *Vorverarbeitung* der Daten inklusive einer eventuellen Bereinigung der Datenn (Data Cleansing), sowie eine *Transformation* der Daten in die von DM-Algorithmen benötigte Form. Nach Schätzung von Experten werden ca. 80% der Zeit und Kosten des DM für diese Vorarbeiten aufgewandt. Die letzte Phase, die *Wissensgewinnung* schließlich identifiziert Datenmuster.

\centerline{\includegraphics[width=0.5\textwidth]{img/DMprozess.png}}

Verfahren des **Data Mining**:

 - Zur *Klassifikation* sind *Entscheidungsbäume* einsetzbar: Die Verbindungen von der Baumwurzel bis zu einem Endknoten (Blattknoten) stellen eine Regel dar, die aus "und"-verknüpften Bedingungen besteht.
 - Die *Abweichunganalyse* beschäftigt sich mit Objekten, die sich keinem Datenmuster eindeutig zuordnen lassen.
 - Die Verfahren der *Assoziationanalyse* suchen nach signifikanten Abhängigkeiten zwischen einzelnen Attributen der Analyseobjekte und bewerten diese mit Häufigkeiten.
 - Das Ziel der *Reihenfolgeanalyse* ist es, einzelne Phasen und die zeitlichen Distanzen zwischen wiederkehrenden Ereignissen zu entdecken.
 - Die *Analyse ähnlicher Zeitabfolgen* sucht Zeitabfolgen mit ähnlichem Muster, z.B: Suche alle Aktien, deren Kurs sich in 2015 ähnlich wie der Kurs von ABC bewegt haben.
\pagebreak

**Sprachverarbeitung**

\centerline{\includegraphics[width=1\textwidth]{img/sprachver.png}}

**Text Mining**  ist ein Bündel von Algorithmus-basierten Analyseverfahren zur Entdeckung von Bedeutungsstrukturen aus un- oder schwachstrukturierten Textdaten. Mit statistischen und linguistischen Mitteln erschließt Text-Mining-Software aus Texten Strukturen, die die Benutzer in die Lage versetzen sollen, Kerninformationen der verarbeiteten Texte schnell zu erkennen. Im Optimalfall liefern Text-Mining-Systeme Informationen, von denen die Benutzer zuvor nicht wissen, ob und dass sie in den verarbeiteten Texten enthalten sind. Bei zielgerichteter Anwendung sind Werkzeuge des Text Mining außerdem in der Lage, Hypothesen zu generieren, diese zu überprüfen und schrittweise zu verfeinern.

**Visual Analytics**  ist ein interdisziplinärer Ansatz, der die Vorteile aus unterschiedlichen Forschungsgebieten verbindet. Das Ziel der Visual-Analytics-Methode ist, Erkenntnisse aus extrem großen und komplexen Datensätzen zu gewinnen. Der Ansatz kombiniert die Stärken der automatischen Datenanalyse mit den Fähigkeiten des Menschen, schnell Muster oder Trends visuell zu erfassen. Durch geeignete Interaktionsmechanismen können Daten visuell exploriert und Erkenntnisse gewonnen werden.

3. **System of Engagement**

Beispiele: Verknüpfung von Laufschuhen mit Smartphone App. Verknüpfung von Hotelzimmerbuchung mit einem Check-In vor Ort ohne Hotelpersonal (Code-Generierung für Zugang zum Hotelzimmer).

### Wechselwirkungen zwischen Organisationen und IS
Die Einführung von IS führt zu starken Veränderungen in der betroffenen Organisation und, je nach System, auch in den Beziehungen der Organisation zu ihrer Außenwelt.

Nach der **Theorie des "technologischen Imperativs"** determinieren Informationstechnologien Organisationsstrukturen. So wird bestimmten Hardwaretechnologien ein zwangsläufiger Einfluss auf die De- oder Zentralisierung in Unternehmungen zugesprochen. Bsp: Großrechner unterstützen eine zentrale Organisation, während Client-server-Architekturen führen zu dezentralen Strukturen.

Die **Theorie des "organisatorischen Imperativs"** nimmt hingegen an, dass Organisationen eine vollständige Kontrolle über die Auswahl und den Einsatz von IT besitzen.

Der Zusammenhang zwischen Technologieänderungen und Veränderungen einer Organisation kann wie folgend dargestellt werden.

\centerline{\includegraphics[width=1\textwidth]{img/ITunterbe.png}}

Manche Veränderungen betreffen nur die Ebene der IT, andere durchdringen alle Unternehmungsebenen. Das beginnt bei der Strategie, die festlegt, *was* zu tun ist, und setzt sich auf Organisationsebene fort, die Geschäftsprozesse bestimmt und vorgibt, *wie* etwas erfolgen soll. Daraus ergeben sich die fachlichen Anforderungen für die Gestaltung der benötigten IS, die mithilfe der vorhandenen IT umgesetzt werden. Die letzte Ebene beantwortet also die Frage nach dem *womit*. Die IT ist aber nicht nur Umsetzungsinstrument, sondern die Innovationen der IT eröffnen auch fachliche Möglichkeiten zur Entwicklung neuer Geschäftsmodelle und daraus abgeleiteter Strategien und Geschäftsprozesse (IT als Enabler).

**Phasen von Organisationsveränderungen**
In der ersten Phase ist die Atmosphäre für Veränderung herzustellen, d.h. Menschen müssen für die Aufgabe des momentanen Zustands gewonnen werden (**Auftauphase**). Erst wenn diese Bereitschaft geschaffen oder, im ungünstigen Fall, erzwungen worden ist, sollte die Veränderung auch durchgeführt werden (**Durchführungsphase**). In der letzten Phase geht es darum, den neuen Zustand für eine bestimmte Zeit ohne Veränderungen beizubehalten (**Einfrierphase**), damit sich die Menschen an ihn anpassen können und dabei die Angst vor der Neuigkeit verlieren.

\pagebreak

##  Kapitel 3: Planung und Steuerung des Einsatzes von IS

Dieses Kapitel führt in die Aufgaben ein, die sich für die Leitung eines Unternehmens aus der Nutzung der Informationstechnologie ergeben. Dazu gehören vereinfacht Planung, Umsetzung und Überwachung. Überwachung schließt die ökonomische Bewertung des Einsatzes von Informationstechnologie ein.

### Informationsmanagement

**Informationsmanagement** (IM) umfasst die Aufgaben der Planung, Überwachung und Steuerung der Informationsinfrastruktur als Ganzes (strategische Ebene) und der einzelnen Komponenten dieser Infrastruktur (administrative Ebene) sowie der Nutzung dieser Infrastruktur (operative Ebene).

**Aufgaben des IM nach den drei Sichten auf das IM:**

* unternehmerische Sicht: prinzipielle Lösung geschäftlicher Fragestellungen mithilfe der IT. Die unternehmerische Sicht erfordert ein "informationsbewusstes" Management. Das beinhaltet das Erkennen der Potenziale der IT und ihre Umsetzung in generelle unternehmerische Lösungen. Träger dieser Aufgabe sind alle Bereiche und Ebenen der Unternehmensführung.

* konzeptionelle Sicht: Entwicklung des logischen Aufbaus der IS. Die konzeptionelle Sicht des IM umfasst die logischen Aspekte aller IS in der Unternehmung und ihrer Beziehungen. Sie bezieht sich auf Daten, Funktionen, Aufgabenträger und Kommunikationsbeziehungen. Es handelt sich hier um eine Gesamtsicht, die es erlaubt, Integrationsbereiche zu erkennen.

* instrumentelle Sicht: Realisierung und Betrieb der IS. Die instrumentelle Sicht bezieht sich schließlich auf das Management der Ressourcen zur Implementierung und zum Betrieb der IS. Zu diesen Ressourcen gehören das zuständige Personal, Software und Hardware.

**Wissensmanagement** umfasst alle Anstrengungen einer Unternehmung, Wissen als eine explizite Unternehmensressource zu betrachten, zu vermehren und erfolgreich einzusetzen.

\centerline{\includegraphics[width=1\textwidth]{img/BausteinedesWM.png}}

Die Abbildung stellt zwei Kreisläufe dar. Der „äußere Kreislauf“ beinhaltet die Festlegung der **Wissensziele**, die Umsetzung dieser Ziele und die Bewertung des daraus gewonnenen Wissens. Die Umsetzung der Ziele besteht aus einem „inneren Kreislauf“, der mit der Prüfung des bestehenden Wissens beginnt und mit der Wahrung des evtl. gewonnenen Wissens endet. Die Aktivität der Festlegung von Wissenszielen dient der Verknüpfung des WM mit der allgemeinen strategischen Planung des Unternehmens sowie der Definition von Zielen, die kommunizierbar sind und deren Zielerreichung nachprüfbar ist. Diese Prüfung findet in der Teilaktivität der **Wissensbewertung** statt, die damit zur Regelung des äußeren Kreislaufs beiträgt.

Der erste Baustein in der Umsetzung der gesetzten Ziele ist die **Wissensidentifikation**, die einem Unternehmen helfen soll zu erkennen, welche Wissenselemente vorhanden sind und welche fehlen. Danach kann bei Bedarf ein **Wissenserwerb** betrieben werden, wobei dafür unterschiedlichste Quellen und Bezugsmöglichkeiten existieren (z. B. eigene Kunden, andere Unternehmen, Manager auf Zeit). Die **Wissensentwicklung** ist ein nur bedingt steuerbarer Prozess. Hier kommt es hauptsächlich auf die Schaffung von geeigneten Rahmenbedingungen für Kreativität an. Das kann auf Algorithmen basierende Verfahren wie das beschriebene Data Mining beinhalten, aber auch einfach die Teilnahme an bestimmten Fortbildungskursen. Gezielte **Wissensverteilung** sichert, dass aus individuellem oder Gruppenwissen organisationales Wissen wird. Das bedeutet natürlich nicht, dass alle Mitglieder einer Organisation schließlich über das gleiche Wissen verfügen sollen. Die Bestimmung, wer in einem Unternehmen welches Wissen benötigt, stellt eine schwierige Aufgabe der **Wissensverteilung** dar. Die **Wissensnutzung** ist ebenfalls eine Aktivität, die gezielt gefördert werden muss, da Individuen Wissen oft nicht nutzen, selbst wenn sie seine Existenz kennen. Die Schaffung geeigneter Anreizsysteme zur Nutzung fremden Wissens ist eine solche Maßnahme. Die **Wissensbewahrung** dient schließlich der Sicherstellung, dass das benötigte Wissen auch stets verfügbar ist. Dies beinhaltet auch Entscheidungen und Maßnahmen bezüglich der legalen Vernichtung von Wissen, das den Zwecken des Unternehmens nicht mehr dient.

Nochmals sei betont, dass es sich bei WM um keine Funktion handelt, die nur oder vorwiegend von Mitarbeitern der IT-Abteilung ausgeführt wird. In manchen Unternehmen befindet sich WM nicht in der gleichen Abteilung wie IM. Doch unabhängig davon, wo WM organisatorisch angesiedelt wird, muss es in enger Abstimmung mit dem IM durchgeführt werden.

### Controlling von IS

Der Begriff **Controlling** wird durch die beiden folgenden Aufgabenklassen zur Unterstützung der Unternehmensführung definiert

- Gestaltung und Betreuung einer Informationsversorgung bei der Planung, Steuerung und Kontrolle (systemgestaltende Aufgabe),
- Durchführung und Koordination von Planung, Steuerung und Kontrolle (systemnutzende Aufgaben).

Beim IS-Controlling (in der Praxis **IT-Controlling**) ist das Controllingobjekt der IT-Bereich eines Unternehmens, der die Planung, Steuerung und Kontrolle des Hardware- und Softwareeinsatzes sowie die hierbei beteiligten personellen und räumlichen Ressourcen verantwortet. Gegenstand des IT-Controllings ist die Planung einer Infrastruktur, durch die das IM mit allen erforderlichen Informationen versorgt wird, um die Wirtschaftlichkeit des IT-Bereichs zu sichern und um Potenziale von IS aufzuspüren.

#### **Strategisches IT-Controlling**

Das **strategische IT-Controlling** bezeichnet die Schaffung einer Infrastruktur zur langfristigen Planung und Kontrolle des IT-Bereichs sowie die Koordination und Durchführung dieser Aktivitäten.

**Aufgaben des strategischen IT-Controlling**

- die systematische Erschließung von Erfolgspotenzialen, die einen Betrag zur langfristigen Sicherung der Unternehmung leisten,
- die Koordination zwischen der Unternehmensstrategie und der langfristigen Ausrichtung der IS,
- die langfristige Planung der Ressourcen, die der Informationsverarbeitung zur Verfügung gestellt werden,
- die Auswahl strategisch wichtiger IS und
- die Auswahl von Methoden und Instrumenten zur Planung  und zum Betrieb der IS.

**Methoden der strategischen IS-Planung**

\centerline{\includegraphics[width=1\textwidth]{img/Porter5.png}}

Zur Entwicklung von Strategien wird empfohlen, zunächst die Branchenstruktur des Unternehmens zu untersuchen. Zur Analyse dieser Struktur dient das bekannte Fünf-Kräfte-Modell (Porter 1985). In seinem Modell geht Porter von der These aus, dass die Branchenstruktur einen wichtigen Einfluss auf die Unternehmensstrategie ausübt.
Eine offensichtliche Schwäche des Fünf-Kräfte-Modells ist darin zu sehen, dass konkurrierende Ersatzprodukte auch in anderen Branchen entstehen können, sodass nicht nur die eigene Branche untersucht werden sollte, sondern ein „Blick über den Tellerrand“ erforderlich ist.

\centerline{\includegraphics[width=1\textwidth]{img/Porterkette.png}}

Der zweite Ansatz stellt ebenfalls eine Anwendung einer Methode der generellen Strategieplanung dar - die Wertschöpfungskette (Value Chain) nach (Porter 1985). Diese Methode versucht, in der Wertschöpfungskette eines Unternehmens diejenigen Wertaktivitäten zu identifizieren, die noch nicht durch IS angemessen unterstützt werden. Dabei kann es zu mehr Integration von Wertaktivitäten, zu Reorganisationen von Geschäftsprozessen oder zur Auslagerung von Aktivitäten kommen. Wenn z. B. die Wertkette eines Herstellers mit der Wertkette einer Handelsorganisation besser integriert wird, indem dem Hersteller Informationen vom Point-of-Sale direkt weitergeleitet und an die Funktionen der Disposition und Lagerversorgung übergeben werden, können nach Praxiserfahrungen 10–15 % der Prozesskosten eingespart werden.

#### **Operatives IT-Controlling**

Gegenstand des operativen IT-Controllings ist die Sicherung der Rationalität des für den IT-Bereich zuständigen Managements durch kurzfristige Planung und Kontrolle der Aktivitäten zur Nutzung von IS sowie die dabei notwendige Koordination. Auf der operativen Ebene sind die Vorgaben des strategischen IT-Controllings zu berücksichtigen. Im Einzelnen ergeben sich für das operative IT-Controlling folgende Aufgaben

- Transparente Planung, Überwachung und Abrechnung von Kosten und Leistungen
- IT-Budgetierung und Kontrolle
- Operative Koordinierung des IT-Ressourceneinsatzes
- Überwachung von IT-Projekten im gesamten Projektverlauf
- Erstellung von Erfahrungsbilanzen und -statistiken sowie Ermittlung von zeit- bzw. projektbezogenen Kennzahlen.

In der Praxis hat sich eine Reihe von Instrumenten für das operative IS-Controlling bereits bewährt. Im Folgenden wird zunächst auf das *Monitoring* eingegangen, das bedeutsame Leistungsdaten ermittelt. Anschließend ist die Verdichtung zu *Kennzahlen* kurz zu betrachten. Schließlich ist auf die *IT-Kosten- und Leistungsrechnung* einzugehen, die als Bestandteil des internen Rechnungswesens eines Unternehmens zusammen mit der Budgetierung die administrative Grundlage für das operative IT-Controlling darstellt.

**Monitoring**

 Unter Monitoring wird die Leistungsmessung und -beobachtung in IS verstanden. Es gewinnt Informationen, die für eine bessere Lastenverteilung auf die IS-Ressourcen, für die Ermittlung von Schwachstellen und für die damit verbundene Einleitung von Verbesserungen von Programm- oder Datenstrukturen oder für Aufstockungsmaßnahmen herangezogen werden
 können. Es existieren fünf verschiedene Arten von Monitoring:

- *Hardware Monitoring*: Mittels Sensoren werden die Leistungen der Hardwarekomponenten, wie z. B. der Zentralprozessor (CPU) oder der internen Datenleitungen, aufgrund physikalisch messbarer Signale erfasst.
- *Software Monitoring*: Bei zentraler Informationsverarbeitung werden mittels Monitoren für das Betriebssystem oder für Anwendungsprogramme Informationen über das Einsatzverhalten dieser Software gewonnen. Bei diesen Monitoren handelt es sich um Programme, die ständig im internen Speicher eines Rechners verbleiben. Ein Betriebssystemmonitor liefert Informationen über die Leistung des zentralen Rechnersystems. Mithilfe der Anwendungsmonitore kann eine Verbindung der gemessenen  Leistungsdaten zu den Anwendungen, die den Ressourcenverbrauch verursacht haben, hergestellt werden. Messgrößen sind hierbei z. B. die verbrauchte Zeit der Zentraleinheit (s. Glossar) oder die Anzahl der Dateizugriffe je Benutzer. Bei dezentraler Informationsverarbeitung verfügen die Benutzer über eigene Kapazitäten. Eine Leistungsüberwachung dieser lokalen Ressourcen ist daher aus Sicht der Abteilung i. d. R. nicht erforderlich.
- *Netzwerk-Monitoring*: Durch die Anwendung von Hard- und Software Monitoren kann auch eine Überwachung und Leistungsmessung des Netzwerks erfolgen. Sie können Messgrößen, wie z. B. Arbeitslast, Durchsatz, Wartezeit auf die Nutzung einer Ressource sowie die Antwortzeit und die Verfügbarkeit einer Ressource ermitteln.
- *Datenbank-Monitoring*: Das Datenbank-Monitoring überwacht das Datenbankmanagementsystem. Wichtige Informationen in diesem Zusammenhang sind beispielsweise die Speicherplatzbelegung einer Datenbank, die Zugriffshäufigkeiten auf bestimmte Datenbestände sowie Antwort- oder Wartezeiten bei der Abfrage von Daten.
- *Accounting*: Eine spezielle Form der Ablaufüberwachung von Anwendungsprogrammen ist das Accounting. Als Ziel ist hierbei die kostenmäßige Weiterverrechnung der von Nutzern beanspruchten Systemressourcen anzusehen. Dazu dienen sogenannte Job-Accounting-Systeme, die mit der IT-Kosten- und Leistungsrechnung verbunden sind.

**Kennzahlen und Kennzahlensysteme**

 Kennzahlen sind Zahlen, die in verdichteter Form über quantifizierbare Sachverhalte rückwirkend informieren oder diese vorausschauend festlegen. Die wichtigsten Kennzahlen werden als Schlüsselkennzahlen (Key Goal Indicators oder Key Performance Indicators, KPI) bezeichnet. Eine Kombination mehrerer Kennzahlen führt zu einem Kennzahlensystem, in dem die einzelnen Kennzahlen in einer sachlich sinnvollen Beziehung zueinander stehen, sich ergänzen und/oder aufeinander aufbauen. Letztlich sind sie auf ein gemeinsames übergeordnetes Ziel ausgerichtet. Beispielhafte Kennzahlen aus dem IT-Bereich sind:

- Durchschnittliche Antwortzeit = Summe Antwortzeiten/Anzahl Transaktionen
- Durchschnittliche Nutzungsdauer = Summe Nutzungsdauer/Anzahl Programmnutzungen
- Relevanz einer Anwendung = Summe der Aufrufe dieser Anwendung/Anzahl aller Programmaufrufe
- Zuverlässigkeit = Summe fehlerfreier Ausführungen/Summe aller Programmausführungen
- *IT-Kosten- und Leistungsrechnung*: die Kosten- und Leistungsrechnung für den IT-Bereich dient zum einen der Erfassung und Bewertung des Verbrauchs sowie zur Abbildung, Steuerung und Kontrolle der IT-Ressourcen; zum anderen sind die Leistungen des IT-Bereichs abzurechnen. Die Kostenrechnung hat folgende Funktionen zu erfüllen:
- *Ermittlungsfunktion*: Die Kosten der Informationsverarbeitung müssen erhoben werden.
- *Prognosefunktion*: Die wirtschaftlichen Konsequenzen einzelner, die Infrastruktur betreffenden Handlungen müssen vorhergesagt werden können.
- *Vorgabefunktion*: Für einzelne Objekte des IT-Bereichs (z. B. bestimmte Leistungen) sind in Absprache mit den jeweiligen Verantwortlichen Sollwerte für die entstehenden Kosten vorzugeben.
- *Kontrollfunktion*: Die vorgegebenen Sollwerte gilt es nach Abschluss einer Planungsperiode mit den tatsächlichen Kosten der zu kontrollierenden Objekte zu vergleichen. Im Falle von signifikanten Abweichungen sind die Ursachen zu analysieren.

 Durch die Erfüllung dieser Funktionen können IT-Leistungen kalkuliert und mit den Preisen von Angeboten Dritter verglichen werden. Des Weiteren kann die Wirtschaftlichkeit einzelner Objekte des IT-Bereichs kontrolliert werden, und die gewonnenen Informationen können zur Entscheidungs- und kurzfristigen Erfolgsrechnung herangezogen werden.

#### Balanced Scorecard als Integrationsinstrument

Ein Beispiel für ein Instrument des strategischen und operativen IT-Controllings ist die Balanced Scorecard. Die Balanced Scorecard ist entwickelt worden, um die Leistung eines Unternehmens über die finanziellen Kennzahlen hinaus zu beobachten und zu steuern. Dabei geht es insbesondere darum, nicht nur die Leistung vergangener Perioden zu messen, sondern auch Größen zu beobachten, deren Entwicklung die zukünftige Entwicklung des Unternehmens beeinflusst. Die Balanced Scorecard soll ein Instrument sein, das sowohl die Umsetzung der operativen wie auch der strategischen Ziele fördert. Zur Klassifikation der Anwendungsbereiche werden Perspektiven formuliert. Zusätzlich zur finanziellen Perspektive gibt es die Kundenperspektive, die Perspektive der internen Geschäftsprozesse sowie die Perspektive des Lernens und des Wachstums. Für jede der vier Perspektiven sollen Kennzahlen definiert werden, mit deren Hilfe das Unternehmen so gesteuert werden kann, dass die Erreichung seiner Ziele über eine ausgeglichene Zielerreichung bei allen Perspektiven erfolgen kann.

\centerline{\includegraphics[width=1\textwidth]{img/scorecard.png}}

### Wertbeitrag von IS

\centerline{\includegraphics[width=1\textwidth]{img/modellwertgene.png}}

Die Ansätze zur Bestimmung des Wertbeitrags eines IS können dem Modell entsprechend nach verschiedenen Kriterien klassifiziert werden, z. B. nach der Organisationsebene, auf der ein Verfahren angewendet werden kann, oder der Anzahl von betrachteten Transformationsstufen vom IS-Einsatz bis zur organisationalen Performanz. Ein Kriterium kann auch der generelle Einsatzzweck der Anwendungen sein, dessen Wert gemessen werden soll. Dabei wird zwischen drei Anwendungsgruppen unterschieden.

**Verfahren zur Bewertung von IS: Anwendungsgruppen**

- *Substitutive Anwendungen* ersetzen die menschliche Arbeitskraft, dazu gehört z. B. die Lohnbuchhaltung. Diese Anwendungen werden bezüglich ihrer Bewertbarkeit als „rechenbar“ bezeichnet.
- *Komplementäre Anwendungen* werden eingesetzt, um die Produktivität und Effektivität ihrer Nutzer bei bestehenden Aktivitäten zu erhöhen; hierzu gehören z. B. Tabellenkalkulationsprogramme. Diese Anwendungen werden in Bezug auf die Bewertung als „kalkulierbar“ bezeichnet.
- *Innovative Anwendungen* dienen dazu, Wettbewerbsvorteile zu gewinnen oder zu erhalten. Hierzu gehören z. B. IS, die differenzierte oder neue Produkte oder Dienstleistungen schaffen. Diese Anwendungen werden in Hinblick auf die Bewertbarkeit als „entscheidbar“ bezeichnet.

\centerline{\includegraphics[width=1\textwidth]{img/wibewertungis.png}}

Wenn die aufbauorganisatorische Dimension als Klassifikationskriterium gewählt wird, berücksichtigen wir hier auch die Ebene der Volkswirtschaft. Tendenziell gilt: Je höher die Ebene, desto komplexer das Verfahren. Es kann auch notwendig sein, mehrere Verfahren einzusetzen und Ebenen zu analysieren, um ein vollständiges Bild aller Kosten- und Nutzenaspekte zu erhalten.

Das Verfahren **Time-Saving Time-Salary** versucht, über die eingesparte und bewertete Zeit der Mitarbeiter den Wert eines IS zu berechnen. Das Verfahren verläuft in fünf Schritten:

1. Klassifikation der Mitarbeiter zu Mitarbeitergruppen (z. B. Führungskräfte, technische Fachkräfte, Sachbearbeiter),
2. Identifikation von Aufgabenklassen und ihren Zeitanteilen für die Mitarbeitergruppen (z. B. Dokumente erstellen, Schriftgut verwalten),
3. Ermitteln individueller IS-unterstützter Arbeitsinhalte (z. B. Texterfassung, Retrieval),
4. Ableiten und Abschätzen von Einsparungspotenzialen bei den Arbeitsinhalten, und
5. Monetäre Bewertung der Gesamteinsparungen.

Das **Hedonistische Verfahren** geht einen Schritt weiter, indem es, vereinfacht zusammengefasst, die durch das betrachtete IS eingesparte Zeit vorwiegend höherwertigen Aktivitäten zuordnet und daraus den zusätzlichen Nutzen berechnet. Dabei berechnet es für die einzelnen Aktivitäten implizite hedonistische Preise unter der Annahme eines effizienten Einsatzes der Ressource Arbeit.

Ein Verfahren, das über mehrere Bereiche und Ebenen einsetzbar ist, sind die **Nutzeffektketten**. Dieses versucht, alle Auswirkungen des Einsatzes eines IS zu verfolgen, um dadurch ein konzeptionelles Verständnis der Wirkungszusammenhänge zu erreichen. Allerdings lässt der Ansatz die Frage nach der genauen quantitativen Bewertung offen.

\centerline{\includegraphics[width=1\textwidth]{img/cadnutz.png}}

Die obige Abbildung zeigt ein Beispiel für die Analyse von Nutzeffektketten bei der Einführung einer Computer Aided Design (CAD) Software über zwei Ebenen. Auf der ersten Ebene sind die Effekte an den Arbeitsplätzen im Konstruktionsbereich dargestellt, während die zweite Ebene die Auswirkungen in verschiedenen, nachfolgenden Bereichen zusammenfasst.

### IT-Gorvernance

#### Bezugsrahmen
Mangelnde Transparenz der Unternehmensführung, Verletzungen gesetzlicher Bestimmungen wie auch nicht gesetzeswidrige, aber unverantwortliche Handlungen von Unternehmensleitungen haben in den letzten Jahren zum Wunsch geführt, Regeln für eine gute und verantwortungsbewusste Unternehmensführung vorzuschreiben.

**Corporate Governance** Die Grundsätze der Unternehmensführung, die die Rechte und Pflichten der Unternehmensleitung, Aufsichtsorgane, Anteilseigner und verschiedener anderer am Unternehmen interessierter Gruppen (Stakeholder) bestimmen, werden als Regeln der Corporate Governance bezeichnet.

Die Erreichung von Unternehmenszielen unterstützen heute meist IS, deren Betrieb wiederum Risiken birgt. Daher lassen sich aus den Anforderungen der Corporate Governance auch Ziele und Anforderungen für die Entwicklung, Beschaffung und den Betrieb von IS ableiten, die als IT-Governance bezeichnet werden.

**IT-Governance** beinhaltet Regeln und Methoden zur Planung, Steuerung und Kontrolle des Einsatzes von IS in einem Unternehmen, die sicherstellen, dass sie an Unternehmenszielen ausgerichtet sind und unter Beachtung von Risiken effizient und effektiv eingesetzt werden.

Damit diese anspruchsvolle Aufgabe planmäßig und nachvollziehbar organisiert und durchgeführt werden kann, sind entsprechende Ansätze entwickelt worden, von denen das Rahmenwerk Control Objectives for Information and Related Technologies (COBIT) die größte Praxisrelevanz aufweist.

#### COBIT - Control Objectives for Information and Related Technologies
Aus der Sicht von COBIT betrifft IT-Governance fünf Bereiche:

- Die *strategische Ausrichtung* (Strategic Alignment) konzentriert sich auf den Abgleich von Unternehmens- und IT-Zielen sowie auf die Festlegung, Beibehaltung und Validierung des Wertbeitrags von IS.
- Die *Wertschöpfung* (Value Delivery) beschäftigt sich mit der Realisierung des Wertbeitrags im Leistungszyklus sowie der Sicherstellung, dass IS den strategisch geplanten Nutzen generieren können und dabei kostenoptimal agieren.
- Das *Ressourcenmanagement* umfasst die Optimierung von Investitionen in IT-Ressourcen und ein geregeltes Management derselben. IT-Ressourcen sind Anwendungen, Information, Infrastruktur und Personal. Ebenso sollte Wissen optimal eingesetzt werden.
- Das *Risikomanagement* erfordert ein Risikobewusstsein bei der Unternehmensleitung, ein klares Verständnis über die Risikobereitschaft, ein Verständnis für Compliance-Erfordernisse, Transparenz über die für das Unternehmen wichtigsten Risiken und die Verankerung des Risikomanagement in der Ablauf- und Aufbauorganisation.
- Die *Leistungsmessung* (Performance Measurement) überwacht die Umsetzung der Strategie und der Projekte, die Verwendung von Ressourcen sowie die Prozess- und Outputperformance. Die Messung geht hierbei über die Anforderungen des Rechnungswesens hinaus.

Aus der Unternehmensstrategie ergeben sich Unternehmensziele, deren Erreichung IS unterstützen sollen. Deswegen können aus ihnen Ziele für die Informationsverarbeitung abgeleitet werden, die COBIT als IT-Ziele bezeichnet. Die nächste Tabelle zeigt beispielhaft einige Unternehmensziele und daraus ableitbare IT-Ziele.

\centerline{\includegraphics[width=1\textwidth]{img/cobitbsp.png}}

Zur Erreichung der IT-Ziele müssen geeignete Prozesse festgelegt und durchgeführt werden. Die aus den Prozessen gewonnenen Informationen müssen bestimmte Qualitätskriterien erfüllen, um den Geschäftsanforderungen zu entsprechen. Diese sogenannten Informationskriterien sind aus den Anforderungen zur Einhaltung von Gesetzen und abgeschlossenen Verträgen, Sicherheitsbedürfnissen und wirtschaftlichen Erfordernissen abgeleitet. In COBIT werden sieben Informationskriterien für relevant gehalten.

\centerline{\includegraphics[width=1\textwidth]{img/cobitmeaning.png}}

Die Dimensionen Informationskriterien, IT-Prozesse sowie IT-Ressourcen, mit denen die Prozesse durchgeführt werden, bilden den **COBIT-Würfel**. Während die *Informationskriterien* unterschiedliche Geschäftsanforderungen darstellen und die *IT-Ressourcen* die involvierten Objekte gruppieren, stellen die Ausprägungen der Dimension *IT-Prozesse* eine Hierarchie dar. Aktivitäten werden zu Prozessen und Prozesse zu vier Domänen zusammengefasst, die einen Regelkreis bilden. Die IT-Ressource Infrastruktur fasst Hardware, Systemsoftware, Netze, Gebäude u. ä. zusammen.

\centerline{\includegraphics[width=1\textwidth]{img/cobitcube.png}}

Prozesse dienen der Erreichung der Ziele (Control Objectives), also den Geschäftsanforderungen. Die Prozesse sind auf die Anforderungen unterschiedlich stark ausgerichtet. Bei der intendierten Wirkung ist zwischen primären (P) oder sekundären (S) Einflüssen zu unterscheiden. Den Zusammenhang zwischen Prozessen und Geschäftsanforderungen stellt Tab. 3.5 dar. Wenn weder ein P noch ein S eingetragen sind, besteht ein geringer Einfluss. Ein „X“ kennzeichnet, welche Ressourcen im Prozess zum Einsatz  kommen. Tab. 3.5 veranschaulicht Prozesse der Domäne Planung und Organisation (PO).

\centerline{\includegraphics[width=1\textwidth]{img/tab35.png}}

Die erreichte Güte des Prozessmanagements wird mithilfe eines Reifegradmodells ausgedrückt, das ursprünglich im Bereich der Softwareentwicklung entstanden ist (nächste Abbildung).

\centerline{\includegraphics[width=1\textwidth]{img/modellreifeprozess.png}}

Die spezifische Messung der Erreichung von Zielen und Leistungen der Prozesse erfolgt mithilfe von KPI. Jeder Prozess besteht aus Aktivitäten, deren Folge Flussdiagramme darstellen. Rechtecke repräsentieren Aktivitäten und Rauten Entscheidungen. Den Ablauf kennzeichnen gerichtete Kanten. Die nächste Abbildung zeigt als Beispiel den Ablauf der Aktivitäten des Prozesses PO1 („definiere einen strategischen IT-Plan“).

\centerline{\includegraphics[width=1\textwidth]{img/ablaufprozess.png}}

##  Kapitel 4: Organisation des Einsatzes von IS

Dieses Kapitel erörtert wie der Einsatz der Informationstechnologie in einem Unternehmen organisiert und als eine klar definierte Dienstleistung an organisationsinterne und -externe Abnehmer abgegeben werden kann. Danach werden das zunehmend wichtige Management der Sicherheit im Umgang mit Informationssystemen und die Möglichkeiten des Fremdbezugs der genannten Dienstleistungen betrachtet. Das Kapitel schließt mit einer Übersicht der Berufe im Umfeld der IT.

### Organisation der IS-Funktion

#### Betriebliche Einordnung der IS-Funktions

Zuordnungsalternativen der IT-Abteilung:

*Alternative 1*: Die IT-Abteilung stellt eine Hauptabteilung neben anderen funktionalen Abteilungen dar (s. Abb. 4.1). Damit haben alle anderen Abteilungen formal einen gleichrangigen Zugriff auf die Dienste der IT-Abteilung, und die IT-Abteilung bewirbt sich eigenständig um die Ressourcen des Unternehmens. Die IT-Abteilung stellt ihre Dienste i. d. R. den anderen Bereichen in Rechnung.

*Alternative 2*: Die IT-Abteilung wird als eine Stabsabteilung der Unternehmensleitung etabliert. Abb. 4.2 stellt dies durch die Anordnung der IT-Abteilung außerhalb der Hierarchie grafisch dar. Diese Anordnung wird aus der Einschätzung heraus gewählt, dass die Informationsverarbeitung zwar wichtig, aber keine primäre Aufgabe des Unternehmens ist. Die Informationsverarbeitung ist vornehmlich eine Unterstützungsfunktion. Durch die gute Anbindung an die Unternehmensleitung hat sie zwar ein großes Durchsetzungsvermögen. Allerdings wird ihr häufig Argwohn aus anderen Abteilungen entgegengebracht.

*Alternative 3*: Bei einem *divisionalisierten Unternehmen* sind Teile der IT-Abteilung der Zentrale und andere Teile den einzelnen Divisionen (Geschäftsbereichen) zugeordnet. Die Positionierung der Informationsverarbeitung in den Geschäftsbereichen soll die optimale Versorgung dieser Bereiche mit IS-Diensten sicherstellen. Die Mitarbeiter der IT-Abteilung, oder zumindest ihr Leiter, berichten dann primär an die Leitung ihres Geschäftsbereichs und sekundär an die zentrale Informationsverarbeitung. Diese „doppelte“ Zuordnung kann zu Problemen führen. Abb. 4.3 zeigt, dass die Einordnung der dezentralen Informationsverarbeitung innerhalb der Geschäftsbereiche sowohl in der Linie als auch in Form einer Stabsabteilung geschehen kann.

\centerline{\includegraphics[width=1\textwidth,trim={0 0 0 50pt},clip]{img/be1.png}}
\centerline{\includegraphics[width=1\textwidth,trim={0 0 0 50pt},clip]{img/be2.png}}

#### Innere Organisation der IT-Abteilung
\centerline{\includegraphics[width=1\textwidth]{img/internkrit.png}}

Die Gliederung der IT-Abteilung kann nach verschiedenen Kriterien erfolgen. Es sollten diejenigen Gliederungskriterien gewählt werden, die den jeweiligen Bedürfnissen nach spezifischen Kenntnissen am besten entsprechen. Ein Unternehmen, das die fachliche Spezifität der Anwendungen kritischer als die technische Spezifität der eingesetzten Hardware und Software einschätzt, sollte einer Organisation nach betrieblichen Funktionen oder nach Geschäftsbereichen den Vorzug geben. Im umgekehrten Fall sollte der Vorzug einer organisatorischen Strukturierung nach Plattformen, Art oder Status der Systeme gegeben werden.

Es gibt innerhalb der IT-Abteilung auch Organisationseinheiten, die sich speziell um die Unterstützung der unmittelbaren Benutzer der IS bei ihrer (individuellen) Datenverarbeitung kümmern. Eine solche Einheit bezeichnet man oft als **Information Center** (IC). Die Mitarbeiter eines IC helfen den Benutzern bei der Nutzung von Programmen, wie z. B. bei Werkzeugen für Textverarbeitung und Tabellenkalkulation.

Eine Datenverarbeitung, die nicht unter der (direkten) Kontrolle der zentralen IT-Abteilung stattfindet, gilt als dezentrale Datenverarbeitung. Die IT-Abteilung übt darüber eine indirekte Kontrolle aus, indem sie z. B. den Zugang zu zentralen Datenbeständen regelt oder Richtlinien für die Anschaffung von Soft- und Hardware ausgibt.

Die Position und die Bezeichnung des IT-Leiters spielt eine nicht zu unterschätzende Rolle für die wahrgenommene und die tatsächliche Bedeutung der IS in einem Unternehmen. Je höher der Leiter in der Hierarchie angesiedelt ist, desto besser sind die Bedingungen, dass die IS die Unternehmensziele optimal unterstützen können. Die IT-Abteilung kann sich dann nicht nur an die Gesamtstrategie des Unternehmens anpassen, sondern auch zur Entwicklung dieser Strategie beitragen. Für Großunternehmen bedeutet das, dass der Leiter der IT-Abteilung Mitglied des Vorstands sein sollte.

\centerline{\includegraphics[width=1\textwidth]{img/internorga1.png}}

Abb. 4.4 zeigt die grobe aufbauorganisatorische Verankerung der IS in einer Bank. Der Hauptverantwortliche für die zentral organisierte Funktion, hier Chief Information Technology Officer (CITO) genannt, ist Mitglied des Vorstands. Eine Stabsabteilung (CITO Office) unterstützt ihn. Die Fachabteilungen sind hier nach Softwarekomponenten zusammengefasst. Sie sind nicht Geschäftsbereichen untergeordnet, deren Systeme sie hauptsächlich betreuen, sondern haben designierte Partner im höheren Management der Geschäftsbereiche, um eine optimale Zusammenarbeit sicherzustellen.

\centerline{\includegraphics[width=1\textwidth]{img/internorga2.png}}

Abb. 4.5 zeigt die aufbauorganisatorische Verankerung der IS in einem Industrieunternehmen, in welchem der ranghöchste IT-Manager kein Mitglied der Geschäftsleitung ist. Die Aufteilung der Funktionen in die drei Bereiche beschreiben folgende Begriffe:

* Anwendungen („Informationsverarbeitung“) - sowohl für betriebswirtschaftliche Anwendungen (z. B. Vertrieb) als auch für technische Anwendungen (z. B. Computer Aided Design) verantwortlich.
* Systemsoftware und Produktivitätswerkzeuge („Informationstechnik“)
* Hardware und Betrieb („Rechenzentrum“)

### IT-Servicemanagement mit Hilfe von ITIL

#### ITIL

Die Ergebnisse der Arbeit von Mitarbeitern, die IS entwickeln, betreiben oder warten, schlagen sich bei den Benutzern von IS als Dienstleistungen nieder. Damit diese Dienstleistungen sinnvoll geplant und eingesetzt werden, bedarf es eines IT-Servicemanagements. Der bekannteste Ansatz in diesem Bereich ist die **Information Technology Infrastructure Library** (ITIL). ITIL hat gewisse Überschneidungen mit COBIT. Die Konzepte werden durchaus mit COBIT zusammen eingesetzt, wobei ITIL die spezifische Ausgestaltung der von COBIT nicht konkret benannten Serviceaufgaben übernimmt. In ITIL wurden bewährte Vorgehensweisen (Best Practices) in Form von Büchern (Library, Bibliothek) durch eine britische Regierungsorganisation gesammelt, die heute Office of Government Commerce (OCG) heißt. Die Inhalte beziehen sich dabei vorwiegend darauf, *was* gemacht werden soll und nicht *wie* die Aufgabe auszuführen ist.

*ITIL-Definition eines Service*: Ein *Service* ist eine Dienstleistung, deren Erbringung dem Serviceempfänger einen Nutzen stiftet. Dafür hält der Leistungserbringer die notwendigen Betriebsmittel und das Know-how vor und trägt die entsprechenden Kosten und Risiken.

In der noch aktuellen Version, ITIL V3, sind die wichtigsten Aspekte in fünf Hauptbüchern organsiert, je eines für jeden Kernbereich (ITSMF 2012). Die darin enthaltenen Aufgaben und Prozesse sind in Ebenen angeordnet, die von der Strategie bis zur Ausführung führen (Abb. 4.6). Die kontinuierliche Bewertung und Verbesserung der Prozesse (Continual Service Improvement, links in Abb. 4.6) stellt eine Rückkopplung dar, sodass die fünf Bereiche zusammen einen Servicelebenszyklus repräsentieren. Die Tätigkeiten auf den einzelnen Ebenen verdeutlicht eine Kurzbeschreibung der darin enthaltenen Prozesse.

\centerline{\includegraphics[width=1\textwidth]{img/itil5v3.png}}

#### Service Strategy
* **Strategy Generation**: Die Entwicklung der Strategie muss auf einer eingehenden Analyse der Benutzerbedürfnisse basieren, damit der Anbieter bestimmen kann, was er wann und an wen liefern kann und will. Ebenso ist frühzeitig zu bestimmen, wie die Performance der Leistungen zu messen und der erbrachte Wert für die Nutzer zu bewerten ist. Dabei sollte auch berücksichtigt werden, dass Nutzer die Wahl zwischen verschiedenen Anbietern haben möchten.
* **Financial Management**: Wirtschaftliches Handeln in der IS-Organisation ermöglicht das Financial Management. Eine nachvollziehbare Aufstellung von Kosten und Leistungen für IS-Dienste sind die Voraussetzung für sinnvolle Service-Vereinbarungen mit den Kunden.
* **Service Portfolio Management**: Bestandteil dieses Prozesses ist die Bestimmung der aktuell und der in Zukunft angebotenen Leistungen. Leistungen, die nicht mehr ökonomisch sinnvoll angeboten werden können, sollten möglichst aus dem Portfolio eliminiert werden. Die Nutzer können sie eventuell von anderen Anbietern beziehen.
* **Demand Management**: Die Nachfrage der Benutzer nach Leistungen sollte vom Anbieter geplant und nach Möglichkeit gesteuert werden, damit die Kapazitäten kontinuierlich ausgelastet werden, und Einschränkungen in der Qualität oder Verfügbarkeit der Leistungen nicht auftreten.

#### Service Design
* **Service Level Management**: Der Prozess des Service Level Managements ist bei ITIL von zentraler Bedeutung und organisatorisch mit allen Prozessen verflochten. Er steuert die Servicevereinbarungen (**Service Level Agreement**, SLA) und kontrolliert die Qualität der erbrachten Leistungen. SLAs legen dabei Ziele und Messgrößen für den IS-Service fest, sorgen für eine transparente Leistungsfähigkeit der IT-Organisation und erzielen ein ausgewogenes Verhältnis zwischen Kundenanforderungen und den Kosten der Services.
* **Capacity Management**: Heutige und zukünftige Anforderungen an den Umfang und die Leistungsfähigkeit der IS-Ressourcen werden im Prozess des Kapazitätsmanagements erfasst. Hier werden die benötigten und kostenmäßig vertretbaren Kapazitäten der IS-Ressourcen ermittelt, um die vereinbarten Serviceleistungen termingerecht und in vollem Umfang erfüllen zu können.
* **Availability Management**: Die Abhängigkeit vieler Unternehmensprozesse von IS verlangt eine hohe Zuverlässigkeit der entsprechenden Systeme. Ziel des Availability Managements ist es, die mit dem Kunden vereinbarten Verfügbarkeiten der IS zu gewährleisten. Zur Überprüfung der Einhaltung von SLAs werden Verfügbarkeitsdaten der IS-Komponenten gesammelt und ausgewertet.

#### Service Transition
* **Change Management**: Mithilfe des Change Managements sollen effiziente, kostengünstige und termingerechte Veränderungen im IS-Umfeld mit kontrolliertem Risiko für die bestehende IS-Infrastruktur koordiniert und durchgeführt werden. Der **Service Desk** (Kundendienstbüro) ist die zentrale Stelle, an die sich Anwender mit Fragen und Wünschen bzgl. zugesagter Services wenden können. Im Kontext des Change Management kann ein Service Desk Informationen über Status und Verlauf der Änderungen geben.
* **Release Management**: Prüfung, Freigabe und Einführung neuer Hardware- und Softwarekomponenten erfolgen im Prozess des Release Managements. Dazu werden Releases geplant und gestaltet, notwendige Tests durchgeführt, die Einführung geplant und die betroffenen Anwender informiert und geschult.
* **Service Asset und Configuration Management**: Alle IS-Objekte werden zur Überwachung und Pflege eindeutig identifizierbar in einer Datenbank (**Configuration Management Database**, CMDB) gespeichert. Die Statusüberwachung der einzelnen Objekte lässt erkennen, bei welcher Stelle die Verantwortlichkeit für sie liegt und wie sie eingesetzt werden können.

#### Service Operation
* **Incident Management**: Meldungen über Störungen (Incidents), Servicebeeinträchtigungen und -beschwerden nimmt ein Service Desk entgegen und leitet diese an das Incident Management weiter. Dort werden die Störungen mit dem vorrangigen Ziel der schnellstmöglichen Wiederherstellung der gestörten Funktionen diagnostiziert und klassifiziert. Dieser Prozess stellt die Schnittstelle zwischen der IS-Organisation und den Anwendern dar.
* **Problem Management**: Ziel des Problem Managements ist die mittel- bis langfristige Reduktion der Anzahl der Störungen durch systematische Fehlersuche und -beseitigung.
* **Request Fulfillment**: Dieser Aufgabenbereich nimmt vorgesehene Serviceaufträge (Service Requests) der Anwender entgegen, prüft und stößt die Ausführung der Aufträge an und rechnet diese nach erfolgreicher Ausführung ab.

#### Continual Service Improvement
\centerline{\includegraphics[width=1\textwidth]{img/ci7.png}}

### Datensicherheit und Datenschutz

#### Gegenstand der Sicherheitsbemühungen
Die **DSGVO** verlangt den Schutz der in Organisationen gespeicherten und verarbeiteten persönlichen Daten. Darüber muss u. a. auch ein Datenschutzbeauftragter wachen.

Die Buchführung muss die **Grundsätze zur ordnungsmäßigen Führung und Aufbewahrung von Büchern, Aufzeichnungen und Unterlagen in elektronischer Form sowie zum Datenzugriff (GoBD)** beachten. Diese schreiben eine genaue Dokumentationspflicht des eingesetzten Systems und die Aufbewahrung originär digitaler Daten in maschinell auswertbarer Form vor, sodass das Finanzamt bei Bedarf die Daten bei buchführungspflichtigen Steuerzahlern elektronisch auswerten kann.

Seit Mitte 2015 ist das **Gesetz zur Erhöhung der Sicherheit informationstechnischer Systeme (IT-Sicherheitsgesetz)** in Kraft, das vor allem Betreiber von öffentlichen Telekommunikationsnetzen, Webseiten und kritischen Infrastrukturen zur Absicherung der IT und zur Meldung von Sicherheitsvorfällen verpflichtet.

Das **Gesetz zur Kontrolle und Transparenz im Unternehmensbereich (KonTraG)** betrifft den Vorstand von Aktiengesellschaften und die Geschäftsleitung großer GmbHs. Es verpflichtet Leitungsorgane, geeignete Prozesse zur Unternehmenssicherung, inklusive der Sicherheit der IS, zu etablieren. Bei Verstößen können sie persönlich haftbar gemacht werden. Für in den USA operierende Aktiengesellschaften ergeben sich ähnliche Konsequenzen aus dem **Sarbanes-Oxley-Gesetz**.

Andere Bestimmungen lassen wirtschaftliche Sachzwänge entstehen, die Unternehmen zur erhöhten Sicherheit bezüglich ihrer IS und der zugehörigen Prozesse veranlassen. Ein Beispiel hierfür ist die 2007 in Kraft getretene Vereinbarung für **Internationale Konvergenz der Kapitalmessung und Eigenkapitalanforderungen** (besser bekannt als **Basel II**), die Entscheidungen über die Kreditvergabe von Banken standardisiert. Weitere Regelungen (**Basel III**) sind bereits beschlossen und werden seit 2014 stufenweise eingeführt. Dabei ist die individuelle Wahrscheinlichkeit eines Kreditausfalls zu berücksichtigen. Ähnliches gilt beim Abschluss von Versicherungen, da Versicherungsgesellschaften über **Solvency II** zu einer genaueren Steuerung und Kontrolle der Risiken aus ihrer Tätigkeit angehalten sind.

Zu den schützenden Ressourcen zählen Daten, Programme, Hardware und Netze. Sie sind einer Reihe von Bedrohungen ausgesetzt, die frühzeitig erkannt werden müssen. Die Aufgabe des Sicherheitsmanagements (**Security Management**) besteht darin, die Schadensfälle nach Möglichkeit zu verhindern und auf Vorfälle zur Beeinträchtigung der Sicherheit vorbereitet zu sein. Das Bundesamt für Sicherheit in der Informationstechnik (BSI) unterteilt die als Bausteine bezeichnete Ressourcen in seinen IT-Grundschutz-Katalogen (GSK) in folgenden Gruppen:
\centerline{\includegraphics[width=1\textwidth]{img/gskbaustein.png}}

Für jede Ressource oder jedes Konzept in einer Unternehmung sind die spezifischen und konkreten Bedrohungen zu identifizieren. Danach können die geeigneten Maßnahmen geplant werden.

#### Bedrohungen der Sicherheit
* **Höhere Gewalt**: Naturkatastrophen oder Ereignisse wie Feuer
* **Organisatorische Mängel**: Diese Mängel entstehen, wenn in einer Organisation keine geeigneten Regeln für den Umgang mit IS bestehen oder das Personal dafür nicht adäquat geschult ist. Beispiele sind der Zugriff unberechtiger Personen auf bestimmte Daten oder Unkenntnis über den Initiator einer Transaktion.
* **Menschliche Fehlhandlungen**: Hierzu gehören Handlungen, die unbeabsichtigt zu Sicherheitsproblemen führen. Ein Beispiel hierfür ist das Aufschreiben eines Passworts auf einem in der Nähe des Computers aufbewahrten Zettel.
* **Technisches Versagen**: Dieser Faktor beinhaltet den Ausfall von Programmen, Hardware oder Netzen. Während Programme aufgrund menschlicher Programmierfehler ausfallen können, fallen Hardware und Netze aufgrund der begrenzten Lebensdauer ihrer technischen (auch elektronischen) Komponente aus.
* **Vorsätzliche Handlungen**: Hierzu zählen Aktionen von Tätern, um daraus einen wirtschaftlichen Nutzen zu ziehen oder aber, um sich "Genugtuung" zu verschaffen. Der Grund für Letztereskann der Wunsch sein, der angegriffenen Organisation Schaden zuzufügen oder sein technisches Können zu beweisen. Neben diesen beiden Sachverhalten umfassen vorsätzliche Handlungen auch Spionage und informationstechnische Kriegsführung. Beispiele sind Diebstahl von Daten, Zerstören von Daten durch Verbreitung von Viren sowie Manipulationen, um Programme zum Stillstand zu bringen oder ihr Verhalten zu verändern.

Das BSI unterteilt auch die Gefahren, Ressourcen und Vorgehensweisen in seinem IT-Grundschutz-Kompendium – Edition 2018 in folgende vier Gruppen (BSI 2018a):

* Elementare Gefährdungen (Feuer, Wasser, Diebstahl von Ressourcen, fehlerhafte Nutzungvon Ressourcen, Schadprogramme usw.),
* Bausteine (Organisation und Personal, Anwendungen, Netze und Kommunikation usw.),
* Umsetzungshinweise (für jeden Baustein), und
* Anleitung zur Migration (von der alten Version des BSI-Standards).
Die Bausteine beinhalten zunächst nur einen Teil der in früheren Versionen erfassten Bausteine und werden zügig ergänzt.
Das zentrale Konzept in diesem Ansatz stellen die Bausteine dar. Sie werden in Prozess-(z. B. Betrieb) und Systembausteine (z. B. Anwendungen) unterteilt. Jeder Baustein erklärt zuerst, worum es im Baustein geht (z. B. Organisation und Personal oder Netze und Kommunikation), was mit der Implementierung entsprechender Sicherheitslinien erreicht werden kann, welche spezifischen Gefährdungen bestehen (die bei elementaren Gefährdungen schon allgemein beschrieben sind) und dann Anforderungen, die umgesetzt werden müssen, um diesen Gefährdungen zu begegnen. Die Anforderungen sind immer in drei Stufen unterteilt:
* Basis-Anforderungen (müssen vorrangig umgesetzt werden),
* Standard-Anforderungen (sollten grundsätzlich umgesetzt werden), und
* Anforderungen bei erhöhtem Schutzbedarf.

Jede Anwenderorganisation kann ihr Modell für den Grundschutz mit den benötigten Bausteinen und Anforderungen planen und umsetzen. Die Entwicklung des Managements der Informationssicherheit kann als ein kontinuierlicher Prozess betrachtet und implementiert werden, wie es die Abb. 4.8 darstellt. ISMS ist hier die Bezeichnung für den Baustein Sicherheitsmanagement.

\centerline{\includegraphics[width=1\textwidth]{img/48.png}}

#### Datenschutz
\centerline{\includegraphics[width=1\textwidth]{img/49.png}}
\centerline{\includegraphics[width=1\textwidth]{img/datenschutz.png}}

Das *Recht auf Vergessenwerden* ist nun Bestandteil der DSGVO. Es gibt Betroffenen die Möglichkeit, die Löschung ihrer personenbezogenen Daten (oder Hinweisen darauf), unter bestimmten Umständen zu verlangen.

#### Blockchain

Wir besprechen die Blockchain-Technologie wegen ihres Potenzials zur Erhöhung der IT-Sicherheit an dieser Stelle. Die Technologie kann aber auch für weitere Zwecke genutzt werden. Ein Beispiel dazu sind Smart Contracts, die eine Automatisierung der Vertragsumsetzung erlauben. Bestimmte Aktionen können angestoßen werden, sobald bestimmte Bedingungen eintreten (z. B. bei Erreichen eines Datums oder bei Erreichen der vereinbarten Zahlungshöhe).

Eine Blockchain speichert Daten in sequenziellen Blöcken auf unterschiedlichen Rechnern redundant ab. Diese Rechner gehören unterschiedlichen Organisationen oder privaten Personen und sind im Allgemeinen alle gleichberechtigt (ein Peer-to-Peer-Netzwerk), so dass eine nachträgliche Manipulation bereits gespeicherter Daten durch Einzelne unmöglich ist. Diese Art der verteilten Datenhaltung entspricht einer verteilten Journalführung (englisch Distributed Ledger). Sie ermöglicht eine hohe Verfügbarkeit der Daten und gleichzeitig eine Art öffentlicher Aufsicht über die Daten. Dadurch entfällt der Bedarf nach einer Vertrauensinstanz, wie sie sonst bei vielen Transaktionen nötig ist. Die momentan bekannteste Anwendung des Ansatzes ist die Verwaltung des elektronischen Geldes Bitcoin. Dabei wird jede Bewegung einer „Münze“ aufgezeichnet, von ihrer Schöpfung bis zum aktuellen Verbleib, so dass eine nachträgliche Änderung einer Überweisung oder eine doppelte Ausgabe dieser Münze nicht möglich ist.

Jeder Block besteht aus den Informationen zur Transaktion und einer „Blocküberschrift“ (Block-Header). Jeder Block-Header erhält einen eindeutigen Hashwert, eine Identifikation, die per Algorithmus berechnet wird. Der nachfolgende Block stellt die Verknüpfung her, indem er auch den Hash seines Vorgängers speichert. Ein weiterer Hashwert fasst die gesamte bisherige Kette über die Wurzel des entsprechenden Hash-Baum zusammen.

Die Gültigkeit eines Blocks wird durch einen Proof of Work (oder ein anderes Konzept) festgestellt, bei dem viele Netzwerkteilnehmer Berechnungen durchführen und dann die Mehrheit den Block als korrekt anerkennt. Ein oder wenige Teilnehmer könnten nicht die Gültigkeit zufällig oder absichtlich abstreiten (oder umgekehrt einen ungültigen Block akzeptieren), denn der Konsens der Mehrheit ist entscheidend. Dieser Prozess verbraucht Rechenressourcen, wird als Mining bezeichnet und geeignet belohnt, z. B. durch (Anteile von) Bitcoins. Bei Bitcoins wird der Proof of Work durch eine nur einmal verwendete Zahl (Nonce, number used only once) repräsentiert. Schließlich enthält der Block-Header auch einen Zeitstempel. Die Verkettung in einer Blockchain wird in der nächsten Abbildung dargestellt.

\centerline{\includegraphics[width=1\textwidth]{img/blockchain.png}}

Eine eventuelle Gleichzeitigkeit von Aktivitäten kann dazu führen, dass unterschiedliche Kettenverlängerungen möglich erscheinen. Dieser Zustand wird jedoch schnell aufgehoben, indem nur eine Verlängerung (die längste) als valide angesehen wird und andere verworfen werden. Während der Inhalt der Transaktion relativ leicht lesbar ist, können die Teilnehmer der Transaktion dank Anonymisierung unerkannt bleiben, die durch asymmetrische Verschlüsselung realisiert wird. Das führt bei Bitcoins dazu, dass das System manchmal für illegale Transaktionen missbraucht wird (Geldwäsche, Waffenverkauf, usw.).

### Fremdbezug von IS-Leistungen

#### Theoretische Grundlagen
Viele kleine Institutionen beziehen aufgrund ihrer Größe IS-Leistungen von anderen Organisationen. Anfang der 90er-Jahre begannen jedoch auch einige Großunternehmen, ihre bestehenden IT-Abteilungen teilweise oder ganz in unabhängige Firmen auszulagern (Outsourcing). Dabei werden Mitarbeiter, ganze Rechenzentren und andere Ressourcen an die neuen Dienstleister übertragen oder verkauft und es wird ein langjähriger Vertrag geschlossen, in dem sich der Auftraggeber verpflichtet, vom Outsourcinganbieter bestimmte Dienstleistungen zu bestimmten Preisen zu beziehen. Es stellt sich die Frage, warum große Unternehmen Outsourcing der IS-Dienstleistungen betreiben, wenn sie im Prinzip selbst von Größendegressionseffekten profitieren können, die durch fallende Durchschnittskosten aufgrund steigender Produktionsmengen entstehen.

Ein Motiv hierfür besteht darin, dass sie ihre Aktivitäten auf Kernkompetenzen konzentrieren. In manchen Unternehmen ist die Leitung mit den Leistungen der IT-Abteilungen zwar nicht unzufrieden, aber sie geht nicht davon aus, dass der Wechsel zu einer neuen Technologie mit der bestehenden Organisation erfolgreich realisierbar ist. Weiterhin können die Outsourcinganbieter die benötigten Leistungen oft günstiger produzieren als die nachfragenden Firmen, weil sie sich auf bestimmte Dienste spezialisieren und dadurch noch größere Produktionsmengen erreichen oder weil sie als Hardware- und Softwarehersteller Informations- und Wissensvorsprünge gegenüber Anwenderfirmen besitzen.

Das Outsourcing birgt aber auch eine Vielzahl von Risiken. Dadurch, dass nun Firmenfremde die IS-Leistungen erbringen, verstehen diese eventuell weniger vom Kerngeschäft des Kunden und haben weniger Interesse am Kunden. Das strategische Potenzial des Einsatzes von IS wird dann vielleicht nicht erkannt und realisiert.

Die Wahl der optimalen Organisation von IS-Aktivitäten hängt nach der *Theorie der Transaktionskosten* von der Sicherheit und Häufigkeit einer Transaktion sowie der Spezifität der involvierten Ressourcen (z. B. Maschinen oder Wissen) ab.

\centerline{\includegraphics[width=1\textwidth]{img/outsourcingmecha.png}}

#### Formen von Outsourcing
* **Cosourcing**: Bildung einer gemeinsamen Tochtereinheit durch die Vertragspartner, i. d. R. einer selbstständigen Firma, die dann auch anderen Parteien Leistungen verkauft.
* **Insourcing**: Wenn eine Firma vor einer Outsourcing-Entscheidung auch die eigenen Mitarbeiter um ein Angebot bittet und diese den Wettbewerb gewinnen. Dabei schließt sie Verträge über die zu erbringenden Leistungen mit der eigenen Abteilung; die Entlohnung der Mitarbeiter wird an die Erfüllung dieser Verträge gekoppelt.
* **Offshore Outsourcing (Offshoring)**: Wenn der Outsourcinganbieter seine Leistungen im Ausland (insbesondere in Übersee) erstellt. Dabei handelt es sich i. d. R. um Länder mit niedrigeren Lohnniveaus, wie sie derzeit z. B. in Indien und China vorherrschen.
* **Nearshoring**: Outsourcing nach nahen Ländern (z.B Osteuropa - Deutschland).

Nach Schätzungen von Marktforschern wird der Anteil der über Outsourcing erbrachten IS-Leistungen weiterhin steigen. Das Outsourcing verkleinert die IT-Abteilungen, sodass man in diesem Zusammenhang auch von **Downsizing** spricht. Dieser Begriff kennzeichnet auch den Übergang von Großrechnern auf kleinere Rechner. Da jedoch mit der Zeit erkannt wurde, dass kleinere Rechner und kleinere IT-Abteilungen nicht immer zu besseren Ergebnissen führen, versucht man mittlerweile, die für das jeweilige Unternehmen richtige Größe der IT zu finden (**Rightsizing**, oder **Smartsourcing**) und genau die Leistungen zu beziehen, die andere ökonomisch sinnvoller bereitstellen können.

**Application Service Providing (ASP)** ist eine Form des Outsourcings, bei der der Anbieter eine Anwendung für den Kunden in seinem Rechenzentrum (oder dem eines von ihm beauftragten Unternehmens) mit einer von ihm entwickelten, gekauften oder gemieteten Software betreibt. Der Kunde nutzt die Anwendung in seinen Räumen meist über das Internet mithilfe eines Webbrowsers. Dies ist ein Unterschied zum traditionellen Outsourcing wie auch die Tatsache, dass es beim ASP regelmäßig zu keiner Übertragung von Ressourcen oder zu einem Wechsel der Mitarbeiter zum Outsourcinganbieter kommt. Ein ASP-Anbieter wird die Anwendungen nur in geringem Ausmaß an die Anforderungen einzelner Kunden anpassen wollen, da er sonst seine „Produktionskosten“ nicht niedrig halten kann.

#### Cloud, Edge und Fog Computing
Eine Erweiterung von ASP stellt das **Cloud Computing** dar. Dabei wird nicht nur der Betrieb von Anwendungen angeboten, sondern auch andere IT-Dienstleistungen, die von einem oder mehreren kooperierenden Anbietern mit ihrer Hardware und Software zur Verfügung gestellt werden. Der Zugriff auf die angebotene Dienstleistung erfolgt i. d. R. über das Internet, das oft als eine Wolke (Cloud) vernetzter Computer dargestellt wird. Die Vorteile von Cloud Computing basieren auf der Vorstellung, dass der Kunde die Dienstleistungen flexibel nach Bedarf (On Demand) nutzen und nach Verbrauch bezahlen kann (Workload Based Billing). Zusätzlich benötigte Ressourcen werden sofort ohne weitere Verhandlungen zur Verfügung gestellt und abgerechnet.

**Cloud Computing** ist eine Architektur, die einen bequemen Netzwerkzugang nach Bedarf zu einem gemeinsam genutzten Vorrat von konfigurierbaren Rechenressourcen (z. B. Netzwerke, Server, Speicherplatz, Anwendungen und Dienste) ermöglicht, die schnell und mit einem geringen Managementaufwand oder mit geringer Anbieterinteraktion bereitgestellt und abgerufen werden können.

Cloud Computing unterscheidet unterschiedliche Dienstkategorien. Das Angebot von standardisierten Anwendungen, die einzelne Softwarekomponenten oder Services umfassen, wird als *Software as a Service (SaaS)* bezeichnet. Wenn Kunden nur die Hardware des Anbieters nutzen möchten, um dort z. B. Daten zu speichern oder eigene Programme ausführen zu lassen, dann wird diese Dienstleistung *Infrastructure as a Service (IaaS)* genannt. Manche Anbieter bieten auch eine Plattform an, auf der flexibel Software mit standardisierten Schnittstellen entwickelt werden kann, was dann als *Platform as a Service (PaaS)* bezeichnet wird. Die genannten Dienstleistungen können auch kombiniert angeboten werden. Diese Kombination kann zu einem kompletten Geschäftsprozess führen. Wenn ein Geschäftsprozess über die Cloud angeboten wird, wird dies als *Business Process as a Service* (BPaaS) bezeichnet.

Wenn die angebotenen Ressourcen und Dienste der Organisation gehören, in der sie genutzt werden, liegt eine *Private Cloud* vor. Wenn Dienstanbieter und Nutzer unterschiedlichen Organisationen angehören, wobei die Nutzer Mitglieder vieler Organisationen (oder Privatpersonen) sind, spricht man von einer *Public Cloud*. Wenn Cloud Computing nur einem geschlossenen Kreis von Nutzern, die bestimmten Organisationen angehören, angeboten wird, ist diese Konfiguration als eine *Community Cloud* zu bezeichnen. Beim *Multi Cloud Computing* liegt der Fokus auf der Verwendung mehrerer Clouds von dritten Anbietern.

\centerline{\includegraphics[width=1\textwidth]{img/cloud.png}}

Wenn an einem Ort sehr viele Daten entstehen, z. B. durch Sensoren, die kontinuierliche Prozesse überwachen, dann kann ihre Verarbeitung an einem anderen Ort wegen der notwendigen Übertragung zu lange dauern oder zu teuer sein.  Diese Verzögerung (Latenz) bei der Übertragung großer Datenmengen kann vermieden werden, wenn die Daten zuerst vor Ort verarbeitet werden (an den Rändern einer Cloud-Architektur), was zu **Edge Computing** führt. Aggregierte Daten können danach in die Cloud gesendet werden, um dort detaillierte Analysen vieler solcher Prozesse, die an verschiedenen anderen Orten ablaufen, durchzuführen und Prozesse mittelfristig zu verbessern. In manchen Umgebungen kann es auch sinnvoll sein, zwischen Rändern und einer (oder mehreren) zentralen Cloud(s) Verarbeitungskapazitäten zu schaffen. Damit können z. B. Engpässe bei der Leistung an Edge-Geräten vermieden werden bei gleichzeitiger Minderung der Probleme der Übertragungslatenz. Eine solche Möglichkeit wird als **Fog Computing** bezeichnet. Dabei kann es mehrere Fog-Schichten geben. Das Zusammenspiel der Schichten wird in Abb. 4.12 dargestellt.

\centerline{\includegraphics[width=1\textwidth]{img/cloudfogedge.png}}

##  Kapitel 5: Unternehmen in der vernetzten Welt

Dieses Kapitel betrachtet die Rolle der Unternehmen in der durch digitale Kommunikation geprägten Welt. Zuerst werden die grundlegenden Möglichkeiten des Einsatzes des zunächst an einen festen Ort gebundenen Internets für kommerzielle Zwecke entlang der Wertschöpfungskette kurz erläutert. Diese Betrachtung wird dann auf die mobile Nutzung und damit mobile Geschäftsaktivitäten erweitert. Die Kommunikation mit Konsumenten spielt sich zunehmend in sozialen Medien, in die deswegen auch in diesem Kapitel eingeführt wird. Das Kapitel schließt mit der Betrachtung von Möglichkeiten, die sich aus der Kommunikation von Maschinen und Informationssystemen untereinander ergeben.

### Einführung

**Electronic Business** schließt alle Aktivitäten ein, die über ein elektronisches Kommunikationsnetz abgewickelt werden und direkt oder indirekt kommerziellen Zwecken dienen.

Eine häufig verwendete Klassifikation der Erscheinungsformen von E-Business unterscheidet drei gesellschaftliche Bereiche, aus denen die Teilnehmer kommen können: Öffentliche Verwaltungen (Administration), Unternehmen (Business) oder Privatpersonen (Consumer).

\centerline{\includegraphics[width=1\textwidth]{img/ebform.png}}

Wenn ökonomische Transaktionen auf einer elektronischen Plattform erfolgen, liegt ein *elektronischer Marktplatz* vor. Elektronische Marktplätze unterscheiden sich nach der Anzahl der Teilnehmer, die auf der Anbieter- und Nachfragerseite am Zustandekommen einer Transaktion beteiligt sind. Die nächste Tabelle gibt einen Überblick über vier Typen elektronischer Marktplätze.

\centerline{\includegraphics[width=1\textwidth]{img/emarket4.png}}

Der hohe Standardisierungsgrad von Internettechnologien und das große Softwareangebot haben Unternehmen dazu motiviert, diese Technologien auch für firmeninterne Kommunikationsnetze einzusetzen. Solche Netze werden dann als *Intranet* bezeichnet. Wenn Unternehmen ihr Kommunikationsnetz für ausgewählte Geschäftspartner öffnen, spricht man von einem *Extranet*. Sowohl ein Intra- als auch ein Extranet können die Infrastruktur des Internets verwenden, wobei Passworte und Verschlüsselung die Exklusivität der Nutzung sicherstellen.

Websites, die Besucher als zentralen Zugang zum Internet benutzen, werden als **Portal** bezeichnet. Die Portale können Dienste wie Suche, Inhalte (z. B. aktuelle Nachrichten), Gemeinschaftsdienste wie Kommunikation unter den Nutzern oder elektronischen Handel anbieten. Sie können oft vom Benutzer über Parameter seinen Bedürfnissen angepasst werden (*Personalisierung*). Portale, die Benutzern zur Suche nach anderen Websites dienen, werden als *Suchmaschinen* bezeichnet (z. B. Google oder Yahoo). Portale werden oft auch im Intranet als *Unternehmensportale (Enterprise Portal)* zur Verfügung gestellt.

### Ausgehende Aktivitäten

Unter **E-Marketing** ist die Nutzung elektronischer Netzwerke und Medien für die Aufgaben des Marketings zu verstehen. Insbesondere das Internet kann zur Unterstützung vieler Marketinginstrumente sowie zur Marketingforschung genutzt werden.

Beim Werben im Internet wird die Werbebotschaft häufig in einem kleinen, rechteckigen Bereich (*Banner*) auf einer Website präsentiert. Die Werbung kann aus einem Text, einer Grafik oder einer Videosequenz bestehen. Wenn der Betrachter mehr Informationen haben möchte, kann er i. d. R. auf das Banner klicken und so zur beworbenen Website gelangen. Bei dieser Werbeform ergeben sich Vorteile gegenüber den traditionellen Werbeformen wie z. B. Print-Medien, Radio und TV-Werbung:

* Geringere Streuung (Werbung wird auf Websites platziert, die in Zusammenhang mit dem beworbenen Produkt stehen, oder nur denjenigen Besuchern gezeigt, die aufgrund ihrer demografischen oder Verhaltensdaten als Zielgruppe für das beworbene Produkt ermittelt wurden),
* höhere Flexibilität (die Werbung kann ganz kurzfristig geschaltet werden),
* geringere Kosten (die Erstellung eines Banners ist kostengünstig und die Präsentation wird automatisch gesteuert) und
* bessere Erfolgskontrolle (es ist feststellbar, wie Besucher zu einer Website gelangt sind und welche Aktionen sie dort ausgeführt haben).

Ebenso kommen Textanzeigen zur Anwendung, insbesondere auf Suchmaschinen. Die Werbetreibenden buchen Begriffe, sodass bei Verwendung dieser Begriffe in der Suche ihre Textanzeigen eingeblendet werden. Diese Werbeform wird **Search Engine Advertising** (Suchmaschinenwerbung) genannt. Die Anpassung eigener Websites sowie die Platzierung von Verweisen auf das eigene Informationsangebot auf externen Websites, damit die eigene Website einen hohen Rang in Suchergebnissen erhält, wird als **Search Engine Optimization (SEO)** bezeichnet. E-Marketing ist kein Ersatz für traditionelle Marketinginstrumente, sondern stellt eine Ergänzung dar. So führen vielfach Konsumgüterhersteller hybride Marketingkampagnen durch, die unterschiedliche Werbeformen (z. B. TV-Werbung und Websites) kombinieren.

Ein Bestandteil der Marketingforschung im Web ist die Beobachtung des Besucherverhaltens auf der Unternehmenswebsite. Das wird durch die Aufzeichnung aller Seitenaufrufe in einer Logdatei unterstützt. Die spätere Analyse dieser Datei mit Methoden des Data Mining gilt als **Web Log Mining**, was besonders bei einem E-Shop zu wertvollen Erkenntnissen führen kann.

Das Marketing verändert in den letzten Jahren seinen Fokus von transaktions- und produkt- hin zu beziehungsorientierten Aspekten. Es stehen nicht der einzelne Produktverkauf, sondern der Aufbau und die Pflege der langfristigen Kundenbeziehung im Vordergrund, aus der dann ökonomische Vorteile entstehen sollen. Dieser Ansatz, der die Integration kundenorientierter Aktivitäten im Marketing, Vertrieb und Kundendienst erfordert, wird als **Customer Relationship Management (CRM)** bezeichnet. Erfolgreiches CRM erfordert entsprechende organisatorische und mitarbeiterbezogene Maßnahmen, aber die Umsetzung des CRM ist in großen Organisationen ohne Unterstützung durch spezifische IS kaum realisierbar. Der Begriff **E-CRM** steht für die Verwendung von IS für CRM.

### Interne Aktivitäten und Logistik

Die Nutzung elektronischer Netzwerke zur Produktionsunterstützung wird als **E-Production** bezeichnet. Zuerst geht es darum, den Planungsstand und den Fortschritt der Produktion im Intranet oder im Extranet besser zu kommunizieren. Durch die verbesserte Kommunikation können dann notwendige Dispositionen früher getroffen werden.

Logistikprozesse umfassen Güter- und begleitende Informationsflüsse. Logistische Leistungen werden auf der eingehenden Seite eines Unternehmens (Beschaffungslogistik), betriebsintern (Produktionslogistik) und auf der ausgehenden Seite (Distributionslogistik) benötigt. Sofern es sich um digitale (z. B. Software) bzw. digitalisierbare Güter (z. B. Musik) oder Dienstleistungen (z. B. Beratung) handelt, können sämtliche Logistikprozesse mithilfe elektronischer Netzwerke realisiert werden. Andernfalls beschränkt sich die Unterstützung durch IS auf die begleitenden Informationsflüsse. **E-Logistik** schließt also den Versand digitaler Güter über elektronische Kommunikationsnetze wie auch elektronische Marktplätze für logistische Leistungen ein, auf denen z. B. LKW-Transportkapazitäten gehandelt werden.

Die Notwendigkeit der Verbesserung zwischenbetrieblicher Prozesse hat in den letzten Jahren zu Konzepten wie **Supply Chain Management (SCM)** geführt. SCM soll die Zusammenarbeit zwischen einem Produzenten und seinen Zulieferern entlang aller Zulieferstufen (also der gesamten Lieferkette) so fördern, dass ein optimales Ergebnis für alle Beteiligten entsteht. Zur Erreichung dieser Ziele ist u. a. ein präzise geplanter und standardisierter Informationsaustausch notwendig, den **E-SCM** unter Nutzung der Internettechnologien liefern kann.

**E-Procurement** umfasst die elektronische Beschaffung aus Katalogen sowie auf elektronischen Marktplätzen.

### Unterstützende Aktivitäten

#### Personalfunktion

Die Personalfunktion umfasst u. a. die Personalbeschaffung und die Personalentwicklung.

In zunehmendem Maße werden zur Personalbeschaffung internetbasierte Jobportale verwendet, mit denen der Bewerbungsprozess digital unterstützt werden kann. Solche Jobportale werden von Medienunternehmen (z. B. Frankfurter Allgemeine Zeitung) zur Verfügung gestellt, oder aber von personalsuchenden Unternehmen (z. B. Telekom).

Eine der wichtigsten Maßnahmen der Personalentwicklung ist die Weiterbildung der Mitarbeiter. Bei konventionellem Lernen müssen sich die Mitarbeiter an einen bestimmten Ort zu einer bestimmten Zeit befinden (Präsenzlernen). Dadurch entstehen nicht nur direkte Kosten, sondern auch Kosten durch Unterbrechungen der normalen betrieblichen Abläufe. Diese Probleme lassen sich beim Lernen mit vorwiegender Hilfe elektronischer Medien umgehen. Der Begriff des **E-Learning (Computer Assisted Learning)** fasst verschiedene Szenarien zusammen.

Die verschiedenen Formen des E-Learning können nach den Merkmalen der Kommunikationsfähigkeit des Lernenden mit anderen Lernenden oder dem Lehrenden und dem zeitlichen Bezug zwischen Angebot und Nachfrage der Lerninhalte zueinander abgegrenzt werden.

\centerline{\includegraphics[width=1\textwidth]{img/elearningmerkmal.png}}

Im Szenario des **virtuellen Seminarraums** findet Unterricht zu einer bestimmten Zeit statt, aber Lehrende und Lernende können an verschiedenen Orten sein und miteinander audiovisuell kommunizieren. Im Szenario des **Web-Based Training** ist ein Kurs jederzeit über das Internet abrufbar und der Nutzer kann den Ablauf (z. B. Lernpfad und Lerntempo) individuell steuern. **Computer Based Training (CBT)** ist die historisch älteste Form des E-Learning und kann auf einem PC ohne Netzanbindung erfolgen. Bei dem Szenario des **Business TV** wird das Lernprogramm über einen unternehmenseigenen Fernsehkanal oder einen Video on Demand Server bereitgestellt.

#### Forschung und Entwicklung

Eine relativ neue Form zur Erschließung externer Wissensressourcen findet im Bereich der Forschung und Entwicklung Anwendung. Dabei werden externe Personen offen oder verdeckt dazu aufgefordert, bei der Entwicklung neuer Produkte (oder Dienstleistungen) oder der Verbesserung bestehender Produkte mitzuhelfen. Dieser Ansatz des **Open Innovation** kann im Internet in Diskussionsgruppen, auf einfachen Websites oder mithilfe spezieller Plattformen umgesetzt werden.

### Mobile Business

Die rasante Verbreitung mobiler Kommunikationstechniken hat zum zunehmenden Einsatz von mobilen Endgeräten zur Abwicklung von Geschäfts- und Transaktionsprozessen geführt. **M-Business** ist die kommerzielle Nutzung mobiler Geräte über Mobilfunknetze.

Generell ist M-Business als ortsungebundenes E-Business aufzufassen. M-Business liefert gegenüber E-Business zusätzliche Anwendungsmöglichkeiten, die sich insbesondere aus der Lokalisierungsmöglichkeit ergeben, wenn das Zugangsgerät im mobilen Netz angemeldet oder auf andere Weise lokalisierbar ist. Dann können dem Benutzer auch *ortsabhängige Dienste (Location Based Services)* angeboten werden (z. B. Anzeige des nächst gelegenen Restaurants). Zusätzlich kann der Netzbetreiber auch die Bewegung (Motion) des Zugangsgeräts feststellen. Im vorhergehenden Beispiel könnte man eine Werbung einem Benutzer senden, der sich in Richtung des Restaurants bewegt, aber nicht einem, der sich davon entfernt oder sich schon eine bestimmte Zeit gar nicht bewegt, obwohl sie alle im Augenblick gleich entfernt von Restaurant sind. Wenn Lokation und Bewegung vieler Teilnehmer beobachtet wird, können auch neue Anwendungen entstehen, z. B. die Vorhersage von Staus. Dabei sind jedoch stets Fragen des Datenschutzes zu klären.

Auf modernen mobilen Endgeräten wie Smartphones können Anwendungen (Apps als Abkürzung für Applications) installiert werden, womit Nutzer ihre Endgeräte um neue Funktionalitäten erweitern können. Die Potenziale von M-Business fasst wie folgt zusammen:

* **Ubiquität (Allgegenwärtigkeit)**, d. h. die Angebote sind überall und stets verfügbar, da die Endgeräte i. d. R. immer eingeschaltet sind (Always On), nicht gestartet werden müssen und an jeden Ort mitgenommen werden können.
* **Kontextspezifizität**, d. h. durch die Möglichkeit der Lokalisierung und der Interaktion mit der Umgebung wird der Kontext (Ort, Bewegungsrichtung, Uhrzeit, Temperatur, bekannte Interessen des Nutzers) in das Angebot mit einbezogen.
* **Datenproaktivität**, d. h. Dienste können nach dem Push-Prinzip automatisiert ausgelöst werden (z. B. Unwetterwarnung).
* **Abschlussmöglichkeit**, d. h. Abrechnung von Leistungen, indem man das mobile Gerät zur Identifikation des Kunden benutzt (Mobile Payment).
* **Interaktion**, d. h., dass beispielsweise mittels App mit anderen Kommunikationspartnern im Umkreis kommuniziert werden kann.
* **Integration von Unterhaltung**, d. h., dass beispielsweise Videos oder Musik im MP3-Format auf das Endgerät übertragen, im Gerät gespeichert und jederzeit abgespielt werden können.
* **Remote Control (Fernsteuerung)**, d. h., dass beispielsweise aus dem Urlaub per „intelligentem Endgerät“ die Elektronik des eigenen Hauses ferngesteuert werden kann.

### Soziale Medien und Web 2.0

#### Eigenschaften von Web 2.0-Anwendungen
Der Begriff **Web 2.0** kennzeichnet Anwendungen, die das World Wide Web als technische Plattform nutzen, auf der die Programme und die *benutzergenerierten Inhalte* zur Verfügung gestellt werden. Die *gemeinsame Nutzung der Inhalte und gegenseitige Bezüge* begründen Beziehungen zwischen den Benutzern.

Prägend für diese Anwendungen ist, dass die Inhalte auf den Websites primär von ihren Besuchern generiert werden **(User Generated Content, UGC)**. Sowohl die Programme als auch die Daten werden auf der Webplattform vorgehalten und sind deswegen von überall mithilfe des Browsers nutzbar. Den Unterschied zwischen den Anwendungen des Web 1.0 und 2.0 stellt Abb. 5.2 grafisch dar.

\centerline{\includegraphics[width=1\textwidth]{img/web1and2.png}}

Der Nutzen von Web 2.0-Anwendungen entwickelt sich nach dem Prinzip der **Netzwerkeffekte**. Je mehr Nutzer eine Anwendung hat, desto wertvoller wird sie für sämtliche Nutzer, da mit jedem neuen Benutzer die Anzahl potenzieller Kommunikationsmöglichkeiten überproportional wächst.

Bei einer aktiven Teilnahme vieler Benutzer wachsen meist auch Quantität und Qualität der Inhalte, weil eine Gruppe mehr und bessere Informationen als ein Einzelner oder einige wenige Benutzer beitragen kann. Dieses Prinzip wird als **Crowdsourcing (Wisdom of Crowds)** oder **kollektive Intelligenz** bezeichnet.

Einige Anwendungen erlauben die Bedienung spezieller Interessen, z. B. den Austausch selten gebrauchter Produkte oder die Beantwortung sehr spezifischer Fragen. Diese Art von Nachfrage wird als **Long Tail** bezeichnet. Der Begriff kommt daher, dass die statistische Verteilung der Nachfrage wie ein langes Rumpfende (s. Abb. 5.3) erscheint. Sie ergibt sich daraus, dass einige wenige Güter sich großer Nachfrage erfreuen (*Bestseller*), während viele andere Güter nur selten nachgefragt werden (*Nischenprodukte*). Die Bedienung von Nischenmärkten mit Informationen oder Produkten, die digital geliefert werden können (z. B. Bilder, Musikstücke oder Videos), verursacht relativ geringe Grenzkosten, sodass Geschäftsmodelle, die sich außerhalb der elektronischen Netze nicht lohnen würden, im Internet wirtschaftlich sein können.

\centerline{\includegraphics[width=1\textwidth]{img/longtail.png}}

Die gemeinsame Entwicklung von Inhalten, die Kommunikation mit anderen Benutzern der Anwendung oder der regelmäßige Konsum der Beiträge anderer Benutzer führen zu sozialen Beziehungen zwischen den Benutzern des Web 2.0. Deswegen wird die Gesamtheit der Benutzer einer solchen Anwendung auch als eine **soziale Gemeinschaft (Social Community)** angesehen, und die verschiedenen Anwendungen werden zusammen als **soziale Medien (Social Media)** bezeichnet. Sie stehen damit im Gegensatz zu traditionellen Medien wie Fernsehen oder Druckmedien, bei denen die Anbieter gleiche Inhalte an viele passive Empfänger (Konsumenten) verteilen.

Die unterstützenden Programme werden als **Social (Networking) Software** bezeichnet. Die Kommunikationsbeziehungen zwischen den Benutzern einer Web 2.0-Anwendung können mithilfe von Methoden der **Social Network Analysis (SNA)** untersucht werden.

#### Soziale Netzwerke mit Fokus auf Kommunikation
Bei kommunikationsfokussierten **sozialen Netzwerken (SN)** stehen die Individuen und deren Kommunikationsprozesse im Vordergrund. Zu diesem Zweck spezifizieren Benutzer ein individuelles Profil. Dieses kann u. a. Fotos, demografische Angaben, Angaben zu Interessen, Freunden oder Kontakten enthalten. Teile des Profils können auch als privat deklariert und so nur ausgewählten Benutzern zugänglich gemacht werden. Meistens gehören zunächst bestehende Bekanntschaften zum eigenen Kommunikationskreis, aber im Laufe der Zeit kommen neue Bekanntschaften aus dem Netzwerk hinzu. Innerhalb des Netzwerkes bilden sich thematische Subnetze z. B. nach Studienort, Beruf oder Hobby.

Die Mitglieder können u. a. mit einzelnen Bekannten Nachrichten austauschen, in Foren diskutieren, multimediale Inhalte in ihrem Bereich publizieren und anderen zur Verfügung stellen, sowie Fragen stellen. SN sind zunächst für private Zwecke, wie z. B. Facebook, oder für berufliche oder geschäftliche Zwecke, wie z. B. LinkedIn, angeboten worden. Weiterhin wird zwischen offenen und geschlossenen Netzwerken unterschieden, die nur für bestimmte Personenkreise zugänglich sind (z. B. nur für Fahrer eines bestimmten Automodells).

#### Soziale Netzwerke mit Fokus auf multimediale Inhalte

Bei multimedialen Netzwerken publizieren die Benutzer Bilder (z. B. bei Flickr), Videoclips (z. B. bei YouTube) oder Audiodateien und stellen sie der Allgemeinheit zur Verfügung (und bekommen manchmal Geld dafür). Derjenige, der einen Beitrag hochlädt, kann diesen mithilfe einiger Stichworte beschreiben, die als Tags bezeichnet werden. Daraus entsteht eine implizite Kategorisierung der Beiträge, nach denen mit Stichworten gesucht werden kann. Benutzer können Beiträge bewerten und kommentieren.

Es wird versucht, die Klassifizierung der multimedialen Inhalte aufgrund der Inhalte selbst vorzunehmen. Dann kann z. B. nach allen Bildern, auf denen ein Sonnenuntergang abgebildet ist, oder nach allen Videoclips, in denen Fußball gespielt wird, gesucht werden, ohne dass diese Begriffe in Tags vorkommen müssen. Dies gestattet auch die zielgenauere Platzierung von Werbung, sodass z. B. ein Werbespot für Fußballschuhe automatisch nur in Videoclips, in denen Fußball gespielt wird, ausgestrahlt wird.

#### Weblogs

Das Wort **Weblog**, abgekürzt **Blog**, setzt sich zusammen aus Web und Logbuch und kennzeichnet damit eine Art Tagebuch im World Wide Web, das von einem oder mehreren Autoren geführt wird. Der neueste Beitrag erscheint auf der Website ganz oben, gefolgt von älteren Beiträgen. Leser können die Beiträge an gleicher Stelle kommentieren. Zum Schreiben in einem Blog sind dank entsprechender Softwarelösungen keine Programmierkenntnisse notwendig. Ein Blog kann mit einer Liste auf andere Weblogs verweisen (**Blogroll**). Ein Blog kann auch Bezüge auf seine Beiträge in anderen Weblogs verzeichnen (**Trackbacks**). Durch alle diese Querbezüge entsteht ein Netzwerk, das als Blogosphäre bezeichnet wird und exemplarisch in Abb. 5.5 dargestellt ist.

\centerline{\includegraphics[width=1\textwidth]{img/weblog.png}}

Während Millionen Blogs nur wenige Einträge und Leser haben, können Beiträge von Blogautoren, die als Meinungsmacher angesehen werden, hohe Relevanz für Unternehmen besitzen. Deswegen betreiben große Unternehmen bisweilen eine regelmäßige, teilweise automatisierte Beobachtung von Blogs, um mögliche Probleme oder Chancen frühzeitig zu erkennen. Immer mehr Unternehmen setzen Blogs auch für die externe und interne Kommunikation ein. Als Autor tritt dort oft der Vorstandsvorsitzende auf.

Eine spezielle Form des Weblogs stellen sog. **Mikroblogs** dar (z. B. Twitter). Wenngleich diese typische Merkmale von Weblogs, wie die umgekehrt chronologische Darstellung der Nachrichten eines Nutzers, besitzen, unterscheiden sie sich insbesondere hinsichtlich des Umfangs eingereichter Nachrichten von dem zuvor dargestellten Weblog. Verschiedene Dienste geben eine maximale Anzahl von Zeichen pro Eintrag vor. Abonnenten werden in diesem Kontext als **Follower** bezeichnet. Im Kontext der nach außen gerichteten Kommunikation benutzen Unternehmen Mikroblogging, um z. B. Mitteilungen über Jobangebote oder über das eigene soziale Engagement zu verbreiten.

#### Wikis

Der Begriff **Wiki** kommt vom hawaiischen Ausdruck wiki wiki für „schnell“. Er soll andeuten, dass mit dieser Technologie eine schnelle und einfache Veröffentlichung von gemeinsam entwickelten Dokumenten möglich ist. Ein Benutzer erstellt einen Text mit der Bearbeitungsfunktion der Wiki-Software, die einfache Textverarbeitungsbefehle zur Verfügung stellt. Der Text kann dann sofort im WWW veröffentlicht, von anderen Benutzern gelesen und geändert werden. Die Zielsetzung besteht darin, dass durch die gemeinsame Entwicklung vieler Autoren Dokumente mit hoher Qualität entstehen, da ein Kollektiv stets über mehr Wissen und Intelligenz verfügt als ein individuelles Mitglied dieses Kollektivs (kollektive Intelligenz). Einzelne Dokumente eines Wikis sind miteinander verknüpft und die Änderungen des Dokuments werden fortlaufend festgehalten, sodass die Änderungshistorie transparent ist. Ungewollt oder absichtlich eingetragene Fehler können schnell entdeckt und korrigiert werden, wenn ein Wiki viele Benutzer hat. Dokumente im Wiki können auch multimediale Inhalte enthalten.

Für Unternehmen stellt diese Technologie eine einfache, kostengünstige und dennoch leistungsfähige Plattform für das Wissensmanagement dar, sodass zunehmend unternehmensinterne Wikis für Projektmanagement, Produkt- oder Kundeninformationen u. a. Zwecke entstehen.

### Internet der Dinge, M2M und Industrie 4.0

#### Internet der Dinge

Da viele Maschinen über Sensoren zur Erhebung von Zustandsdaten verfügen und diese Maschinen wiederum über Programme gesteuert werden, die selbstständig Entscheidungen treffen können, ist auch die autonome Kommunikation zwischen Maschinen (engl. **Machine-to-Machine** oder abgekürzt **M2M**) zu betrachten. Dank der Version 6 des Internet-Protokolls (IPv6) ist es möglich geworden, nicht nur Milliarden von Computern eindeutig zu adressieren und zu vernetzen, sondern auch alle mit IP-Zugang ausgestatteten „Dinge“ oder Maschinen, z.B Haushaltsgeräte, Heizungen in Wohnungen und Häusern (Smart Home), selbstfahrende Autos usw.

Unter dem **Internet der Dinge** wird das Verbinden von selbstständigen physischen Geräten mit dem Internet verstanden. Selbstständig bedeutet, dass die Geräte entweder selbstständig in der physischen Welt agieren bzw. Daten sammeln, im Internet über sie vertretende Programme agieren (Softwareagenten) oder selbstständig in beiden Welten agieren. Die letzte Variante, also Aktivität in der virtuellen und realen Welt, drückt der Begriff der **cyber-physischen Systeme (Cyber-Physical Systems)** aus.

Eine IP-Adresse und eine direkte Verbindung zum Internet ist oft nicht notwendig, sondern die von einem Sensor gesammelten Daten können zunächst an ein an das Internet angeschlossenes Gerät gesendet werden, z. B. über Bluetooth an ein Smartphone, von wo sie mit oder ohne Weiterverarbeitung an andere IS im Internet gelangen.

Die durch Sensoren entstehenden Daten können am Ort ihres Entstehens verarbeitet werden oder mit oder ohne Aggregation an zentralisierte Ressourcen (evtl. in einer Cloud) weitergegeben werden. Dort können sie integriert werden (z. B. mit Daten vieler anderer gleichartigen Maschinen). Daraus kann man evtl. neue Erkenntnisse gewinnen und Handlungsempfehlungen zurück an die Maschinen versenden.

#### Industrie 4.0
In Deutschland wurde für Anwendungen von IoT im industriellen Bereich der Begriff **Industrie 4.0** geprägt, der diese Entwicklung als die nächste Welle der Industrialisierung kennzeichnet (Kagermann et al. 2013). Die vier Wellen können wie folgt charakterisiert werden:

1. Mechanisierung
2. Elektrifizierung
3. Automatisierung mit IT
4. Vernetzung

Industrie 4.0 basiert auf den beschriebenen cyber-physischen Systemen. Produkte und Produktionsprozesse werden schon lange Zeit am Computer geplant und simuliert. Bei Industrie 4.0 wird nun sowohl der Produktionsprozess weiter kontinuierlich beobachtet als auch die Verwendung des Produkts. Die digitale Abbildung eines realen Systems wird als **digitaler Zwilling** bezeichnet. Sie erlaubt Berechnungen mit dem digitalen Zwilling, deren Ergebnisse dann automatisch zur Steuerung oder Wartung des realen Systems verwendet werden können. Abb. 5.8 zeigt diesen Zusammenhang.

\centerline{\includegraphics[width=1\textwidth]{img/indus4.png}}

Die Voraussetzungen für Industrie 4.0 sind u. a. die Realisierung einer geeigneten technischen Infrastruktur, Standardisierung der Kommunikationsprotokolle für die M2M-Kommunikation (da oft Maschinen und Geräte unterschiedlicher Hersteller zum Einsatz kommen), Verarbeitungskapazitäten für große Datenmengen, Sicherheit der Kommunikation und die Mitarbeiterakzeptanz. Akzeptant bedeutet in diesem Fall z. B. die Erlangung neuer Qualifikationen, Anpassung an neue Prozesse oder das Teilen des Arbeitsplatzes und Zusammenarbeit mit kleinen Robotern (Cobots), die ermüdende oder gefährliche Arbeitsschritte übernehmen.

*Fallbeispiel: Internet der Dinge in der Landwirtschaft*

Die Firma Claas, größter Hersteller von Mähdreschern in Europa, und die Deutsche Telekom betreiben in Sachsen-Anhalt ein Pilotprojekt.

Auf einem Feld voller Landmaschinen werden Informationen über die Fahrrichtung der Fahrzeuge, Fülle der Tankbehälter, Feuchtigkeit des Getreides usw. gesammelt. Sie werden von Sensoren der Fahrzeuge erhoben und per Mobilfunk an Rechner gemeldet. Diese verarbeiten die Daten und zeigen sie auf Bildschirmen der Fahrzeugfahrer an. Der Traktorfahrer kann dann rechtzeitig losfahren, um den vollen Korntank eines Mähdreschers im richtigen Moment zu leeren.

Die Verbesserung der Prozesse wird auf 10–15 % eingeschätzt. Weitere Geräte und Lokationen können leicht einbezogen werden, so dass alle Beteiligten sofort über Menge und Qualität informiert werden und sich bei Bedarf koordinieren können. Weitere Produktivitätsgewinne von bis zu 30 Prozent seien zu erwarten. Die gemeinsam entwickelte Plattform soll auch anderen Unternehmen angeboten werden. Die Landwirtschaft wird als ein gutes Versuchsfeld angesehen, weil in ihr viele Partner mit unterschiedlichen Maschinen agieren und stark vom Wetter abhängen.

# Teil 2: Gestaltung der Digitalisierung

## Kapitel 6: Mehr-Ebenen Betrachtung bei der Gestaltung

Kapitel 6 orientiert sich an der Einbettung von IS in den fachlichen und strategischen Zusammenhang in Unternehmen. Es beschreibt typische multidimensionale Gestaltungsansätze, wie sie beispielsweise das Business Engineering mit den Ebenen Strategie, Organisation und IS vorsieht. Kapitel 6 liefert damit den Überblick für die ebenenbezogenen Detailbetrachtungen in den Kapiteln 7 bis 9.

Gestaltungsziele

* **Multidimensionalität**: Die Gestaltung von Anwendungen berücksichtigt systematisch die Wechselwirkungen zwischen fachlichen und technischen Gestaltungsaspekten. Dazu sind mehrere Gestaltungsebenen bzw. -sichten zu unterscheiden, die zur Sicherung der Konsistenz von Gestaltungsaktivitäten auf den einzelnen Ebenen integrativ bzw. wechselseitig miteinander verbunden sein sollten.
* **Formalisierung**: Die Gestaltung bzw. Konstruktion von Anwendungen soll systematisch erfolgen, und dabei bewährte sowie untereinander abgestimmte Ergebniskonstrukte/-artefakte verwenden. Das Einhalten vorgegebener Modellierungssprachen bzw. -notationen und die damit einhergehende Formalisierung reduziert die Beliebigkeit der Gestaltung und unterstützt die intersubjektive Verständigung – also das Verständnis zwischen verschiedenen Personen – über die Gestaltungsergebnisse.
* **Ergebnisorientierung**: Die Gestaltung von Anwendungen soll sich an den Anforderungen der Nutzer orientieren. Ergebnisorientierung bedeutet, dass der Mehrwert für den Nutzer im Vordergrund steht und nicht-mehrwertgenerierende Aspekte wegzulassen sind.
* **IT als „Enabler“**: Wie Teil 1 dieses Buchs gezeigt hat, gestalten Anwendungen die Aufgaben von Organisationen nicht nur durch (Teil-)Automatisierung rationeller, sondern tragen durch ihre Rolle als „Ermöglicher“ neuer oder verbesserter Lösungen auch zur Differenzierung im Wettbewerb sowie zur Gewinnsteigerung bei.

Ein wichtiges Gestaltungsziel der Wirtschaftsinformatik ist die Integration im Sinne einer Abstimmung aller Gestaltungselemente, um die Effizienz des betrachteten Gesamtsystems zu erhöhen. In der Realität besteht aufgrund der zahlreichen abzustimmenden Gestaltungselemente (z. B. Nutzergruppen, Geschäftsprozesse, Endgeräte) und den zwischen ihnen bestehenden Abhängigkeiten eine hohe Komplexität.
### Gestaltungansätze

**Gestaltungsansätze** zielen auf eine Reduktion der Gestaltungskomplexität. Häufig als *Methode* bezeichnet, beschreiben sie zeitliche und inhaltliche Abhängigkeiten zwischen Gestaltungsaktivitäten und den dabei verwendeten Modellen bzw. Artefakten.

In der Praxis sind zahlreiche methodische Ansätze zur Spezifikation  fachlicher Zusammenhänge verbreitet. Eine leistungsfähige **Modellierungsmethodik** ist dabei von einem einfacheren **Modellierungsansatz** zu unterscheiden: Während ein Modellierungsansatz sprachliche Konstrukte zur Modellbildung (**Modellierungsobjekte/ Modellelementtypen**) sowie ein **Metamodell** (spezifiziert Modellierungsobjekte als Bausteine einer Modellierungssprache und deren Beziehungen) zur Gewährleistung eines abgestimmten Begriffssystems enthält, umfasst eine Modellierungsmethodik zusätzlich:

* Ein **Architekturmodell**, das Modellierungsebenen, Sichten und die Verwendungsmöglichkeit
von Submodellen zur Reduzierung der Modellkomplexität spezifiziert,
* Ein **Vorgehensmodell**, das die Aktivitätsfolge während der Modellierung vorgibt und
* **(Software-)Werkzeuge** zur Unterstützung der Modellerstellung und -pflege.

Die längste Tradition besitzen **Gestaltungsansätze im Rahmen der Softwareentwicklung** (z.B **Wasserfallmodell**). Mit Aufkommen von betriebswirtschaftlicher Standardsoftware ab den 1980er-Jahren hat sich jedoch gezeigt, dass die Softwareentwicklungsmethoden zwar von fachlichen Anforderungen ausgehen, nicht jedoch die **Gestaltung der Organisationsstrukturen** selbst im Fokus haben.

In den 1990er-Jahren sind daher Methoden des **Business Process (Re-)Design (BPR)** entstanden, die bestehende Organisationsstrukturen in Frage stellen und den Geschäftsprozess als Gestaltungsobjekt in den Vordergrund rücken. Nachdem integrierte Anwendungen Informationen über Organisationseinheiten hinweg bereitstellen und abteilungsübergreifende Abläufe ermöglichen, hat die Gestaltung der Ablauforganisation an Bedeutung gewonnen. Gemäß der Ergebnisorientierung geht es dabei nicht primär um die Unterstützung der intern in einem Unternehmen durchgeführten Funktionen (und der Orientierung an Suboptima einzelner funktionaler Bereiche), sondern um das Zusammenwirken aller Funktionen im Rahmen eines Ablaufs, dessen Nutzen einen Wertbeitrag beim (internen oder externen) Kunden bildet (s. Abb. 6.2). Zur Überwachung der Leistung von Prozessen dienen Messgrößen/Kennzahlen sowie eigene Zuständigkeiten und Aktivitäten der Prozessführung (s. Abschn. 7.5 und 8.5), welche auf die Bewertung, Steuerung und Kontrolle von Unternehmen ausgerichtet sind.

\centerline{\includegraphics[width=1\textwidth]{img/porient.png}}

**Geschäftsprozess** Ein Geschäftsprozess ist eine logisch zusammenhängende Kette von Aktivitäten, die in einer vorgegebenen Ablauffolge durchzuführen und auf die Erzeugung einer bestimmten Prozessleistung ausgerichtet sind. Ausgelöst durch ein definiertes Ereignis transformieren Prozesse bestimmte Einsatzgüter (Input) unter Beachtung bestimmter Regeln und durch Einsatz verschiedener Ressourcen zu Arbeitsergebnissen (Output).

Ein idealtypisches Vorgehen bei der (Neu-)Gestaltung betrieblicher Strukturen verläuft **Top-down** von der Unternehmensstrategie hin zur Implementierung eines konkreten IS (s. Tab. 6.1). Es legt bereits zu Beginn die Zielstellung und die wichtigsten Elemente des geplanten Systems fest und detailliert diese im weiteren Verlauf der Entwicklung.

\centerline{\includegraphics[width=1\textwidth]{img/bpr.png}}

Grundsätzlich können die Veränderungsmaßnahmen nicht nur Top-down von den übergeordneten Themenstellungen der Strategieebene, sondern auch von der Fachseite auf Organisationsebene (z. B. Realisierung effizienterer Bestellprozesse) sowie **Bottom-up** von der IT getrieben sein. Im letzteren Falle sind beispielsweise die Einführung einer neuen betriebswirtschaftlichen Standardsoftware oder das Aufkommen disruptiver Technologien (d. h. neue technologische Entwicklungen, die bestehende Technologien ersetzen, wie z. B. Blockchain , Big Data oder künstliche Intelligenz).

Mit dem BPR sind Ansätze der **kontinuierlichen (Prozess-)Verbesserung (Continuous (Process) Improvement (CI))** entstanden. Das CI geht von der Idee aus, dass grundlegende Neugestaltungen im Sinne des BPR nur periodisch stattfinden sollten, und dazwischen eine kontinuierliche Verbesserung der entworfenen Strukturen durchzuführen ist.

Nach den Ansätzen zur Softwareentwicklung und zur Prozessentwicklung sind in den 2000er-Jahren die **Gestaltungsansätze für die Geschäftsmodellentwicklung** entstanden. Im Mittelpunkt dieser Ansätze stehen die Identifikation und Modellierung neuer IT-basierter Geschäftsmodelle, wobei aufgrund des innovativen Charakters dieser Aufgaben die Einbeziehung kreativer Elemente von Bedeutung ist. Zur Erarbeitung derartiger Lösungen hat sich das **Design Thinking** (s. Abb. 6.3) etabliert, das Prinzipien agiler Softwareentwicklungsmethoden mit Kreativitätstechniken verbindet. Das Ergebnis dieses Ansatzes ist jedoch keine fertiggestellte Software, sondern ein testbarer Prototyp als Basis für (weitere) Diskussionen und Konkretisierungen des Geschäftsmodells.

\centerline{\includegraphics[width=1\textwidth]{img/designthinking.png}}

### Gestaltungebenen

Der **Business Engineering (BE)-Ansatz** unterscheidet drei Gestaltungsebenen:

* Die **Strategieebene** legt für ein Unternehmen die strategischen Eckpunkte fest. Dazu zählen etwa die Identifikation der Prozessvision, die Positionierung im Wettbewerb (Märkte und Leistungen) oder die Zusammenarbeit mit Partnern und die entsprechenden Werte-/ Leistungsflüsse. Daneben liefert die Strategieebene den Ausgangspunkt für die Prozessführung, indem sie aus den Zielstellungen der Kunden und den daraus abgeleiteten kritischen Erfolgsfaktoren die strategischen Führungsgrößen Kennzahlen für das **Prozesscontrolling (Process Performance Management)** ableitet.
* Die **Organisationsebene** konkretisiert die auf strategischer Ebene festgelegten Strukturen und unterscheidet grundsätzlich zwischen der Prozessgestaltung und der Prozessführung. Die Prozessgestaltung besteht aus dem fachlichen Prozessentwurf und unterscheidet wiederum die Gestaltung der Ablauf- und der Aufbauorganisation (Prozesse), Aufbaustrukturen. Seitens der Ablauforganisation bringen Prozessmodelle die abstrakteren Modelle der Strategieebene in einen zeitlichen Zusammenhang und ordnen die Aktivitäten den verschiedenen ausführenden Organisationseinheiten (Stellen, Verantwortlichkeiten, Organisationseinheiten) zu.
* Die IS-Ebene spezifiziert, welche softwaretechnischen Bausteine (Anwendungen und „technische Services“) zur Unterstützung von Geschäftsprozessen und -modellen zum Einsatz kommen. Ein zentrales Gestaltungsziel auf IS-Ebene bildet die Abstimmung mit den fachlichen Gestaltungsebenen im Sinne eines Business-/IT-Alignment bzw. Strategic Alignment. Weitere Ziele bilden die Transparenz und Vereinfachung sowie die Flexibilität bzw. Agilität und die Wiederverwendung fachlicher Bausteine/ Softwarekomponenten.

\centerline{\includegraphics[width=1\textwidth]{img/businessengi.png}}

Eine Ausdifferenzierung von Subebenen ist im Business Engineering auf IS-Ebene durch die Unterscheidung von einer Integrations-, einer Software- und einer Infrastrukturebene vorhanden. Weiterhin fasst z. B. das Framework von Zachman (2008) die Strategie- und die Organisationsebene zusammen, während die **Architektur integrierter Informationssysteme (ARIS)** als ein verbreiteter Strukturierungsansatz im deutschsprachigen Raum die Strategieebene nicht unmittelbar erwähnt. Die fünf Sichten von ARIS unterscheiden mit Steuerungs- (bzw. Prozess-), Daten-, Funktions-, Leistungs- und Organisationssicht ähnliche Elemente wie die Organisations- und IS-Ebene des BE (s. Abb. 6.4). Wechselwirkungen zwischen den Gestaltungsebenen zeigen sich etwa darin, dass Anwendungen die Voraussetzung für neue Geschäftsmodelle (z. B. Cloud Computing) liefern, oder innovative Geschäftsprozesse (z. B. das One Click Ordering von Amazon) einen strategischen Wettbewerbsvorteil unterstützen können.

Die Strategie- und Organisationsebene bilden auch den Ausgangspunkt für die *Prozessführung*. Diese leitet aus den strategischen Unternehmenszielen Führungsgrößen ab, die der Prozessmessung und -steuerung dienen. Die nächste Abbildung zeigt die Zuordnung von Beschreibungselementen/ Modelltypen der Strategie- und Organisationsebene (s. Abb. 6.4) zu diesen beiden Bereichen sowie deren Beziehungen.

\centerline{\includegraphics[width=1\textwidth]{img/65.png}}

## Kapitel 7: Strategieebene

Kapitel 7 beschreibt strategische Gestaltungsaspekte der digitalen Transformation. Hier zeigt sich, wie sich Kundenanforderungen mit den grundsätzlichen Fragen des Geschäftsmodells wie der Positionierung im Wettbewerb, den Partnerverflechtungen und den Leistungsbestandteilen modellhaft abbilden lassen. Neben der Gestaltung geht das Kapitel auf die Bedeutung von Unternehmenszielen als Basis für die Umsetzung der strategischen Prozessführung ein.

### Gestaltungsinhalte auf Strategieebene

Die Strategieebene legt in Abstimmung mit der allgemeinen Unternehmensstrategie die grundsätzliche Ausrichtung und Positionierung eines Unternehmens im Wettbewerb fest. Die strategische Positionierung umfasst einerseits die Entwicklung der Kundenvision, die Festlegung der relevanten Kundengruppen. Zum anderen bestimmt sie die eigenen Kernkompetenzen und die daraus resultierenden Produkt-/Leistungsangebote für den Kunden, die Identifizierung von Wertschöpfungspartnern und die Etablierung von Leistungsaustauschbeziehungen, die Grobkonzeptionierung der Prozessarchitektur sowie die Festlegung der strategischen Prozessführung. Zu den Modelltypen der Strategieebene zählen:

* Das **Kundenprozessmodell** beschreibt zunächst aus Kundensicht, welche Aktivitäten zur Lösung seiner Bedürfnisse zu durchlaufen und welche Vorleistungen von anderen Stakeholdern (z. B. Unternehmen) dafür erforderlich sind. Ein Unternehmen kann daraus ableiten, welche Aktivitäten des Kundenprozesses es mit seinem Leistungsprogramm adressieren/unterstützen möchte.
* Das **Geschäftsmodell** spezifiziert die Positionierung des Unternehmens im Markt. Es enthält Informationen zum Geschäftszweck/ Kundennutzen, den Kernressourcen/-aktivitäten und zu den finanziellen Konsequenzen des Geschäftsbetriebs. Zusätzlich bildet das **Geschäftsnetzwerkmodell** das Zusammenwirken von Unternehmen in einem Geschäfts- bzw. Wertschöpfungsnetzwerk im Sinne einer Geschäftsarchitektur ab.

Die **strategische Prozessführung (Process Performance Management/Prozesscontrolling)** bildet die für ein Unternehmen festgelegten strategischen Ziele und die davon abgeleiteten (kritischen) Erfolgsfaktoren sowie strategischen Führungsgrößen/ Kennzahlen ab und stellt sicher, dass die Gestaltung des fachlichen Entwurfs den geschäftlichen (Ziel-)Vorgaben folgt.
### Kundenprozessmodell

Ausgangspunkt zur Identifikation der (künftig) angebotenen Leistungen eines Unternehmens sind die Bedürfnisse der Zielkunden als wesentliche Stakeholder eines Unternehmens, die sich in Kunden- bzw. Verwendungsprozessen niederschlagen. Das **Kundenprozessmodell** spezifiziert die Aktivitäten beim Kunden und die benötigten Leistungsbestandteile zur Deckung eines komplexen Kundenbedürfnisses für ein Kundensegment. Ziel ist die Zuordnung der aus Kundensicht nachgefragten zu den aus Unternehmenssicht angebotenen Leistungen.

Zu den möglichen Segmentierungsdimensionen zählen:

* Die **Phase des Kundenprozesses**, wonach sich die Kunden in einer Anforderungs-, Akquisitions-, Besitz- oder Entsorgungsphase befinden können. Beispielsweise unterscheiden sich dadurch Neu- und Bestandskunden.
* Der *Lebensabschnitt des Kunden*, wonach sich Kundenbedürfnisse an bestimmten „Life Events“, wie Schulabschluss, Berufsanfang, Firmengründung etc. orientieren.
* Der **Kundenwert (Customer Lifetime Value)** bewertet Kunden nach ihrem getätigten und ihrem zukünftigen Geschäftsvolumen. Ein Beispiel für die Verwendung des Kundenwertes ist die Segmentierung von Kunden im Rahmen von Loyalitätsprogrammen.
* Die **Rolle im Wertschöpfungsprozess**, z. B. ausgehend von Privatkunden (Business-to-Consumer) und Geschäftskunden (Business-to-Business) in Händler, Endkunden etc.
* Die **Region des Kunden**, wonach insbesondere international agierende Unternehmen zusätzlich nach lokalen, nationalen oder globalen Kunden segmentieren.

In Kundenprozessmodellen sind häufig einerseits die Aktivitäten auf Kundenseite (rechter Bereich in Abb. 7.1) und andererseits die korrespondierenden Aktivitäten innerhalb des Unternehmens (linker Bereich in Abb. 7.1) aufgeführt.

\centerline{\includegraphics[width=1\textwidth]{img/71.png}}

Abb. 7.1 setzt das Uhren-Beispiel fort. Für den Kundenprozess „Uhr kaufen“ zeigt es, welche Teilaspekte/Aktivitäten aus Kundensicht wichtig sind (z. B. Suche nach Uhrenmodellen, Preisvergleiche) und welche Teilaktivitäten der übergeordneten Leistungsprozesse „Herstellung von Uhren und Kaufabwicklung“ sowie „Kundenwerbung“ auf die Unterstützung der Kundenaktivitäten ausgerichtet sind und mit diesen in Leistungsaustauschbeziehung stehen (gestrichelte Kanten).

Für ausgewählte Gestaltungsaspekte lassen sich zusätzliche Modelle einsetzen. So ist angesichts der zahlreichen, für die Kundeninteraktion verfügbaren Kanäle eine abgestimmte Nutzung im Rahmen von Cross-Channel-Management-Ansätzen notwendig. Eine solche hybride Kundeninteraktion geht von einem Nebeneinander mehrerer Kanäle und einem Wechsel während einer Kundeninteraktion im Sinne von **Customer Journeys** aus. Diese beginnen beim ersten Auftreten eines Kundenbedürfnisses und erstrecken sich über das Informieren und Abwägen verschiedener Leistungsangebote, den Kauf von Produkten und/oder Dienstleistungen sowie dem nachfolgenden Aftersale-Service bis hin zu langfristigen loyalitätsfördernden Maßnahmen. Abb. 7.2 zeigt beispielhaft eine Customer Journey, die auf dem in Abb. 7.1 dargestellten Ablauf des Kundenprozesses aufbaut und den Aktivitäten die genutzten Interaktionskanäle zwischen Kunde und Unternehmen zuordnet.

\centerline{\includegraphics[width=1\textwidth]{img/72.png}}
### Geschäftsmodell und -netzwerk

Da in arbeitsteilig organisierten Wertschöpfungsstrukturen ein Unternehmen nicht alle Aufgaben selbst ausführt, entstehen Netzwerke von mehreren Unternehmen. Die Unternehmen ergänzen sich dabei idealerweise mit ihren Kernkompetenzen, wobei sich unterschiedliche generische Schwerpunkte für die Gestaltung erkennen lassen:

* **Position in der Wertschöpfungskette**: Wertschöpfungsnetzwerke lassen sich aus Unternehmenssicht in kunden- und lieferantenorientierte Abschnitte untergliedern. Die Leistungsrichtung hin zum Endkunden lässt sich als **Downstream** und jene hin zum (Rohstoff-) Lieferanten als **Upstream** bezeichnen.
* **Bündelungsgrad von Leistungen**: Unternehmen können sowohl Einzelaufgaben in einem Prozess übernehmen als auch Leistungen für einen Prozess bündeln.
* **Kompetenzen der Leistungserstellung**: Unternehmen vereinen Kompetenzen in den Bereichen Vertrieb, Produkt und Infrastruktur. Spezialisierung ist sinnvoll, weil die drei Bereiche unterschiedliche Ziele verfolgen: Während vertriebsorientierte Unternehmen die umfassende Abdeckung von Kundenbedürfnissen anstreben, ist dies bei produkt- und dienstleistungsorientierten Unternehmen die schnelle Entwicklung Know-how-intensiver Angebote und bei standardisierten Dienstleistungen die Bereitstellung einer effizienten Infrastruktur zur Realisierung von Mengeneffekten im Massengeschäft.

Durch die Kombination von Positionierung, Bündelungsgrad und Leistungserstellungskompetenzen lassen sich *Geschäftsmodelle* ableiten. Ein **Geschäftsmodell** spezifiziert die Geschäftslogik eines Unternehmens. Dieses umfasst u. a. den differenzierenden Geschäftszweck (**Value Proposition**), die beteiligten Akteure mit den sie verbindenden Leistungsflüssen sowie Angaben zu den finanziellen Konsequenzen.

Beispiele für mögliche, aus den drei genannten Schwerpunkten abgeleitete Geschäftsmodelle sind:

* **Schichtenspezialisten (Fokus auf bestimmte Wertschöpfungsstufen)** konzentrieren sich auf eine oder mehrere Wertschöpfungsstufen einer Wertkette und besitzen gegenüber anderen Wettbewerbern einen Wettbewerbsvorteil. Dieser Vorteil kann in einem Wissensvorsprung, in Größenvorteilen und/oder in spezifischen Eigentumsrechten liegen.
* **Pioniere (Fokus auf das Erweitern von Wertschöpfungsketten)** erweitern bestehende Wertketten um zusätzliche und innovative Wertschöpfungsstufen/Leistungen.
* **Orchestratoren (: Fokus auf Koordination der Akteure innerhalb einer Wertschöpfungskette)** koordinieren das Zusammenspiel von Leistungen und Akteuren über einen Teil oder die Gesamtheit der Wertschöpfungskette.
* **Integratoren (Fokus auf das Abdecken eines Großteils der Wertschöpfungskette)** sind für überwiegende Teile der Wertschöpfung entlang der Wertschöpfungskette selbst verantwortlich, wobei der Anteil von fremdbezogenen Leistungen gering bis nicht vorhanden ist. Von zentraler Bedeutung ist hierbei zum einen die Minimierung von Transaktionskosten zwischen den Wertschöpfungsstufen, um damit einen Wettbewerbsvorteil gegenüber den Orchestratoren zu erlangen oder zu behalten. Zum anderen muss ein Integrator jede Wertschöpfungsstufe so effizient gestalten, sodass er nicht gegenüber Schichtenspezialisten ins Hintertreffen gerät.

Zur strukturierten Darstellung von Geschäftsmodellen haben sich zahlreiche Methoden etabliert. Ein in der Praxis verbreiteter Ansatz ist die **Business Model Canvas**, welche die Gestaltungsdimensionen eines Geschäftsmodells in neun Bereiche untergliedert:

* Die **Kundensegmente** umfassen Personengruppen oder Organisationen, die ein Unternehmen mit seinen Produkten und Dienstleistungen erreichen möchte.
* Ein **Nutzenversprechen (Value Proposition)** stellt ein Bündel von Produkten und/oder Dienstleistungen dar, die für ein Kundensegment einen Nutzen stiften.
* Die **Kanäle** beziehen sich auf die Wege zur Kommunikation sowie zur Übermittlung der Produkte und Umsetzung der Dienstleistungen gegenüber den Kundensegmenten.
* Die **Kundenbeziehungen** umfassen die Beziehungen, die ein Unternehmen mit seinen Kundensegmenten besitzt bzw. aufbauen möchte. Dies reicht von Informationsangeboten (z. B. über eine Webseite oder E-Mail-Newsletter) über persönliche Beratung (z. B. Hotlines), Self-Service-Angeboten (z. B. Überweisung per Online Banking) und dem Betreuen von Communities (z. B. zur Verprobung neuer Produktideen) bis hin zum gemeinsamen Entwickeln und Gestalten neuer Produkte und Dienstleistungen (Co-Creation).
* Die **Schlüsselressourcen** beschreiben die wichtigsten materiellen (z. B. Maschinen) und immateriellen (z. B. Patente, Mitarbeiterwissen) Güter und Fähigkeiten (Assets) einer Organisation zur Umsetzung des Geschäftsmodells.
* Die **Kernaktivitäten** sind die wichtigsten Aktivitäten und Prozesse zur Umsetzung des Geschäftsmodells.
* Die **Schlüsselpartnerschaften** beschreiben die wichtigsten Zulieferer und sonstigen Partner im Wertschöpfungsnetzwerk.
* Die **Erlösquellen** beschreiben die finanziellen Rückflüsse von Seiten der Kundensegmente für gelieferte Produkte und geleistete Dienstleistungen inklusive der quantitativen Kalkulation von Verkaufspreisen und Verkaufsmengen.
* Die **Kostenstruktur** umfasst die wesentlichen Kostenpositionen zur Umsetzung des Geschäftsmodells.

Eine Möglichkeit zur Modellierung von Geschäftsnetzwerken ist die in Abb. 7.3 verwendete **e3Value-Notation**. Darin stellen Rechtecke mit spitzen Ecken einen oder mehrere Akteure (Actors), Rechtecke mit abgerundeten Ecken die zentralen Aufgabenbereiche, die Kanten (bzw. Verbindungslinien) die Wertflüsse/Leistungsübergänge (Value Exchanges), die ovalen Symbole die Leistungsschnittstellen (Value Interfaces) mit den gerichteten Kanten (Pfeile) und die roten Punkte Startereignisse (einfacher Kreis) oder Endereignisse (Doppelkreis) dar.

\centerline{\includegraphics[width=1\textwidth]{img/73.png}}

In Abb. 7.3 ist zu erkennen welche Leistungsaustauschbeziehungen notwendig sind, um ausgehend von einem Kundenwunsch eine Uhr zu fertigen und schließlich an den Uhren-Kunden auszuliefern. Dies betrifft zum einen durch den Kunden ausgelöste Austauschbeziehungen (z. B. Spezifikation der Anforderungen an die Ausstattung und Gestaltung der Uhr), die sich daran anschließenden und bei den Unternehmen ablaufenden Leistungsaustausche (z. B. Bestellung von Komponenten) sowie im Vorfeld angesiedelte Interaktionsbeziehungen (z. B. Übermittlung von Sortimentslisten von Zulieferern als Basis für die Zusammenstellung der Uhrenmodelle). Im Rahmen der Kaufabwicklung ist neben den Akteuren (Lieferanten, Uhrenhersteller, Uhren-Onlinehändler) noch eine Auskunftei (z. B. Schufa) als externer Dienstleister zur Beurteilung der Kundenbonität beteiligt.

### Strategische Prozessführung

Das Unternehmen hat sicherzustellen, dass die Gestaltungsaktivitäten auch zu den angestrebten Zielen führen. Zur Entwicklung der fachlichen Vorgaben entlang der strategischen Vorgaben umfasst die strategische Prozessführung (s. Abb. 6.4) zunächst eine genauere Beschreibung von aus der allgemeinen Unternehmensstrategie/dem Geschäftsmodell abgeleiteten **Organisationszielen** sowie die diesen Zielen zuzuordnenden **kritischen Erfolgsfaktoren**. Allerdings sind die kritischen Erfolgsfaktoren (z. B. hohe Kundenbindung, differenziertes Uhrenangebotsportfolio) häufig auf hohem Abstraktionsniveau formuliert und daher nicht direkt messbar. Sie erfordern daher eine Operationalisierung in Form eines detaillierten und konsistenten Systems von **strategischen Führungsgrößen** (Messgrößen), mit denen sich Geschäftsprozesse hinsichtlich der Zielerreichung gegenüber strategischen Vorgaben messen und steuern lassen.

* **Organisationsziele** definieren die langfristige Richtung der betrieblichen Aktivitäten, ohne unmittelbar umsetzbar zu sein. Beispiele für diese unternehmensstrategischen Ziele sind die Erhöhung der Kundenzufriedenheit oder eine größere Innovationskraft.
* **Kritische Erfolgsfaktoren (KEFs)** konkretisieren die (langfristigen) Organisationsziele und beschreiben gewünschte/notwendige Eigenschaften und Fähigkeiten einer Organisation , z.B. durch kürzere Fristigkeit, durch Bezug zu aktuellen Lösungen und/oder durch Quantifizierung.
* **Führungsgrößen - Key Performance Indicators (KPI)** sind Messgrößen, die den Umsetzungsgrad einzelner Erfolgsfaktoren quantitativ bewerten, d.h. sie operationalisieren einen Erfolgsfaktor durch eine konkrete Messbarkeit der Zielerreichung. Hierbei ist zwischen den übergeordneten strategischen Führungsgrößen (z. B. durchschnittliche Auftragsdurchlaufzeit von Bestellung bis Auslieferung) und den daraus abgeleiteten Prozessführungsgrößen (z. B. durchschnittliche Wartezeit zwischen Produktionsende und Versand) zur unmittelbaren Beurteilung der Prozessleistung zu unterscheiden. Sollwerte bzw. Prozessziele sorgen für eine weitere Konkretisierung, indem sie die Führungsgrößen um eine Zielvorgabe für einen bestimmten Zeitraum ergänzen (z. B. soll die durchschnittliche Wartezeit eines Artikels zwischen Produktionsende und Versand weniger als ein Tag betragen). Führungsgrößen lassen sich in finanzielle (Prozesskosten oder Umsatz) und direkte Führungsgrößen (z. B. Auftragsabwicklungszeit, Antwortzeit auf Kundenanfragen, Nutzungsanteil von Online-Kanälen) unterscheiden.

Abb. 7.4 zeigt die Beziehungen zwischen Organisationszielen, kritischen Erfolgsfaktoren und Führungsgrößen in Form einer **Balanced Scorecard**. Balanced Scorecards sind aufgrund ihrer Berücksichtigung von nichtfinanziellen sowie zukunfts- und potenzialorientierten Zielen eine Weiterentwicklung traditioneller Controllinginstrumente. Die Bezeichnung „Balanced“ bezieht sich darauf, dass die einzelnen Zieldimensionen ausbalanciert sein sollen und für jede Zieldimension Führungsgrößen definiert sind, also keine Zielkategorie unberücksichtigt bleibt.

\centerline{\includegraphics[width=1\textwidth]{img/74.png}}

## Kapitel 8: Organisationsebene

Kapitel 8 fokussiert mit der Organisationsebene auf die Prozessgestaltung und die operative Prozessführung als Bindeglied zwischen der strategischen Unternehmensgestaltung und der technischen Implementierung (IS-Ebene).

### Gestaltungsziele auf Organisationsebene

Die **Organisationsebene** konkretisiert die Umsetzung der Strategieebene. Dies bezieht sich einerseits auf die in der **Ablauforganisation** zusammengefassten und miteinander in Beziehung stehenden Prozesse. Andererseits ist auch die anschließend erfolgende Gestaltung der **Aufbauorganisation** (einschließlich der Definition von Verantwortlichkeiten, Stellen und Organisationseinheiten) als zweiter wesentlicher Baustein auf der Organisationsebene angesiedelt. Neben der Spezifikation von Sequenz und Leistungsflüssen zwischen Aktivitäten und Prozessen adressiert die organisatorische Gestaltung somit auch die konkrete Umsetzung der auf strategischer Ebene grob vorgegebenen Austauschbeziehungen zwischen einzelnen inner- und überbetrieblichen Einheiten der Aufbauorganisation.

Ausgangspunkt der Prozessmodellierung ist die Beschreibung des Zusammenspiels der Geschäftsprozesse in einer Prozesslandkarte sowie in Prozesskontextdiagrammen (s. Abschn. 8.2). Darauf aufbauend konkretisiert die Leistungsanalyse (s. Abschn. 8.2) die Prozessleistungen hinsichtlich ihrer Bestandteile sowie der (Prozess-)Kunden und eingesetzten Distributions- bzw. Zugangskanäle. Die eigentliche Ablaufplanung (s. Abschn. 8.3) mit Hilfe der Prozessmodellierung ergänzt Abschn. 8.4 um die Ableitung aufbauorganisatorischer Strukturen. Die operative Prozessführung (s. Abschn. 8.5) schließlich leitet aus strategischen Führungsgrößen konkrete Prozessführungsgrößen ab. Auf Basis der Prozessführung und -messung ist schließlich eine kontinuierliche Prozessverbesserung (s. Abschn. 8.6) im Sinne des CI (s. Abschn. 6.1) anzustreben.

### Prozess- und Leistungsüberblick

Während der Kundenprozess die Abläufe aus Sicht des Kunden (**Outside-In**) betrachtet, geht die Prozessanalyse des Unternehmens von den eigenen Abläufen (**Inside-Out**) aus. Neben Kundenprozessen sind hier drei weitere Prozesstypen zu nennen:

* **Leistungsprozesse** - **Kernprozesse** - **Geschäftsprozesse im engeren Sinne** liefern einen direkten Beitrag zur Wertschöpfung eines Unternehmens. Sie erzeugen Leistungen “nach außen”, d. h. für Kunden.
* **Unterstützungsprozesse** ergänzen die Leistungsprozesse durch Erzeugung von Vorleistungen.
* **Führungsprozesse** überwachen und bewerten die Umsetzung von Leistungs- und Unterstützungsprozessen mit Hilfe quantitativer Führungsgrößen und greifen bei Bedarf steuernd ein. Weiterhin dienen Führungsprozesse der Anpassung und Weiterentwicklung der strategischen und operativen Prozessführung.

\centerline{\includegraphics[width=1\textwidth]{img/81.png}}

Die **Prozesslandkarte** liefert einen Überblick zu den übergeordneten Prozessen/Prozessbereichen in einer Organisation. Sie ordnet den aus dem Geschäftsnetzwerk benannten Akteuren die wichtigsten Prozesse zu und verbindet diese mittels Leistungsflüssen. Das obige Beispiel zeigt die übergeordneten Prozesse eines Unternehmens und die Einbettung der unternehmerischen Führungs-, Leistungs- und Unterstützungsprozesse in die unternehmensübergreifenden Wertschöpfungsketten/Prozessstrukturen. Hierbei bestehen insbesondere Beziehungen zwischen den unternehmerischen Leistungsprozessen in Richtung der wertschöpfungsseitig vorgelagerten Leistungsprozesse der Lieferanten (**Upstream**) und den nachgelagerten Kundenprozessen (**Downstream**).

Für das Uhren-Beispiel illustriert Abb. 8.2 eine mögliche Prozesslandkarte. Zur Vereinfachung enthält dieses Modell nur eine integrierte Betrachtung ausgewählter Führungs-, Leistungs- und Unterstützungsprozesse des Uhrenherstellers und des Uhren-Onlinehändlers ohne Berücksichtigung der Kunden- und Lieferantenprozesse.

\centerline{\includegraphics[width=1\textwidth]{img/82.png}}

Für eine genauere Analyse der in der Prozesslandkarte enthaltenen Prozessbereiche dient eine detaillierte Betrachtung der Wechselwirkungen/Leistungsverflechtungen von Prozessen mit ihren vor- und nachgelagerten sowie parallel ablaufenden Umfeld-Prozessen. Die dazu verwendeten **Prozesskontextdiagramme** (s. Abb. 8.3) dienen als Grundlage für die spätere Verfeinerung der Prozessbeschreibungen und detaillieren die auf Strategieebene im Geschäftsnetzwerkmodell grob beschriebenen Leistungen. In
Abb. 8.3 sind für das Uhren-Beispiel die Leistungsverflechtungen des Leistungsprozesses „Herstellung von Uhren und Kaufabwicklung“ sowohl mit dem Kundenprozess „Uhr kaufen“ als auch mit drei weiteren Leistungsprozessen als Prozesskontextdiagramm dargestellt.

\centerline{\includegraphics[width=1\textwidth]{img/83.png}}

Zumeist ist es sinnvoll, die durch einen Prozess erzeugten Leistungen bezogen auf Leistungsbestandteile (einzelne Elemente einer Leistung) und Leistungsmerkmale (Eigenschaften der Leistungsbestandteile) genauer zu spezifizieren. Ein sog. **Leistungsverzeichnis** fasst zusätzliche Informationen zu den Leistungen, wie etwa adressierte Kundensegmente, geeignete Distributions- bzw. Zugangskanäle, grundlegende Qualitätsmerkmale, technische Produktspezifikationen bzw. finanzielle Kennzahlen, dazu zusammen.

Bei der Spezifizierung der Leistungscharakteristika ist auch zu beurteilen, welche Bedeutung die Leistungsbestandteile/-merkmale für den jeweiligen Prozesskunden haben und wie ihre Qualität insbesondere im Vergleich zu wichtigen Konkurrenten einzuschätzen ist. Abb. 8.4 zeigt links ein solches **Qualitätsprofil** für ausgewählte Leistungen des Prozesses „Herstellung von Uhren und Kaufabwicklung“ im Uhren-Beispiel.

\centerline{\includegraphics[width=1\textwidth]{img/84.png}}

### Ablaufplanung

Während die Leistungsplanung eine Konkretisierung der stattfindenden Warenflüsse oder Kommunikationsbeziehungen aus Sicht eines Prozesses darstellt, detailliert die Ablaufplanung die Betrachtung der Prozessaktivitäten über die Zeit.

Die **Ablaufplanung** zerlegt die Erstellung der Prozessleistungen sukzessive in feinere Teilschritte. Nach dem Detaillierungsgrad ist zwischen einer **Ablaufplanung im Groben (Makro-Planung)** und einer **Ablaufplanung im Detail (Mikro-Planung)** zu unterscheiden.

#### Makro-Ablaufplanung

Die **Makro-Planung** löst die Prozesslandkarte in einzelne Geschäftsprozesse mit ihren Schnittstellen zu anderen Prozessen auf. Abgeschlossen ist die Makro-Planung, wenn ein Überblick über den gesamten Prozess besteht und eine für das Entwurfsteam und die Prozessbeteiligten ausreichende Verfeinerung gegeben ist.

Abb. 8.5 zeigt für das Uhren-Beispiel, dass der auf der ersten Modellierungsebene angesiedelte übergeordnete Leistungsprozess „Herstellung von Uhren und Kaufabwicklung“ auf der zweiten Modellierungsebene aus acht Subprozessen besteht, die nacheinander auszuführen sind. Jeder dieser Subprozesse ist auf weiteren Modellierungsebenen in weiter detaillierte Subprozesse zerlegbar.

\centerline{\includegraphics[width=1\textwidth]{img/85.png}}

#### Mikro-Ablaufplanung und Workflows

Die Ergebnisse der Grob-Ablaufplanung dienen als Grundlage für die sich anschließende **Ablaufplanung im Detail (Mikro-Planung)**, welche die in der Grobablaufplanung benannten Prozesse auf weiteren Modellierungsebenen spezifiziert. Sind Prozessmodelle bis zu den elementaren Aktivitäten auf der Ausführungsebene spezifiziert, so spricht man bei diesem Detaillierungsgrad nicht mehr von **Prozessmodellen**, sondern von sogenannten **Workflowmodellen**.

Ein **Workflow** ist ein formal beschriebener, ganz oder teilweise automatisierter Prozess, der die zur automatischen Steuerung des Arbeitsablaufs auf operativer Ebene notwendigen zeitlichen, fachlichen und ressourcenbezogenen Spezifikationen beinhaltet.

Workflowmodelle fokussieren gegenüber Prozessmodellen weniger auf die fachlich orientierte Gestaltung von Aktivitätsabfolgen, sondern stärker auf deren schrittweise und (teil-)automatisierte Umsetzung.

\centerline{\includegraphics[width=1\textwidth]{img/86.png}}

#### Prozessmodellierungssprachen am Beispiel eEPK und BPMN

Für die Prozessmodellierung sind eine Vielzahl von semi-formalen Notationen/Modellierungssprachen entstanden, wobei nachfolgend aufgrund ihrer Verbreitung in der Praxis **BPMN** und **EPK** näher beschrieben sind. Wie unten dargestellt, umfassen beide Prozessmodellierungssprachen bzw. -notationen vergleichbare Darstellungselemente und erfüllen daher ähnliche Zwecke.

\centerline{\includegraphics[width=1\textwidth]{img/epk1.png}}
\centerline{\includegraphics[width=1\textwidth]{img/epk2.png}}

Die **Business Process Model and Notation (BPMN)** umfasst mit dem *Konversationsdiagramm*, dem *Choreografiediagramm* und dem *Kollaborationsdiagramm* drei Modelltypen, wobei die ersten beiden den Nachrichtenaustausch zwischen verschiedenen Akteuren wiedergeben. Das in der Praxis am häufigsten angewendete Kollaborationsdiagramm stellt dabei Aktivitätsfolgen/Prozessflüsse mit Beteiligung von einem oder mehreren Akteuren dar. Vorteile von BPMN sind die Ausdrucksmächtigkeit durch die große Anzahl an Modellierungsobjekten sowie die Möglichkeit zur Überführung von Kollaborationsdiagrammen in technisch-orientierte Workflowspezifikationen (z. B. mittels der *Business Process Execution Language (BPEL)*).

Abb. 8.7 beschreibt für das Uhren-Beispiel den Prozess „Uhrenauswahl und Bestellung“ in grober Form als BPMN-Kollaborationsdiagramm. Die in Abb. 8.7 benutzte BPMN-Notation symbolisiert mit einem Kreuz innerhalb des Prozessschrittes „Konfiguration des Basis-Uhrenmodells“, dass sich dieser Prozessschritt aus weiteren Teilschritten/Aktivitäten zusammensetzt. Diese sind wiederum als (Mikro-)Ablaufmodell in einem separaten BPMN-Modell (s. Abb. 8.8) verfeinert. Da der übergeordnete Prozessschritt „Konfiguration des Basis-Uhrenmodells“ in Abb. 8.7 organisatorisch dem Uhren-Kunden zugeordnet ist, gilt dies auch für alle seine Teilschritte bzw. Aktivitäten in Abb. 8.8. Das verfeinerte Ablaufmodell in Abb. 8.8 beginnt daher nach dem erfolgreichen Abschluss des vorgelagerten Prozessschrittes „Suche nach einem Basis-Uhrenmodell“ (s. Abb. 8.7) und das Startereignis ist in Abb. 8.8 mit „Basis-Uhrenmodell ist ausgewählt“ angegeben.

\centerline{\includegraphics[width=1\textwidth]{img/87.png}}
\centerline{\includegraphics[width=1\textwidth]{img/88.png}}

Neben BPMN ist insbesondere bei Unternehmen im deutschsprachigen Raum der Ansatz der **Architektur integrierter Informationssysteme (ARIS)** verbreitet. Wie in Abschn. 6.1 und Abb. 6.3 erwähnt, umfasst der ARIS-Ansatz fünf Sichten: Die *Funktionssicht* stellt dabei die hierarchischen Beziehungen zwischen den betrieblichen Funktionen und Unterfunktionen dar. Die *Organisationssicht* enthält die aufbauorganisatorische Struktur, die *Leistungssicht* die materiellen sowie immateriellen Input- und Output-Leistungen und die *Datensicht* die betriebswirtschaftlich relevanten Informationsobjekte (z. B. Angebot, Auftrag, Rechnung). Die *Steuerungs- bzw. Prozesssicht* enthält den eigentlichen Ablauf in Form **Ereignisgesteuerter Prozessketten (EPK)**. Im Kern bestehen diese aus einer Folge von:

* Elementaren Ereignissen sowie
* elementaren (fachlichen oder technischen) Funktionen.

Ein oder mehrere Funktionen lösen danach eine Funktion aus, die wiederum ihrerseits ein oder mehrere Ereignisse initiiert. In diese Abfolge von Funktionen und Ereignissen fließen die Spezifikationen der Daten-, Leistungs- und Organisationsicht ein, indem eine Zuordnung der Informations-, Material- bzw. Ressourcenobjekte sowie die beteiligten Organisationseinheiten zu den Funktionen erfolgt. Eine derart mit Informationen aus den anderen Sichten angereicherte EPK heißt dann **erweiterte EPK (eEPK)**. Falls mehrere Ereignisse eine Funktion auslösen oder eine Funktion mehrere Ereignisse auslöst, spezifiziert ein Konnektor die Auslösungslogik. Die zulässigen Varianten der Ereignis-Funktions- Verknüpfung mittels Konnektoren fasst Abb. 8.9 zusammen. *eEPK-Modelle besitzen gegenüber BPMN-Kollaborationsdiagrammen einen geringeren Sprachumfang und sind rein auf die fachliche Betrachtung von Prozessen ausgelegt.*

\centerline{\includegraphics[width=1\textwidth]{img/89.png}}

Die nächste Abbildung zeigt den Ablauf des Leistungsprozesses „Zusammenstellung Uhrenmodelle“ aus der Prozesslandkarte des Uhren-Beispiels (s. Abb. 8.2) als eEPK-Modell mit beteiligten Organisationseinheiten und jeweils benötigten bzw. erstellten Informationsobjekten.

\centerline{\includegraphics[width=1\textwidth]{img/810.png}}

Neben Modellen in eEPK- und BPMN-Notation kommen zur Prozessmodellierung auch Notationen aus dem Bereich der Softwareentwicklung zum Einsatz. Dazu zählen *Aktivitätsdiagramme*, *Sequenzdiagramme* und *Use Case-/Anwendungsfall-Diagramme*, wie sie in der Modellierungssprache **UML** enthalten sind.

#### Aktuelle Entwicklungen

Die Ansätze zur Organisations- bzw. Prozessmodellierung haben in den vergangenen Jahren Weiterentwicklungen in verschiedene Richtungen erfahren. Dazu zählen die Prozesssimulation, das Process Mining, die Modellierung von Entscheidungsregeln sowie die robotergesteuerte Automatisierung von Prozessen.

Bei der **Prozesssimulation** ergänzen Mengen- und Zeitgerüste die Prozessmodelle für quantitative Analysen und Simulationen des Prozessablaufs. Diese initialen Vorgaben enthalten z. B. Informationen zur prognostizierten Häufigkeit von Aktivitäten/Prozessen, zu den erwarteten Durchlauf- und Transportzeiten, zu aktivitätsbedingten Kostensätzen und zu Ressourcenkapazitäten.

Das **Process Mining** nutzt einen Bottom-up-Ansatz, da es von den in der Vergangenheit real abgelaufenen Anwendungs-gestützten Prozessen ausgeht. Process-Mining-Werkzeuge, wie etwa ARIS PPM, Celonis, Disco oder ProM, ermitteln aus Protokolldateien (Log Files) historischer Prozessinstanzen die aufgetretenen Varianten in der Aktivitätsabfolge und führen weitere quantitative Analysen durch (z. B. Bestimmung von Häufigkeiten für Prozessvarianten). Aus den tabellarisch oder auch in Form von grafischen Modellen (z. B. Prozessmodelle, **Organigramme**) aufbereiteten Ergebnissen lässt sich etwa die Reihenfolge der durchlaufenen Aktivitäten jeder einzelnen Prozessinstanz herauslesen, welche Organisationseinheiten/Rollen/Mitarbeiter beteiligt waren, wie lange die Aktivitäten gedauert oder welche Prozessinstanzen zum gewünschten Ergebnis geführt haben. In der Gesamtheit liefern Process-Mining-Analysen Hinweise auf Problembereiche und Ansatzpunkte für zukünftige Prozessveränderungen in der Ablaufplanung.

Einen weiteren Entwicklungsschritt bildet die Modellierung von **Entscheidungsregeln (Business Rules)**. Dieser entstand aus der Beobachtung, dass Entscheidungssituationen in Prozessen häufig vorkommen und diese einfach veränderbar sein sollen. Das *Business Rules Management* zielt daher auf separate und damit schnell anpassbare Abbildung von Entscheidungsregeln. Die **Decision Model and Notation (DMN)** ist eine standardisierte Sprache zur Modellierung von Entscheidungsregeln im Prozessmanagement und unterstützt auch deren automatisierte Verarbeitung. Die Basis der DMN bildet das **Decision-Requirements-Diagramm**, das Entscheidungen zusammen mit den hierfür benötigten Hilfsmitteln/Informationen in grafischer Form darstellt.

Die nächste Abbildung zeigt ein solches Diagramm für die Entscheidung „Gutschein für Uhren-Kunden auswählen“. Diese **Entscheidung** (dargestellt als Rechteck) unterstützt ein zusammengefasstes, und hier in Form einer Entscheidungstabelle abgebildetes Geschäftswissen (ein sogenanntes **Business Knowledge Model**, dargestellt als Rechteck mit zwei abgeschrägten Ecken). Diese Tabelle und die darin enthaltene Entscheidungslogik basiert auf zwei sogenannten **Knowledge-Source-Elementen** (dargestellt als Rechtecke mit einer Wellenlinie als untere Kante). Auch sind für die Entscheidungssituation „Gutschein für Uhren-Kunden auswählen“ neben der „Entscheidungstabelle zur Gutscheinvergabe“ weitere **Inputdaten** („Kaufhistorie Uhren-Kunde“, „Stammdaten Uhren-Kunde“) einzubeziehen.

\centerline{\includegraphics[width=1\textwidth]{img/812.png}}

Die **robotergesteuerte Prozessautomatisierung (Robotic Process Automation (RPA))** zielt auf die vollautomatisierte Nachahmung von manuellen Prozessschritten, bei denen bisher eine einfache menschliche Interaktion mit Benutzerschnittstellen von Anwendungen notwendig gewesen ist. Der Vorteil von RPA liegt darin, dass damit eine Automatisierung manueller Arbeitsschritte erfolgt ohne, dass jedoch aufwändig zu programmierende Schnittstellen zwischen den Anwendungen zu schaffen sind. Zudem zielen RPA-Werkzeuge auf eine einfache Konfiguration der zu automatisierenden Schritte, sodass diese auch geschulte Fachanwender durchführen können. Damit entlastet RPA Anwender von monotonen Routineaufgaben und reduziert damit auch das Potenzial menschlicher Benutzerfehler.
### Aufbauorganisation

Obgleich im Prozessmanagement die Ablauforganisation dominiert und die Ablaufplanung damit zunächst unabhängig von bestehenden Abteilungsgrenzen erfolgt, ist in einem anschließenden Schritt über die **Aufbauorganisation** zu entscheiden. Die Grundelemente der aufbauorganisatorischen Struktur eines Unternehmens bilden die **Stellen**, die durch die Bündelung inhaltlich zusammenhängender Einzelaufgaben entstehen. Die Beschreibung einer organisatorischen **Rolle** basiert ebenfalls auf der Zuordnung zu spezifischen Aufgaben, enthält aber zusätzlich Informationen zu den Mindestqualifikationen eines Rollenträgers und zu den durch die Rolle übertragenen Kompetenzen.

**Organigramme** sind Modelle, die die aufbauorganisatorische Struktur einer Organisation mit ihren Stellen, den darauf aufbauenden Organisationseinheiten und den sich dabei ergebenden Hierarchiebeziehungen abbilden. Ein **Organigramm** bezeichnet eine modellhafte Darstellung der (durch Berichtswege verknüpften) Organisationseinheiten, der Rollen und allenfalls auch Stellen der Aufbauorganisation.

Die nächste Abbildung zeigt für das Uhren-Beispiel das Organigramm für den aufbauorganisatorischen Bereich des Produktmanagements. Dieser Organisationseinheit sind sechs Rollen zugeordnet, die wiederum jeweils einem oder mehreren Mitarbeitern ausfüllen. Dieses Organigramm enthält zusätzlich Informationen zu den Führungsstrukturen (Abteilungsleiter und Teamleiter) innerhalb dieser Organisationseinheit.

\centerline{\includegraphics[width=1\textwidth]{img/813.png}}
### Operative Prozessführung und -messung

Die **operative Prozessführung** setzt an der Spezifikation von Organisationszielen, kritischen Erfolgsfaktoren und strategischen Führungsgrößen an.

Prozessführungsgrößen leiten sich aus strategischen Organisationszielen ab und dienen der Messung und Bewertung von Prozessen.

\centerline{\includegraphics[width=1\textwidth]{img/opeprozess.png}}

Die Messung und Bewertung von Prozessen dient vornehmlich zur Identifizierung von Situationen und Prozesszuständen, die die Erreichung von Prozesszielen und damit die performante Ausführung von Prozessen behindern. Die in den 1980er-Jahren entwickelte, und sich am Konzept des *Continuous Improvement (CI)* (s. Abschn. 6.2) orientierende **Six-Sigma-Prozessverbesserungsmethodik**  versucht durch Verbesserung der Prozessqualität und Reduzierung von zuvor gemessenen/identifizierten Prozessfehlern sowohl die Kundenzufriedenheit als auch die Wirtschaftlichkeit von Unternehmen zu erhöhen.

Zur Bestimmung der Qualität von Prozessinstanzen kommt hier die Kennzahl **Defects per Million Opportunities (DPMO)** zur Anwendung. Zur Berechnung der DPMO ist wie folgt vorzugehen:

\centerline{\includegraphics[width=1\textwidth]{img/814.png}}

* Zu jedem Prozess existieren Anforderungen aus Kundensicht, deren Einhaltung mit entsprechenden Messinstrumenten zu überwachen ist. Im Rahmen des Uhren-Beispiels sind dies einerseits der Versand einer bestellten Uhr an den „Uhrenkunden“ innerhalb von sieben Tagen, und andererseits die Ausstattung und Gestaltung der Uhr in Übereinstimmung mit den Kundenwünschen.
* Bei jeder einzelnen Prozessinstanz (z. B. eine einzelne Bestellung einer Uhr durch einen spezifischen Kunden) besteht die Möglichkeit, dass eine oder mehrere Anforderungen nicht erfüllt sind. Im Uhren-Beispiel gibt es somit pro Prozessinstanz zwei Fehlermöglichkeiten, die bei Nichterreichung jeweils als Defekt zu zählen sind.
* Nach der Berechnungsformel der DPMO (s. nächste Abb.), stellt die „Anzahl betrachteter Einheiten“ die im Rahmen der Berechnung berücksichtigte Anzahl/Stichprobe von Prozessinstanzen dar (z. B. 200 Uhrenkauf-Prozesse). Die „Gesamtanzahl Defekte“ bezieht sich auf die bei dieser Stichprobe ermittelte Anzahl an Defekten. In diesem Beispiel sollen bei den 200 Prozessinstanzen insgesamt zwölf Defekte (d. h. jeweils ein verspäteter Versand oder eine nicht anforderungsgerecht gestaltete Uhr) vorgekommen sein.
* Durch die Multiplikation mit 1 Million ergibt sich für dieses Beispiel ein DPMO-Wert von 30.000. Die (idealtypische, und in der Praxis meist nur schwer zu erreichende) Zielstellung beim Six-Sigma-Ansatz besteht darin, den DPMO-Wert auf 3,4 (99,99966 % Fehlerfreiheit) und damit auf das Sigma-Level 6 zu reduzieren. Das Uhrenbeispiel bewegt sich mit einem DPMO-Wert von 30.000 (97 % Fehlerfreiheit) zwischen dem Sigma-Level 3 und 4 und besitzt somit noch Verbesserungspotenzial.

Die Berechnung des DPMO-Werts dient somit zur Bestimmung des Qualitätsgrads für einzelne Prozesse oder ganze Prozess- oder Unternehmensbereiche. Entspricht das Qualitätsniveau nicht den Erwartungen, so bietet sich die Durchführung eines **Six-Sigma-Prozessverbesserungsprojekts** in fünf Phasen an:

* **Define**: Umfasst die Eingrenzung und Beschreibung der Probleme, die Bestimmung der Prozesskunden und ihrer Anforderungen/Projektziele sowie die Projektzeitplanung und die Organisation des Projektteams.
* **Measure**: Fokussiert auf die Konfiguration des Messsystems, die Detailmessung der Prozessleistungen und den anschließenden Vergleich mit den Kundenanforderungen.
* **Analyze**: Konzentriert sich auf die Analyse der Prozessergebnisse, der Fehlerursachen und der Einflussfaktoren sowie auf die nachfolgende Bestimmung detaillierter Verbesserungsziele.
* **Improve**: Evaluiert die Gestaltungsoptionen zur Prozessverbesserung sowie die Entwicklung, Pilotierung und Implementierung der Lösung.
* **Control**: Erstellt einen Kontrollplan und überprüft die neuen Prozessergebnisse hinsichtlich der Zielsetzungen.

Die Six-Sigma-Methodik bietet zahlreiche Techniken und Modelle, die in den einzelnen Projektphasen zum Einsatz kommen können. Das **SIPOC-Diagramm** ist eine Modellform zur groben Beschreibung der Abfolge von Kernaktivitäten in Prozessen und ist für die Makro-Prozessdarstellung in der Define- und Measure-Projektphase sowie ggf. auch in der Improve-Phase einsetzbar. Ein SIPOC-Diagramm enthält zu jedem Prozessschritt (mittlere Spalte **Process**, s. Tab. 8.3) die jeweils notwendigen Vorleistungen (**Input**) und deren Bereitsteller (**Supplier**) sowie die jeweils erzeugten Leistungen (Output) und deren Konsumenten (**Customer**). Tab. 8.3 zeigt ein Teil des aus Abb. 8.7 bekannten Prozesses zur Uhrenauswahl als SIPOC-Diagramm. In Erweiterung zur standardmäßigen Darstellung eines SIPOC-Diagramms sind hier zu den Prozessschritten zusätzlich die verantwortlichen Akteure in Klammern vermerkt.

\centerline{\includegraphics[width=1\textwidth]{img/sipoc.png}}

Während in der Measure-Phase vorwiegend Kennzahlendefinitionen und Kennzahlenmessungen zum Einsatz kommen, sind in der Analyze-Phase u. a. Techniken zur Ursachenermittlung (z. B. **Ishikawa (Fishbone)-Diagramm**) und zur Fehlereffektanalyse (z. B. **Failure Mode and Effects Analysis (FMEA)**) einsetzbar. In der Improve-Phase kommen sowohl Kreativitätstechniken (z. B. Brainstorming) zur Generierung neuer Ideen für die Prozessumgestaltung als auch Techniken zur Vorab-Bewertung von Lösungsalternativen (z. B. Kosten-Nutzen-Matrix, Simulationen zum Einsatz. Die Control-Phase nutzt neben den Prozessmessungstechniken aus der Measure-Phase Instrumente für die langfristige Prozesskontrolle und Problembeseitigung  sowie Techniken für die Replikation von Best Practices auf andere Prozess- oder Unternehmensbereiche (z. B. Einrichtung regelmäßiger Workshops für den innerbetrieblichen Erfahrungsaustausch).

## Kapitel 9: Informationssystemebene

Kapitel 9 beschreibt zunächst die Gestaltungsziele auf IS-Ebene sowie die prinzipiell zu unterscheidenden Architekturtypen. Im weiteren Verlauf erläutert es den Beitrag serviceorientierter Architekturen (SOA) für die fachlich-technische Integration. Die Darstellung der UML-Modellfamilie als übergreifender Ansatz zur Modellierung von IS und der Entity-Relationship-Notation zur Modellierung von Daten bildet den Abschluss des Kapitels.

### Gestaltungsinhalte auf IS-Ebene

Gegenüber der Strategie- und der Organisationsebene konzentriert sich diese Ebene auf Fragen der Gestaltung von Informationssystemen (IS) mit den darin verwendeten **Anwendungen** und hardwaretechnischen Komponenten.

Eine **Anwendung** (oder eine Anwendungssoftware bzw. eine **Applikation**) ist ein Softwaresystem, das durch die Abbildung der Geschäftslogik die fachlichen Aufgaben eines Unternehmens unterstützt. Als Teilbereich eines IS konzentriert sich die Anwendung auf eine hohe Integration der darin abgebildeten Funktionen, um einen möglichst hohen Automationsgrad zu erzielen.

Auf der IS-Ebene lassen sich fünf grundsätzliche Gestaltungsziele formulieren:

\centerline{\includegraphics[width=1\textwidth]{img/91ziel.png}}

### Anwendungsarchitektur und Anwendungslandschaft

Zur Realisierung der vorgenannten Gestaltungsziele ist beim Aufbau betrieblicher Anwendungen eine Entwicklung in Richtung modularisierter Architekturkonzepte zu beobachten. Ausgangspunkt ist die Aufteilung von Anwendungen in eine Präsentations-, eine Funktions- und eine Datenschicht. Danach besitzt jede Anwendung eine Benutzerschnittstelle (**Präsentationsschicht**), eine funktionale Verarbeitungslogik zur Abbildung der betriebswirtschaftlichen Prozesse (**Funktionsschicht**) sowie eine Datenbank zur Speicherung der verwendeten Daten (**Datenschicht**).

Während bei den frühen sog. Einschicht-Architekturen („1-Tier“, s. Tab. 9.1) die Anwendung alle Schichten monolithisch zusammengefasst hat, haben Client-Server-Architekturen zunächst zu einer Entkopplung von Anwendungslogik und Datenbank geführt. Auf die Schnittstelle der entkoppelten Datenbank konnten damit mehrere Anwendungen mit ihren Funktionen zugreifen („2-Tier“). In einer späteren Entwicklungsstufe hat in **Client-Server-Architekturen** auch eine Entkopplung von Anwendungslogik und Präsentationsschicht stattgefunden („3-Tier“). Dies ermöglicht den Nutzern den Zugriff auf die Funktionen mehrerer Anwendungen über eine entkoppelte Benutzerschnittstelle (z. B. einen Webbrowser). Die aktuelle Entwicklungsstufe hat zur Bildung einer weiteren Schicht geführt. Eine Integrationsschicht soll als zentrale Instanz die bilateralen Beziehungen vermeiden, sodass sich über eine einzige Verbindung zur Integrationsschicht alle anderen daran angeschlossenen Module darüber ansprechen lassen. Derartige Integrations-Anwendungen erlauben die zentralisierte Verwaltung von Schnittstellen, die Transaktionsabwicklung über mehrere verteilte (operative) Anwendungen hinweg sowie die Bereitstellung zentralisierter Dienste (z. B. Verzeichnisse).

\centerline{\includegraphics[width=1\textwidth]{img/table91.png}}

Aufbauend auf den grundsätzlichen Architekturtypen betrieblicher Anwendungen zeigt die **Anwendungslandschaft** eine Gesamtsicht über die Anwendungen einer organisatorischen Einheit. Eine Anwendungslandschaft besteht aus der Gesamtheit aller Anwendungen eines Untersuchungsobjekts (z. B. einer Abteilung, eines Unternehmens oder eines Unternehmensnetzwerks) einschließlich der zwischen den Anwendungen bestehenden Kommunikationsbeziehungen und Schnittstellen.

Wie in Teil 3 dargestellt, kann eine architektierte Anwendungslandschaft beispielsweise **Transaktionssysteme** (operative Anwendungen, s. Kap. 10) und **Entscheidungsunterstützungssysteme** (analytische Anwendungen, s. Kap. 11) unterscheiden. Für die digitale Transformation sind neben Ist-Architekturmodellen auch die Ziel-Architekturmodelle von Bedeutung. Letztere ermöglichen eine zielgerichtete Entwicklung der Gesamtarchitektur, was insbesondere bei der Umsetzung durchgängig digitaler Geschäftsprozesse notwendig ist.

Zur Unterstützung des Architekturmanagements sind im Laufe der Zeit eigene Modellierungswerkzeuge entstanden, die sich neben Ist- und Ziel-Visualisierungen der Anwendungslandschaft auf die Darstellung von weiteren IS-spezifischen Inhalten konzentrieren. Ein Beispiel bildet die gemeinsame Betrachtung von Anwendungslandschaft und Hardwareinfrastruktur im Rahmen von **IT-Landschaften**. Gleichzeitig berücksichtigen diese Werkzeuge zunehmend auch andere (fachliche) Inhalte aus dem Unternehmenskontext (z. B. die Zuordnung von Anwendungen zu den sie benutzenden Organisationseinheiten), so dass man von Werkzeugen des **Enterprise Architecture Management (EAM)** zur Gestaltung und Modellierung von **Unternehmensarchitekturen** spricht.

Die **Unternehmensarchitektur (Enterprise Architecture)** adressiert den ganzheitlichen Aufbau eines Unternehmens unter Berücksichtigung informationstechnologischer und betriebswirtschaftlicher Elemente. Dies umfasst neben den Elementen des Unternehmens selbst (z. B. Aufbau- und Ablauforganisation, Anwendungen,  Infrastrukturelemente) auch flankierende Aspekte wie Strategien und Ziele, Anforderungen, Projekte, Richtlinien und Muster sowie Kennzahlen.

\centerline{\includegraphics[width=1\textwidth]{img/92.png}}

### Gestaltung und Weiterentwicklung von Services

**Serviceorientierte Architekturen (SOA)** haben als mehrschichtiges Architekturkonzept in den vergangenen Jahren eine hohe Bedeutung erlangt. Services im Sinne einer SOA setzen sich aus einem fachlichen und einem technischen Teil zusammen und schlagen so die Brücke zwischen den auf der Organisationsebene angesiedelten Prozessen und den Anwendungen der IS-Ebene.

**Service (im Kontext Serviceorientierter Architekturen)**: Ein Service ist eine abgeschlossene und plattformunabhängig einsetzbare Softwarekomponente zur Umsetzung einer fachlichen Funktionalität, die andere Anwendungen/Services über eine definierte Schnittstelle ansprechen und nutzen können. Der fachliche Teil eines Service beschreibt dessen Einbettung in den fachlichen Anwendungskontext, z. B. welche fachliche Funktion/Aufgabe der Service erfüllt oder welche Organisationseinheit(en) den Service erstellt, verantwortet und verwendet. Der technische Teil beinhaltet die zugrundeliegenden Anwendungsfunktionen und Datenstrukturen sowie die Beschreibung der technischen Schnittstellen.

\centerline{\includegraphics[width=1\textwidth]{img/servicebsp.png}}
\centerline{\includegraphics[width=1\textwidth]{img/SOA.png}}

Zur Entwicklung und zum Management von Services sind in der Vergangenheit zahlreiche Modellansätze entstanden. Hierbei ist zunächst bezüglich der initialen Serviceidentifikation zwischen Bottom-up-Ansätzen (Identifikation/Abgrenzung von Services auf Basis (zusammenhängender) technischer Softwarefunktionalitäten), Top-down-Ansätzen (Identifikation auf Basis fachlicher Aktivitäten/Aktivitätsbündel) sowie gemischten (Hybrid)Ansätzen zu unterscheiden. Die notwendigen Aufgaben für das **Service (Lifecycle) Management** können sich an Ansätzen wie etwa ITIL orientieren und reichen von der Serviceidentifikation und -spezifikation über die Servicevereinbarung (Kauf/Verkauf) hin zur Serviceimplementierung und -lieferung sowie zum Servicemonitoring, dem Servicesupport und zur Serviceweiterentwicklung.

### Systemmodellierung mit der Unified Modeling Language (UML)

Ein **Metamodell** beschreibt, wie Phänomene eines Realitätsausschnitts durch entsprechende Modellelemente abgebildet werden können.

Als **Modell** wird dann ein bestimmter, mithilfe eines Metamodells abgebildeter Realitätsausschnitt bezeichnet.

Erfolgt die Dokumentation des Modells mit grafischen Mitteln, wird das Ergebnisdokument als **Diagramm** bezeichnet.

Die *Unified Modeling Language (UML)* ist eine der dominierenden Sprachen zur Modellierung von Softwaresystemen. Sie dient zur Modellierung, Dokumentation, Spezifizierung und Visualisierung komplexer Systeme unabhängig von deren Fach- und Realisierungsgebiet. Sie liefert die **Notationselemente** für die statischen und dynamischen Modelle dieser Modellfamilie. Die **statischen Modelle** oder auch **Strukturdiagramme** beschreiben die strukturelle Sicht auf ein System. Die **dynamischen Modelle** oder auch **Verhaltensdiagramme** legen den Schwerpunkt auf das Verhalten eines Systems.

\centerline{\includegraphics[width=1\textwidth]{img/diagrammUML.png}}
\centerline{\includegraphics[width=1\textwidth]{img/96.png}}

**Klassendiagramme** (Abb. 9.6) bilden den Kern der meisten objektorientierten Entwicklungen. Sie beschreiben die statische Struktur des zu entwickelnden Softwaresystems. In Abb. 9.6 sind zunächst die beiden Klassen „Uhrenmodell“ und „Einzelkomponente“ mit ihren jeweiligen Attributen (z. B. „Grundpreis“) und Operationen (z. B. „ErmittleVerkaufteStückzahl“) abgebildet. Zwischen den beiden Klassen existiert eine „Besteht aus“-Beziehung, zu der auch die entsprechenden Kardinalitäten (Angabe über die Anzahl der an einer Beziehung beteiligten Objekte, s. auch Abschn. 9.5) vermerkt sind. In diesem Beispiel besteht ein Uhrenmodell aus mindestens drei Einzelkomponenten, wobei eine Einzelkomponente keinem oder einer unbegrenzten Anzahl von Uhrenmodellen zugeordnet sein kann. Weiterhin ist die Klasse „Uhrenmodell“ eine Generalisierung zu den beiden spezifischeren Klassen „Kinderuhr“ und „Sportuhr“, die jeweils noch ein eigenes zusätzliches Attribut besitzen.

**Objektdiagramme** (Abb. 9.6) zeigen den inneren Aufbau eines Systems. Sie stellen die einzelnen Objekte und deren Wertebelegung zu einem bestimmten Zeitpunkt dar. Objektdiagramme und Klassendiagramme besitzen den gleichen Detaillierungsgrad. In Abb. 9.6 basiert das gezeigte Objektdiagramm auf den im Klassendiagramm spezifizierten Inhalten. Hierbei besteht das beispielhafte Uhrenmodell „Gerano“ aus drei spezifischen Einzelkomponenten („ArmbandA15“, „UhrwerkLB7“ und „Gehäuse7BA“), zu denen die jeweiligen „Lieferanten“ und „Güteklassen“ vermerkt sind.

**Paketdiagramme** (Abb. 9.6) eignen sich dazu, ein System in größere Einheiten zu organisieren und Teile des Modells zusammenzufassen. In Abb. 9.6 ist zu sehen, dass das Paket „Preisberechnung“ aus zwei Unterpaketen besteht, und dass das erste Unterpaket „Uhrenmodell-Preisberechnung“ auf alle frei verfügbaren und öffentlichen Elemente des zweiten Unterpakets „Komponenten-Stammdatenverwaltung“ zugreifen darf.

\centerline{\includegraphics[width=1\textwidth]{img/97.png}}

**Sequenzdiagramme** (Abb. 9.7) stellen detailliert den nacheinander erfolgenden Informations- und Nachrichtenaustausch zwischen mehreren Objekten dar. In Abb. 9.7 geht im Sequenzdiagramm „Prototypentwicklung“ die erste Nachrichtenkommunikation vom „Uhrenmodell-Konfigurator“ aus. Die Nachricht „ErstellePrototypen“ an den „Uhrmacher“ ist als synchrone Kommunikation gekennzeichnet, d. h. der „Uhrenmodell-Konfigurator“ wartet als Sender der Nachricht auf das „Prüfprotokoll“ als Rückantwort und pausiert bis zu deren Eintreffen mit seiner weiteren Verarbeitung (s. Balken auf der Lebenslinie).

**Kommunikationsdiagramme** (Abb. 9.7) dienen wie Sequenzdiagramme dazu, das Zusammenspiel und die Kommunikation der Objekte bei der Problemlösung zu spezifizieren. Semantisch sind Sequenzdiagramme und Kommunikationsdiagramme äquivalent. So beziehen sich die in Abb. 9.7 im Kommunikationsdiagramm „Prototypenprüfung“ dargestellten Nachrichtenbeziehungen zwischen dem „Uhrmacher“ und dem „Qualitätsverantwortlichen“ auf die bereits im Sequenzdiagramm dargestellten Inhalte. Hierbei zeigt die ungerichtete Kante zwischen den beiden Objekten das Bestehen einer Kommunikationsbeziehung an. Die Nachrichten sind als zusätzliche gerichtete Kanten unter Angabe der Reihenfolgebeziehung abgebildet.

**Timingdiagramme** (Abb. 9.7) veranschaulichen die durch Nachrichten ausgelösten Zustandsänderungen von Objekten, Klassen oder Schnittstellen im Zeitverlauf. Sie sind wichtig, wenn exakte Zeitpunkte für Ereignisse festzulegen sind. Im Timingdiagramm „Prototypenprüfung“ (Abb. 9.7) befindet sich der „Qualitätsverantwortliche“ im initialen Zustand „Warten“ und der „Uhrmacher“ im initialen Zustand „Bauen“. Die nachfolgend vom „Uhrmacher“ ausgehende Nachrichtenübermittlung „Prototypen prüfen“ verändert ihren Zustand in „Warten“ und versetzt den „Qualitätsverantwortlichen“ in den Zustand „Prüfen“. Spätestens nach zwei Tagen soll der „Qualitätsverantwortliche“ sein „Prüfprotokoll“ an den „Uhrmacher“ versenden, wobei letzterer im Anschluss die Prüfergebnisse analysiert soll und sich damit im Zustand „Auswerten“ befindet.

\centerline{\includegraphics[width=1\textwidth]{img/98.png}}

**Anwendungsfalldiagramme** (Abb. 9.8) (auch Use-Case-Diagramme genannt) stellen aus Anwendersicht die Verknüpfungen zwischen den Akteuren und den Anwendungsfällen eines Systems dar. Weiterhin sind hiermit die Beziehungen zwischen Anwendungsfällen (z. B. Erweiterungen oder Aggregationen) abbildbar. Die Anwendungsfalldiagramme stellen die Außensicht auf das System dar. Das Anwendungsfalldiagramm in Abb. 9.8 zeigt beispielsweise, dass der „Uhrenmodell-Konfigurator“ am Anwendungsfall „Entwurf eines Uhren-Basismodells“ beteiligt ist, wobei dieser Anwendungsfall eine Aggregation aus den beiden Anwendungsfällen „Entwurf einer Kinderuhr“ und „Entwurf einer Sportuhr“ darstellt.

**Aktivitätsdiagramme** (Abb. 9.8) helfen dabei, Prozesse und Aktivitätsfolgen detailliert mit Start- und Endereignissen, Bedingungen, aufbauorganisatorischen Zuordnungen, Schleifen und Verzweigungen zu beschreiben. Das Aktivitätsdiagramm in Abb. 9.8 orientiert sich an den in Abb. 8.10 gezeigten Inhalten und zeigt die Aktivitätsfolge von der Idee zu einem neuen Uhrenmodell bis zur Herstellung eines Uhrenmodell-Prototypen. Hierbei ist wie in der Prozessmodellierungsnotation BPMN (s. Abschn. 8.3) die aufbauorganisatorische Zuordnung der einzelnen Aktivitäten mit Hilfe von Swimlanes abgebildet.

\centerline{\includegraphics[width=1\textwidth]{img/99.png}}

**Interaktionsübersichtsdiagramme** (Abb. 9.9) stellen Interaktionen in ihrer sachlogischen und damit auch zeitlichen Reihenfolge dar. Hierbei kommen innerhalb der Modelle Sequenzdiagramme und aus dem UML-Aktivitätsdiagramm stammende Modellelemente zur Anwendung. In Abb. 9.9 zeigt die mit Hilfe eines Sequenzdiagramms dargestellte Interaktion „Preisübermittlung“ im Detail den Nachrichtenaustausch zwischen dem „Onlineshop“ und der „Preisberechnungsfunktion“, während andere Interaktionen auf bestehende Modelle verweisen (z. B. „Suche und Konfiguration Uhrenmodelle“).

**Komponentendiagramme** (Abb. 9.9) stellen Komponenten als wiederverwendbare und austauschbare modulare Einheiten eines Softwaresystems sowie die zwischen ihnen bestehenden Abhängigkeiten und Schnittstellen dar. In Abb. 9.9 ist die Komponente „Uhrenmodell-Preisberechnungsfunktion“ zunächst über zwei Schnittstellen mit ihrer Umwelt zum „Empfangen von Uhrenkonfigurationen“ und zur „Übermittlung von Preisberechnungen“ verbunden. Eine weitere Schnittstelle zur „Komponentenstammdatenverwaltung“ liefert die für die Preisberechnung von Uhrenmodellen notwendigen „Beschaffungspreise der Komponenten“.

**Verteilungsdiagramme** (Abb. 9.9) zeigen die technische/physische IS-Umgebung (z. B. Hardware, Server, Datenbanken) sowie die Zuordnung von Software- zu Hardwarekomponenten. In Abb. 9.9 sind im Verteilungsdiagramm die zwei Serverkomponenten „Onlineshop“ und „ERP_Backend“ über eine „Ethernet“-Verbindung verknüpft. Zudem betreibt der „ERP-Backend“-Server die Softwarefunktion „Komponentenstammdatenverwaltung“ und nutzt in diesem Zusammenhang die beiden Artefakte „preisberechnung.jar“ und „preislistenimport_uhrenkomponenten.csv“.

\centerline{\includegraphics[width=1\textwidth]{img/910.png}}

**Zustandsautomaten** (Abb. 9.10) zeigen, welche Abfolge von Zuständen ein Objekt bei einer Anzahl von nacheinander auftretenden Ereignissen/ausgeführten Aktivitäten einnehmen kann. In Abb. 9.10 sind die Zustandsabfolgen von einem „Uhrenwunsch“ des „Uhren-Kunden“ bis hin zu einem „konfigurierten Uhrenmodell mit Preisangabe“ innerhalb des „Uhren-Onlineshops“ abgebildet. Dabei sind die Zustände unter Verwendung der Swimlane-Darstellung immer denjenigen organisatorischen Einheiten zugeordnet, die (z. B. mit Hilfe einer Aktivität) zur Veränderung dieses Zustands in der Lage sind (z. B. der „Uhren-Kunde“ verändert durch seine Aktivität „Uhren-Basismodell suchen“ den Zustand von „Uhrenmodelle und Varianten sind angezeigt“ hin zu „Uhren-Basismodell ist ausgewählt“).

**Profildiagramme** (Abb. 9.10) dienen der benutzerorientierten Anpassung und Erweiterung der UML-Metamodellebene durch die Definition von sogenannten Profilen, in denen ausgewählter Notationselemente des Klassendiagramms (wie z. B. Stereotypen) zum Einsatz kommen. Das in Abb. 9.10 gezeigte „Uhrenprofil“ erweitert das Metamodell von UML, indem es die „Uhrenklasse“ als neue aggregierte Klasse mit den Unterklassen „Sportuhr“ und „Kinderuhr“ einführt.

### Datenmodellierung mit der ER-Notation

\centerline{\includegraphics[width=1\textwidth]{img/erm1.png}}

**Generalisierung**. Eine Generalisierungsbeziehung ist dann zu verwenden, wenn sich mehrere zunächst voneinander unabhängige Entitätstypen unter einem generelleren Entitätstyp zusammenfassen lassen. Bei Generalisierungen vererben die generellen Entitätstypen ihre Attribute an die verbundenen Einzelentitätstypen, wobei die Einzelentitätstypen jeweils noch zusätzliche individuelle Attribute besitzen können. Im ER-Modell dienen Dreiecke zur Darstellung von Generalisierungsbeziehungen, die über ungerichtete Kanten mit den Einzelentitätstypen und dem generellen Entitätstyp verbunden sind.

**Kardinalität**. Zur vollständigen Modellierung eines Beziehungstyps ist anzugeben, wie viele Datenobjekte der beteiligten Entitätstypen an Beziehungen dieses Typs teilnehmen können (Kardinalität), z. B. 1:1-, 1:n- und m:n-Beziehungen.

In der x:y-Darstellung von Kardinalitäten stehen die jeweiligen Zahlen für die maximale Anzahl der an einer Beziehung beteiligten Entitäten. Um Kardinalitäten vollständig zu beschreiben ist es notwendig, auch die minimal vorkommende Anzahl der Entitäten in einer Beziehung anzugeben. Dies wird mit der Anwendung der sog. **(Min-Max)-Notation** für Kardinalitäten erreicht, die für eine Beziehung auf jeder Seite des Doppelpunkts jeweils in Klammern die minimale und maximale Anzahl der jeweiligen Entitäten angibt:

* (0,1): Die Entitäten des betreffenden Entitätstyps können (müssen aber nicht) an maximal einer Beziehung teilnehmen.
* (0,n): Die Entitäten des betreffenden Entitätstyps können (müssen aber nicht) an einer oder mehreren Beziehungen teilnehmen.
* (1,1): Die Entitäten des betreffenden Entitätstyps müssen an genau einer Beziehung teilnehmen (klassische Existenzabhängigkeit).
* (1,n): Die Entitäten des betreffenden Entitätstyps müssen an einer oder mehreren Beziehungen teilnehmen.

# Teil 3: Betriebliche Anwendungen

## Kapitel 10: Anwendungen in ERP-Systemen

Dieses Kapitel erläutert, wie Anwendungen in ERP-Systemen Unternehmensprozesse unterstützen und automatisieren können. Es werden sowohl sektorneutrale als auch sektorspezifische Anwendungen vorgestellt. Abschließend wird darauf eingegangen, wie ERP-Systeme als Standardsoftwareprodukte in Unternehmen einzuführen sind.

### Überblick

Ein **Referenzmodell** ist ein Informationsmodell, dessen Inhalt bei der Entwicklung von Anwendungsmodellen wiederverwendet werden kann.

Referenzmodelle werden zumeist auf fachkonzeptioneller Ebene und mit semi- formalen Darstellungstechniken erstellt. Sie beinhalten Modelle zur Beschreibung von Eigenschaftsstrukturen (z. B. Entity-Relationship-Modelle, ERM) und Verhaltensstrukturen z. B. BPMN-Modelle) des ausgewählten betrieblichen Teilgebiets. Eine Übersicht zu Unterscheidungsmerkmalen von Referenzmodellen gibt Abb. 10.1.

\centerline{\includegraphics[width=1\textwidth]{img/101.png}}

Ausgangspunkt der **Referenzmodellentwicklung** bildet die **Problemdefinition**, mit der der Modellierungsbereich und die Ziele der Referenzmodellkonstruktion fixiert sind. Anschließend wird durch **Analyse der Problemdomäne** Wissen über den Modellierungsbereich aufgebaut und ein Modellrahmen definiert. In der folgenden Phase findet die **Konstruktion der strukturellen und dynamischen Aspekte des Modells** statt. Durch die **Evaluation** wird sichergestellt, dass die konstruierten Modelle konsistent sind und den Anforderungen der Anwender genügen. Defizite oder Anforderungsänderungen führen dazu, dass der Entwicklungsprozess erneut ausgeführt wird. Mit dem Entwicklungsprozess ist der **Anwendungsprozess von Referenzmodellen** verknüpft, der durch die **Problemdefinition des Anwenders** angestoßen wird und zu **definierten Anforderungen** führt. In der folgenden Phase erfolgt die **Suche und Selektion** geeigneter Referenzmodelle, die anschließend zur **Konstruktion eines spezifischen Modells** für das Anwenderproblem führen.

\centerline{\includegraphics[width=1\textwidth]{img/102.png}}

### Sektorneutrale Anwendungen
#### Rechnungswesen als Kern des ERP-Systems

Ein ERP-System unterstützt die Administrations- und Dispositionsaufgaben eines Unternehmens. Das Rechnungswesen stellt den Kern des ERP-Systems dar. Die Teilsysteme **Finanzbuchhaltung** (externes Rechnungswesen) und **Kosten- und Leistungsrechnung** (internes Rechnungswesen) werden als seine zentralen Komponenten betrachtet.

Neben dem System SAP ERP existieren weitere Lösungen im Bereich Customer Relationship Management (SAP CRM), Supplier Relationship Management (SAP SRM), Product Lifecycle Management (SAP PLM) und Supply Chain Management (SAP SCM). Wie aus Abb. 10.5 ersichtlich, sind sämtliche Lösungen Teil der SAP Business Suite. Lösungen aus den Bereichen des CRM, SRM und SCM fokussieren die unternehmensexterne Vernetzung mit Kunden sowie Lieferanten.

\centerline{\includegraphics[width=1\textwidth]{img/105.png}}

Einzelne Softwarefunktionalitäten innerhalb von SAP ERP sind einem der Bereiche Analytics (Analyse, Controlling), Financials (Finanzwesen), Human Capital Management (Personalwesen), Procurement & Logistics Execution (Einkauf und Logistik), Product Development & Manufacturing (Produktentwicklung und Fertigung) und Sales & Service (Vertrieb und Kundendienst) zugeordnet. Abb. 10.6 liefert einen Überblick über die Kernbereiche von SAP ERP.

\centerline{\includegraphics[width=1\textwidth]{img/106.png}}

#### Externes Rechnungswesen
##### Aufgaben der Finanzbuchhaltung
Die Aufgabe der Finanzbuchhaltung besteht darin, sämtliche Geschäftsvorfälle eines Unternehmens auf Konten zahlenmäßig abzubilden und durch den Jahresabschluss eine verdichtete Darstellung der unternehmerischen Vermögens- und Erfolgssituation in Form der Bilanz und der Gewinn- und Verlustrechnung (GuV) zu erzeugen.

\centerline{\includegraphics[width=1\textwidth]{img/107.png}}

Als grundlegender Baustein der Finanzbuchhaltung ist die **Hauptbuchhaltung** anzusehen, in der die Buchungen auf den Sachkonten des Kontenplans vorgenommen werden. Als Sachkonten werden diejenigen Bestands- und Erfolgskonten bezeichnet, die im Kontenplan des Unternehmens enthalten sind. Der Abschluss dieser Sachkonten in Form des Jahresabschlusses führt zur Bilanz und zur Gewinn- und Verlustrechnung.

Neben den Sachkonten der Hauptbuchhaltung sind weitere Konten erforderlich. Diese werden im Rahmen von **Nebenbuchhaltungen** erfasst, zu denen die Kontokorrentbuchhaltung, die Lagerbuchhaltung, die Anlagenbuchhaltung und die Lohn- bzw. Personalbuchhaltung gehören.

Der Gegenstand der **Kontokorrentbuchhaltung** (ital. conto corrente = laufende Rechnung) ist die Abbildung der Geschäftsbeziehungen zu Lieferanten (Kreditoren) und Kunden (Debitoren). Durch die Kontokorrentbuchhaltung wird es möglich, für jeden Lieferanten bzw. Kunden den aktuellen Stand der Verbindlichkeiten bzw. Forderungen zu erfassen. Zu diesem Zweck ist es erforderlich, für jeden Lieferanten bzw. Kunden ein eigenes Personenkonto einzurichten, auf dem die entsprechenden Buchungen mit den Verbindlichkeits- bzw. Forderungskonten vorgenommen werden.

Die **Lagerbuchhaltung** dient der Aufzeichnung der Bestände, Abgänge und Zugänge einzelner Materialarten sowie unfertiger und fertiger Erzeugnisse. Die Erfassung der Materialien erfolgt dabei mengenorientiert, sodass für jedes Material der mengenmäßige Bestand buchmäßig ermittelbar ist.

Um das Anlagevermögen des Unternehmens zu verwalten, ist ein Verzeichnis aller zugehörigen Wirtschaftsgüter erforderlich. Da die Anlagekonten des Hauptbuchs als Sammelkonten geführt werden, ist eine Detaillierung in Form einer eigenen **Anlagenbuchhaltung** erforderlich. In der Anlagenbuchhaltung erfolgt die Erfassung der Sach- und Finanzanlagen und der immateriellen Vermögensgegenstände. Für sämtliche Teile des Anlagevermögens werden in der Anlagenbuchhaltung auch die für die Berechnung der Abschreibungen benötigten Daten erfasst.

In der **Lohn- und Personalbuchhaltung** werden die entsprechenden Konten der Mitarbeiter des Unternehmens geführt, auf denen nicht nur die Erfassung von Löhnen und Gehältern erfolgt, sondern auch die Dokumentation sonstiger Leistungen, wie beispielsweise Vorschüsse, Sondervergütungen und Sachleistungen.

##### Stammdaten der Hauptbuchhaltung
Zur Einrichtung der Finanzbuchhaltung als operatives System der Anwendungsarchitektur wird i. d. R. eine unternehmensspezifische Anpassung vorgenommen, die als **Customizing** bezeichnet wird. Im Rahmen des Customizingprozesses ist die Abbildung der Unternehmensstruktur sowie der landesspezifischen Besonderheiten (z. B. Währung, Steuersätze) erforderlich. Dies erfolgt anhand von Stammdaten.

**Stammdaten** sind Grunddaten eines Unternehmens, die sich auf betriebswirtschaftlich relevante Objekte beziehen. Stammdaten existieren unabhängig von anderen Daten und werden im Zeitablauf selten verändert.

Das SAP ERP-System verwendet zum Customizing einen standardisierten Einführungsleitfaden, der als **SAP-Referenz-IMG (Implementation Guide)** bezeichnet wird. Die einzelnen Schritte dieses Leitfadens müssen zur Einführung des Systems abgearbeitet werden, um ein lauffähiges SAP ERP-Produktivsystem zu erhalten.

Die oberste Hierarchieebene der SAP-Stammdaten ist der Mandant. Ein Mandant ist eine geschlossene Unternehmenseinheit, verfügt über einen eigenen Stammdatenbestand und ist von anderen Mandanten unabhängig. Als nächste organisatorische Einheit unterhalb des Mandanten stellt sich der Buchungskreis dar. Mit Buchungskreisen werden rechtlich selbstständige Tochtergesellschaften abgebildet. Betriebswirtschaftlich stellt ein Buchungskreis eine Gesellschaft im juristischen Sinne dar (z. B. eine GmbH, AG, KG), die innerhalb eines als Mandant abgebildeten Konzerns organisiert sein kann.

In der Terminologie des SAP-Customizingprozesses werden für jeden Mandanten unternehmensinterne und unternehmensexterne Sachverhalte auf **interne** und **externe Organisationseinheiten** abgebildet.

Die externen Organisationseinheiten werden auch als **rechtliche Organisationseinheiten** bezeichnet. Zu diesen rechtlichen Konstrukten gehören der **Buchungskreis** und die **Gesellschaft**. Eine **Gesellschaft** ist eine organisatorische Einheit des Rechnungswesens eines Unternehmens. Ein **Buchungskreis** ist eine organisatorische Einheit des Rechnungswesens, durch die das Unternehmen aus **Sicht der Finanzbuchhaltung** gegliedert wird. In einem Buchungskreis erfolgt eine vollständige Buchhaltung. Ein Buchungskreis umfasst grundsätzlich eine rechtlich selbstständige Gesellschaft. Aber auch rechtlich unselbstständige Einheiten, beispielsweise Betriebsstätten im Ausland, können abgebildet werden. Auf diese Weise lassen sich für diese Einheit eigene Berichtsfunktionen in der jeweiligen Landeswährung nutzen. Zu den Stammdaten, die für einen Buchungskreis zu definieren sind, gehören insbesondere der Kontenplan, die Geschäftsjahresdefinition und die zu verwendenden Parallelwährungen.

Zu den internen Organisationseinheiten gehören die optionalen Konstrukte **Geschäftsbereich** sowie **Kreditkontroll- und Mahnbereich**. Durch die Definition von **Geschäftsbereichen** ist es im Rahmen der Finanzbuchhaltung von SAP ERP möglich, die Buchungen auf den Sachkonten differenziert auszuwerten. Um bei der Buchung von Geschäftsvorfällen eine korrekte Zuweisung zu den verursachenden Geschäftsbereichen sicherzustellen, ist der entsprechende Geschäftsbereichsschlüssel bei jeder Buchung anzugeben. Ein **Kreditkontrollbereich** ist eine interne Organisationseinheit des Rechnungswesens, die für Debitoren ein Kreditlimit definiert und überwacht. Ein Kreditkontrollbereich ist dadurch gekennzeichnet, dass er eine einheitliche Währung aufweist und mehrere Buchungskreise umfassen darf. Das **Mahnwesen** von SAP ERP wird im Allgemeinen auf Buchungskreisebene abgewickelt, sodass jeder Buchungskreis genau einen Mahnbereich bildet. In der Praxis liegt häufig eine divisionalisierte Unternehmensstruktur vor, bei der die Mahnfunktion auf die einzelnen Geschäftsbereiche, Vertriebsorganisationen oder Sparten verteilt wird. Diese Organisationsbereiche können unter SAP ERP als Mahnbereiche erfasst werden.

\centerline{\includegraphics[width=1\textwidth]{img/1011.png}}

Abb. 10.11 stellt den Zusammenhang zwischen Buchungskreisen und Kreditkontrollbereichen her. Der im Beispiel abgebildete Konzern besitzt Niederlassungen in Deutschland, Frankreich, USA und Kanada und verfügt über vier Buchungskreise, die nach den landesspezifischen Rechtsnormen einzeln abgeschlossen werden. In jedem Buchungskreis existieren Geschäftsbeziehungen mit dem Debitor X. Innerhalb des SAP ERP-Systems werden die beiden Kreditkontrollbereiche Europa (Währung Euro) und Nordamerika (Währung USD) angelegt. Für jeden dieser Kreditkontrollbereiche wird ein Kreditlimit in der entsprechenden Währung definiert. Dieses Kreditlimit gilt grundsätzlich für jeden einzelnen Debitor. Für einzelne Debitoren kann jedoch zusätzlich ein individuelles Kreditlimit festgelegt werden.

\centerline{\includegraphics[width=1\textwidth]{img/1013.png}}

Sämtliche Geschäftsvorfälle des Unternehmens werden auf **Sachkonten** der Hauptbuchhaltung gebucht, die durch Kontenrahmen und Kontenplan zu gliedern sind. Der Kontenrahmen ist in zehn Kontenklassen unterteilt, bei denen wiederum einzelne Kontengruppen unterschieden werden.

Bei der Auswahl des Kontenrahmens gibt es die grundlegenden **Gliederungsprinzipien der Abschluss-** (orientiert sich am Jahresabschluss der Kapitalgesellschaften, z.B. Industriekontenrahmen IKR) und **der Prozessgliederung** (nach dem generellen Ablauf der betrieblichen Leistungserstellung gegliedert, z.B. Gemeinschaftskontenrahmen GKR).

Die datenorientierte Modellierung der Konten und des Kontenplans wird durch das Entity-Relationship-Modell in Abb. 10.14 beschrieben, das außerdem den Buchungskreis und den Mandanten erfasst.

\centerline{\includegraphics[width=1\textwidth]{img/1014.png}}

Jeder Mandant (Konzern) kann mehrere Buchungskreise (Konzerntöchter) aufweisen. Dieser Sachverhalt wird durch den Beziehungstypen MBKZO ausgedrückt (Mandant-Buchungskreis-Zuordnung). Jedem Buchungskreis muss genau ein Kontenrahmen (z. B. GKR oder IKR) zugewiesen werden. Dies geschieht durch den Beziehungstypen KPBKZO. Erst wenn die Zuordnung des zum Kontenrahmen gehörenden detaillierten Kontenplans zum Buchungskreis erledigt ist, kann über den Beziehungstyp der Kontenzuordnung die Abbildung der Konten auf den Kontenplan für den gewünschten Buchungskreis erfolgen. Der Aufbau des Kontenplans wird durch den Beziehungstypen KSTRUKTUR erfasst. Die (0,n):(0,n)-Kardinalität erlaubt die Abbildung vernetzter Kontenbeziehungen.

Die Attribute der Sachkonten können in buchungskreis- und kontenplanspezifische Daten differenziert werden. Während sich die **kontenplanspezifischen Daten** aus dem selektierten Kontenplan ableiten lassen, sind die **buchungskreisspezifischen Daten** nur für den aktuellen Buchungskreis (z. B. für eine Konzerntochter) gültig.

Zu den **buchungskreisspezifischen Daten** gehören:

* Die **Währung**
* Das **Steuerkennzeichen** gibt an, welche Umsatzsteuersätze zu verwenden sind.
* Die **Kontenabstimmung** stellt sicher, dass entsprechende Abstimmbuchungen mit den Büchern der Nebenbuchhaltung (z. B. Kreditoren-, Debitoren- oder Anlagenbuchhaltung) durchgeführt werden. Durch die Abstimmkontentechnik kann jederzeit ein Abschluss erstellt werden, da die Beträge aus den Nebenbuchhaltungen auch in der Hauptbuchhaltung gebucht werden.
* Die **Berechtigung** kennzeichnet die Benutzergruppe, die zum Zugriff auf das Konto autorisiert ist.

Zu den **kontenplanspezifischen Daten** des Sachkontenstamms gehören:

* Die **Kontonummer** und die **Kontenbezeichnung**,
* der **Kontentyp**, der angibt, ob es sich bei dem Konto um ein Bilanz- oder ein Erfolgskonto handelt und
* die **Kontengruppe**, die bestimmt, welche Felder beim Anlegen oder Ändern des Sachkontenstammsatzes ausgefüllt werden müssen.

##### Stammdaten der Debitoren- und Kreditorenbuchhaltung

Im Rahmen der Debitoren- und Kreditorenbuchhaltung werden die Geschäftsbeziehungen der Unternehmen zu Kunden und Lieferanten erfasst. Hierzu gehören beispielsweise Adressdaten, Zahlungsbedingungen und Bankverbindungen. Da Debitoren und Kreditoren in mehreren Buchungskreisen eines Konzerns aktiv sein können, ist es sinnvoll, die Daten in einen **allgemeinen** und einen **buchungskreisabhängigen** Bereich zu untergliedern.

\centerline{\includegraphics[width=1\textwidth]{img/1016.png}}

Die **allgemeinen Stammdaten** umfassen diejenigen Attribute, die einen Debitoren bzw. Kreditoren unabhängig von seiner Aktivität in den Buchungskreisen des Mandanten beschreiben. Zu diesen Daten gehören sämtliche **Anschriftdaten** (Namen, Adresse, Kommunikationsmöglichkeiten des Kreditoren bzw. Debitoren), **Steuerdaten (Steuernummer)** des Debitoren und **Referenzdaten** (Global Location Number, GLN) zur eindeutigen Identifikation im Geschäftsverkehr.

Zu den **buchungskreisabhängigen Stammdaten** für Kreditoren und Debitoren gehören die Kontoführungsdaten:

* Die Geschäftsvorfälle, die in der Kreditoren- und Debitorenbuchhaltung gebucht werden, müssen gleichzeitig auf den Konten der Hauptbuchhaltung abgebildet werden. Zu diesem Zweck wird jedem Kreditoren- bzw. Debitorenkonto ein **Abstimmkonto** in der Hauptbuchhaltung zugewiesen.
* **Zahlungsverkehrs**: Dazu gehört die Erfassung der gewährten Zahlungsbedingungen durch die Kreditoren bzw. Debitoren sowie die Darstellung der Bankverbindungen. Bei der Durchführung des Zahlungsverkehrs ist neben dem Bank Identifier Code (BIC) die IBAN (International Bank Account Number) als zweites Identifikationsmerkmal zu erfassen, die weltweit der eindeutigen Adressierung von Konten dient.
* Die **Mahndaten** geben an, mit welchen Parametern die Mahnung von Debitoren erfolgen soll. Zu den Parametern des Mahnverfahrens gehört die Anzahl der Mahnstufen, die vor Durchführung eines gerichtlichen Mahnverfahrens durchlaufen werden, sowie die Mahntexte, aus denen automatisch eine schriftliche Mahnung erstellt wird. Für Forderungen mit längerer Laufzeit können Warenkreditversicherungen abgeschlossen werden, die als Teil der Debitorenstammdaten zu erfassen sind.

Die dargestellten Stammdaten verdeutlichen, dass das Anlegen eines neuen Kreditoren bzw. Debitoren mit relativ hohem Aufwand verbunden ist. Für Geschäftspartner, bei denen selten bzw. einmalig Geschäftsvorfälle anfallen, empfiehlt sich die Anlage sog. **Conto-pro-Diverse-Konten (CpD-Konten)**. Bei dieser Art von Personenkonto werden die Stammdaten bei der **Belegerfassung** eingegeben und innerhalb des Belegs gespeichert. Auf diese Weise werden die Datenbestände des Kreditoren- bzw. Debitorenstamms nicht unnötig vergrößert.

##### Stammdaten der Anlagenbuchhaltung

Die Anlagenbuchhaltung dient der Dokumentation des Anlagevermögens der Unternehmen. Dabei werden die Arten des Anlagevermögens in **immaterielle Vermögensgegenstände** (z.B. Rechte, Konzessionen), **Sachanlagen** (z.B. Maschinen, Gebäude) und **Finanzanlagen** (z.B. Unternehmensbeteiligungen, Wertpapiere) unterschieden. Im Folgenden wird nur auf den Bereich der (praktischsten) Sachanlagen eingegangen. Die nächste Abbildung beschreibt die erforderlichen Sachverhalte für die Erfassung von Sachanlagen.

\centerline{\includegraphics[width=1\textwidth]{img/1017.png}}

##### Bewegungsdaten der Finanzbuchhaltung

Die *Bewegungsdaten* resultieren aus den Geschäftsvorfällen eines Mandanten und haben i. d. R. Auswirkungen auf dessen Bestandsdaten. **Bewegungsdaten** sind ereignis- bzw. zeitbezogene Daten, die die Ausprägung von Bestandsdaten verändern. Bestandsdaten beziehen sich auf betriebswirtschaftlich relevante Mengen- und Wertangaben.

Zur korrekten Abbildung der Geschäftsvorfälle sind aber auch Stammdaten, z. B. Kreditoren- und Debitorenkonten, erforderlich. In der Datenmodellierung sind Bewegungsdaten durch Zeitpunkt- und/oder Transaktionsbezüge gekennzeichnet, während Stammdaten entweder unbeschränkt gültig sind oder einen Zeitraumbezug aufweisen (gültig von … bis …).

Bei der Abbildung von Geschäftsvorfällen im System der Finanzbuchhaltung ist das **Belegprinzip** als maßgeblicher Grundsatz zu beachten. Ein Beleg dokumentiert einen Geschäftsvorfall und stellt die Grundlage für die Buchung im System der Finanzbuchhaltung dar.

Um eine möglichst einfache Abbildung der Belegarten im System der Finanzbuchhaltung zu ermöglichen, ist eine einheitliche Belegstruktur für die Bewegungsdatenverwaltung sinnvoll. Abb. 10.19 veranschaulicht eine Modellierungsvariante für den Sachverhalt der Verwaltung von Bewegungsdaten.

\centerline{\includegraphics[width=1\textwidth]{img/1019.png}}

In dem dargestellten ER-Diagramm werden die unterschiedlichen Dokumente der Geschäftsvorfälle  (z. B. Kundenrechnung, Lieferantenrechnung) erfasst und zwecks Vereinheitlichung auf ein generalisiertes Dokument abgebildet. Dieses Dokument, das die Entitätstypen Urbelegkopf und Urbelegposition umfasst, dient dabei lediglich der Standardisierung vielfältiger materieller Belegarten. Es wird benötigt, um die Belegerfassung durch die Entitätstypen Belegkopf und Belegposition zu ermöglichen. Neben dem Belegkopf und den einzelnen Belegpositionen ist es aus Sicht der Datenorganisation erforderlich, den Belegtypen zu erfassen.

SAP ERP orientiert sich am Belegprinzip und speichert Buchungen stets in Belegform.

##### Funktionen der Hauptbuchhaltung

\centerline{\includegraphics[width=1\textwidth]{img/1020.png}}

Im Bereich der **Stammdatenpflege** werden die Sachkonten der Hauptbuchhaltung verwaltet. Zu den zentralen Aufgaben gehören dabei das Anlegen, Ändern, Anzeigen und Löschen der Sachkontenstammdaten.

\centerline{\includegraphics[width=1\textwidth]{img/1023.png}}

**Buchungen durchführen**: Der Prozess der Sachkontenbuchung lässt sich in BPMN-Notation darstellen (s.Abb. 10.23).

* Belegkopf eingeben: Belegdatum (Ausstellungsdatum), Buchungsdatum, Buchungskreis, Währungsschlüssel, Referenz (Referenzbelegnummer zur Erfassung der Belegnummer externer Belege, z. B. der Bank), Belegkopftext (Erläuterungen), Belegart (Nummernkreis im SAP ERP).
* Belegposition(-Parameter) definieren: Buchungsschlüssel, die Nummer des Sachkontos, das bebucht werden soll, die Buchungsart, und den zu buchenden Betrag. Dabei gibt der Buchungsschlüssel,  wie eine Belegposition im System zu buchen ist. Der Buchungsschlüssel steuert, welche Kontenarten (Kreditoren-, Debitoren-, Sach-, Anlage- und Materialkonten) gebucht werden, ob eine Soll- oder Habenbuchung durchgeführt wird, und ob die Buchung umsatzwirksam ist.

Zur Information und Rechenschaftslegung über die Vermögens-, Finanz- und Ertragslage sind im Rahmen der Hauptbuchhaltung **Abschlussarbeiten** durchzuführen. Die Abschlussarbeiten werden unter SAP ERP zeitlich differenziert (Jahres-, Monats- und Tagesabschluss). Die Abschlussarbeiten des Jahresabschlusses umfassen die periodengerechte Abgrenzung der Aufwendungen und Erträge, die Bestandsaufnahme und Bewertung der Forderungen und Verbindlichkeiten und das Erstellen der Bilanz und GuV-Rechnung.

##### Funktionen der Kreditoren- und Debitorenbuchhaltung

Die Kreditoren- und Debitorenbuchhaltung erfasst alle Belege, die Geschäftsvorfälle mit Geschäftspartnern abbilden. Dazu gehören typischerweise die in Tab. 10.3 dargestellten Fälle.

\centerline{\includegraphics[width=1\textwidth]{img/103.png}}

Da es sich bei der Kreditoren- und Debitorenbuchhaltung um spiegelbildliche Prozesse handelt, wird an dieser Stelle nur auf die Debitorenbuchhaltung eingegangen, deren Funktionen in der nächsten Abbildung dargestellt werden.

\centerline{\includegraphics[width=1\textwidth]{img/1030.png}}

Zu den zentralen Aufgaben der **Stammdatenpflege** gehören das Anlegen, Ändern, Anzeigen und Löschen der Debitorenkonten. Wie bei den Sachkonten der Hauptbuchhaltung können Debitorenkonten auch zum Buchen gesperrt werden.

Der Bereich der **Belegbuchung** der Debitorenbuchhaltung wird hier auf die Basisbelege *Rechnung* und *Zahlungseingang* beschränkt. Die Erstellung einer Debitorenrechnung führt zu einer Sollbuchung auf dem Debitorenkonto und damit zu einer fälligen Forderung, die als *offener Posten* bezeichnet wird. Erfolgt der Zahlungseingang zum Ausgleich beispielsweise auf einem Bankkonto, so wird dieser Eingangsposten analog als *geklärt* gekennzeichnet. Als Ausgleichsvorgänge sind die folgenden Standardvorgänge definiert Zahlungseingang, Lastschrift und Umbuchung.

Das **Kreditmanagement** zählt zu den periodischen Arbeiten der Debitorenbuchhaltung. Kunden weisen im Allgemeinen unterschiedlich hohe Bonitätsgrade auf. Aufgrund dieser Tatsache wird die Annahme von Aufträgen erheblich beeinflusst. Um das Risiko durch einen möglichen Zahlungsausfall zu reduzieren, wird im Bereich des Kreditmanagements häufig mit Kreditlimits gearbeitet, die auf Debitorenebene individuell vergeben werden können.

Eine weitere periodische Funktion der Debitorenbuchhaltung ist das **Mahnwesen**. Voraussetzung für ein effektives Mahnwesen ist das Erfassen von Fälligkeitsterminen für den Zahlungsausgleich. Diese können ggf. automatisch bei der Rechnungserstellung vom System generiert oder manuell vom Sachbearbeiter festgelegt werden. Die im Rahmen des Mahnwesens zu verarbeitenden Daten werden in Abb. 10.33 anhand eines Datenflussdiagramms (DFD) dargestellt.

\centerline{\includegraphics[width=1\textwidth]{img/1033.png}}

Wird ein Mahnlauf durchgeführt, selektiert das Mahnprogramm aus den Debitorenstamm- und Belegdaten alle fälligen Forderungen, also die *offenen Posten*. Diese werden vom Mahnprogramm in einen eigenen *Mahnbestand* übernommen, aus dem der *Mahnvorschlag* zusammengestellt wird. Aus diesem Mahnvorschlag kann der Anwender die tatsächlich zu mahnenden Debitoren auswählen. Soll ein Debitor nicht gemahnt werden, obwohl eine Forderung nicht fristgerecht ausgeglichen wurde, kann eine Mahnsperre verhängt werden. Auch können im Mahnbestand die erforderlichen Mahnstufen vergeben werden, die vor Einleitung des gerichtlichen Mahn-/Zwangsvollstreckungs- bzw. Betreibungsverfahrens zu durchlaufen sind. Nach der Bearbeitung des Mahnvorschlags ist das Druckprogramm zu starten, bei dem standardisierte, unterschiedlich gestufte Mahntexte verwendet werden können.

Das Druckprogramm generiert neben den Mahnungen auch eine Mahnliste, die zur internen Dokumentation des Mahn(ab)laufs benötigt wird. Um beim nächsten Mahnlauf eines Debitors die Mahnstufe erhöhen zu können, ist deren Fortschreibung in den Belegdaten des Debitors erforderlich. Bei Erreichen der höchsten Mahnstufe kann automatisch ein Mahnbescheid generiert werden. Um ein positionsspezifisches Mahnen zu ermöglichen, werden die Mahnstufen auf der Ebene der Belegpositionen erfasst.

##### Funktionen der Anlagenbuchhaltung

Die zentralen Funktionen der Anlagenbuchhaltung zur Verwaltung von Sachanlagen werden in der nächsten Abbildung dargestellt.

\centerline{\includegraphics[width=1\textwidth]{img/1034.png}}

Die Stammdatenpflege der Anlagenbuchhaltung verwaltet alle langfristig konstanten Anlagendaten. Ein Anlagenstammsatz für ein Objekt ist beim Zugang einer Anlage aufgrund von Eigenfertigung oder Kauf zu erstellen. Der Stammsatz enthält sowohl sachbezogene Daten als auch organisatorische Zuordnungen (z. B. Geschäftsbereich, Standort) und Bewertungsparameter für die Fortschreibung der Anlage.

Die Geschäftsvorfälle der Anlagenbuchhaltung lassen sich anhand der folgenden Phasen differenzieren:

* Buchungen während des Baus der Anlage,
* Buchung bei Anlagenzugang,
* Buchungen während der Nutzungsphase der Anlage, und
* Buchungen bei Anlagenabgang.

Zu den grundlegenden Funktionen der Anlagenbuchhaltung gehört die Planung und Durchführung von **Abschreibungen im Zeitablauf (Abschreibungslauf)**. Die möglichen Abschreibungsarten werden differenziert in *Normalabschreibung* durch Werteverzehr im Rahmen des betrieblichen Leistungsprozesses, *Sonderabschreibung* durch wirtschaftspolitisch induzierte Rechtsnormen (z. B. in Form von Sonderabschreibungen für Umweltschutzanlagen) oder außerplanmäßige Abschreibungen durch dauerhafte Wertminderung. Die Basis für den Abschreibungslauf ist der Abschreibungsschlüssel.

#### Internes Rechnungswesen

\centerline{\includegraphics[width=1\textwidth]{img/1036.png}}

Zur Erfüllung der in Abb. 10.36 aufgeführten Funktionen hat die Kostenrechnung sämtliche relevanten Geschäftsvorfälle zu identifizieren und im Rahmen einer Grundrechnung zu erfassen. Auf der Basis dieser Dokumentationsfunktion sind Kontrollen und Entscheidungsunterstützungen möglich. Abb. 10.37 stellt den Weg der Kostenverrechnung bei einem System der *Teilkostenrechnung* dar, bei dem ein Kostenträger nur mit den variablen Kosten belastet wird. Diese Verrechnungsstruktur bildet die logische Grundlage für die hier darzustellenden Abläufe.

\centerline{\includegraphics[width=1\textwidth]{img/1037.png}}

Die Aufgabe der **Kostenartenrechnung** besteht in der Erfassung und Gliederung aller angefallenen Istkosten sowie in der innerbetrieblichen Leistungsverrechnung.

Die **Kostenstellenrechnung** hat die in der Kostenartenrechnung erfassten primären Gemeinkosten verursachungsgerecht weiterzuverrechnen und bildet damit für das Istkostenrechnungssystem auf Vollkostenbasis, in dem auch die fixen Kosten auf Produkte verteilt werden, das Bindeglied zwischen Kostenarten- und Kostenträgerrechnung. Leistungen, die von den Hilfskostenstellen für die Hauptkostenstellen erfolgen, werden dabei über periodenspezifische Bezugswerte abgerechnet. Die Aufgaben der Kostenstellenrechnung bestehen neben der Ermittlung von Gemeinkostenzuschlagssätzen für die Kalkulation in der Wirtschaftlichkeitskontrolle der Kostenstellen.

Die Aufgabe der **Kostenträgerrechnung** besteht darin, die Selbstkosten von Produkten, Aufträgen, Projekten oder anderen Kalkulationseinheiten (Marktleistungen oder innerbetriebliche Leistungen) zu ermitteln. Neben der Ermittlung von Selbstkosten dient die Kalkulation der Ermittlung der Herstellungskosten zur Bewertung von unfertigen und fertigen Erzeugnissen. Die Kostenträgerstückrechnung wird durch das gewählte Fertigungsverfahren bestimmt. Tab. 10.4 liefert einen Überblick über die Kalkulationsverfahren.

\centerline{\includegraphics[width=1\textwidth]{img/1037.png}}

#### Nutzung des SAP Enterprise Portal

Das SAP Enterprise Portal ist ein Portal, das auf dem SAP Application Server basiert und Benutzern eine Infrastruktur (Portal Infrastructure) zur Verfügung stellt, die einen gesicherten, verschlüsselten Zugriff auf Anwendungen und Daten erlaubt. Benutzer, die im SAP-System angelegt sind, können gemäß der ihnen zugewiesenen Rollen (z. B. Marketingleiter, Lagerarbeiter) auf vordefinierte Daten und Anwendungen zugreifen. Dazu ist lediglich ein Webbrowser auf dem lokalen Computer des Benutzers nötig. Über ein **Single Sign-on erfolgt** der Zugriff auf Daten und Applikationen verschiedener Unternehmensanwendungen. Das Single Sign-on-Konzept weist den Vorteil auf, dass der Portalbenutzer sich nicht an jedes einzelne System, das er in seiner personalisierten Portalumgebung eingebunden hat, anmelden muss. Vielmehr wird er nach einer einmaligen Registrierung am Portal automatisch bei den erforderlichen Teilsystemen angemeldet.

\centerline{\includegraphics[width=1\textwidth]{img/1038.png}}

Im Rahmen unternehmensübergreifender Geschäftsprozesse (Supply Chain Management) wird die Zusammenarbeit zwischen einem Unternehmen, seinen Zulieferern und Kunden durch ein solches Portal unterstützt. Durch die informationstechnologische Integration der Geschäftsprozesse können Kostensenkungspotenziale realisiert werden. So sind die Unternehmen in der Lage, individuelle Konditionen, den Lagerbestand des Lieferanten sowie den Lieferfortschritt einzelner Aufträge (Order Tracking) aktuell einzusehen. Lieferanten können ihren Kunden individuelle Kataloge per Internet zur Verfügung stellen und eine Onlinebestellung aus diesen Katalogen heraus ermöglichen. Nicht nur die Ausführung von Transaktionen über ein Portal ist möglich, sondern auch die Realisierung unternehmensinterner und -externer Gruppenarbeit (Collaboration). In virtuellen Gruppen wird internen und externen Personen die Möglichkeit zur Koordination von verteilten Geschäftsprozessen und verteilter Projektarbeit gegeben. Gruppen (z. B. Projektteams) können sich in virtuellen Räumen (Collaboration Rooms) zusammenfinden und die dort bereitgestellten Kollaborationsanwendungen nutzen.

### Sektorspezifische Anwendungen
#### Industriebetriebe
#####  Architektur klassischer PPS-Systeme

Die Anwendungsarchitektur für Industriebetriebe wird als Y-Modell dargestellt, dessen linker Ast mit der Produktionsplanung und -steuerung (PPS) vorwiegend betriebswirtschaftliche und dessen rechter Ast primär technische Funktionen enthält. Das Gesamtsystem wird auch als **Computer Integrated Manufacturing (CIM)-Konzept** bezeichnet (s. Abb. 10.40). Zunächst soll auf die **Produktionsplanungsund -steuerungssysteme (PPS-Systeme)** eingegangen werden. Dabei sind folgende Teilbereiche zu koordinieren:

* Programmplanung,
* Produktionsdurchführungsplanung, und
* Bereitstellungsplanung.

Zwischen diesen Teilbereichen bestehen vielfältige Abhängigkeiten, die dazu führen, dass für die operative Planung, Steuerung und Überwachung der Produktionsabläufe ein integriertes Softwaresystem erforderlich ist.

\centerline{\includegraphics[width=1\textwidth]{img/1040.png}}

##### Technische Komponenten

Die Gesamtarchitektur umfasst neben dem primär wirtschaftlich ausgerichteten PPS eine Reihe von Komponenten zur Unterstützung der Technik eines Industriebetriebs:

* **Computer Aided Design (CAD)**. CAD umfasst das computergestützte Entwerfen, Zeichnen und Konstruieren einschließlich der zugehörigen technischen Berechnungen. Hierbei werden ökonomische Fragen einbezogen und auch technische Alternativen bewertet, um zu einer effizienten Lösung zu gelangen.
* **Computer Aided Planning (CAP)**. Das CAP beinhaltet die rechnergestützte Arbeitsplanung, die sowohl eine konventionelle Planung (z. B. Materialbeschreibungen, technischer Fertigungsablauf) als auch eine Planung für NC- (Numeric Control) und DNC (Digital Numeric Control)-gesteuerte Fertigungsanlagen unterstützt.
* **Computer Aided Manufacturing (CAM)**. Unter CAM ist der Rechnereinsatz im Bereich der Fertigung (NC-Maschinen, Roboter) und der innerbetrieblichen Logistik zu verstehen, bei dem insbesondere der Materialfluss verbessert werden soll.

##### Integration

Wesentlich für das CIM-Konzept ist die Verknüpfung der Software des ERP-Systems mit der Produktionsplanung und -steuerung durch die Nutzung der technisch orientierten Verfahren (CAD, CAM, CAP) und durch den Zugriff auf eine einheitliche Datenbasis. Dadurch wird die Bedeutung einer integrierten Stammdatenbank für die beiden Bereiche des CIM-Konzepts deutlich (s. Abb. 10.41).

\centerline{\includegraphics[width=1\textwidth]{img/1041.png}}

#### Handelsbetriebe
##### Konzeptionelle Grundlagen

Handelsunternehmen sind dadurch charakterisiert, dass sie die Güterströme zwischen Wirtschaftssubjekten organisieren und koordinieren. Durch die Überbrückung *räumlicher, zeitlicher, qualitativer und quantitativer Diskrepanzen* wird letztlich der Konsum von Gütern und Dienstleistungen ermöglicht. Die zentralen Funktionen des Handels beziehen sich somit auf die *Beschaffung*, *Lagerhaltung* und die *Distribution* von Gütern. Die IS des Handels, die den physischen Warenstrom und sämtliche damit verbundenen Prozesse abbilden, werden als **Warenwirtschaftssysteme** bezeichnet. Ein Referenzmodell, das die Architektur von Warenwirtschaftssystemen beschreibt, ist das Handels-H-Modell in Abb. 10.42.

\centerline{\includegraphics[width=1\textwidth]{img/1042.png}}

##### Funktionen

Warenwirtschaftssysteme, wie sie beispielsweise von Kaufhaus- oder Supermarktketten eingesetzt werden, nutzen regelmäßig voll integrierte Kassensysteme (Point-of-Sale- Systeme). So werden die Artikel an der Kasse durch einen Laserscanner über die globale Artikelidentnummer (Global Trade Item Number, GTIN) mengenmäßig erfasst. So werden mittels GTIN aus den Artikelstammdaten die Artikelbezeichnung, der Preis und der Umsatzsteuersatz festgestellt und auf dem Kassenbeleg ausgedruckt.

Die Mengendaten der abgesetzten Artikel werden an die Lagerhaltung weitergeleitet, um eine Fortschreibung der Bestandsmengen durchzuführen. Bei Unterschreitung des Mindestbestands (Meldemenge) wird automatisch die Bestellung des entsprechenden Artikels beim Lieferanten ausgelöst. Der Umsatz wird auf den Erlöskonten der Buchhaltung gebucht. Aggregierte Umsatzdaten stehen dann zeitnah für Auswertungen durch Berichtssysteme zur Verfügung. Für den Zweck von Warenkorbanalysen im Rahmen innovativer Controllingkonzepte (Data Mining) ist es jedoch erforderlich, die Belegdaten einzelner Kaufereignisse unverdichtet (elementar) zu speichern. So sind die verfügbaren Daten, die einzelne Kaufprozesse charakterisieren, in einem eigenen Datenpool abzulegen, der für analytische Zwecke aufbereitet werden kann.

\centerline{\includegraphics[width=1\textwidth]{img/1043.png}}

#### Finanzdienstleister

Finanzdienstleistungen (FDL) umfassen Dienstleistungen, die in Verbindung mit Finanzgeschäften, aka **Finanzdienstleistungsunternehmungen (FDL-Unternehmungen)** stehen. Dazu zählen die von Bank- und Kreditinstituten sowie von Versicherungen erbrachten Leistungen, die Kundenprozesse mit überwiegend finanziellem Charakter (z. B. Alterssicherung, Zahlungsverkehr, Kredite, Vermögensanlage) durch Herstellung, Vermittlung/Handel, Integration, Beratung und/oder Abwicklung unterstützen.

Zusammenfassend lassen sich die Anwendungen für FDL-Unternehmen nach zwei Dimensionen strukturieren, wie in Abb. 10.44 gezeigt:

* **Kundenprozesse** in der horizontalen Dimension orientieren sich an den Bedürfnissen des Kunden und unterscheiden für den Bankbereich zwischen Finanzieren, Zahlen und Anlegen. Für den Versicherungsbereich stehen die Kundenprozesse Vorsorgen und Absichern im Mittelpunkt. Zusätzlich können Versicherungsprodukte wie Lebensversicherungen auch den Kundenprozess Anlegen betreffen. Sie deuten damit auf Überschneidungen von Versicherungen und Banken hin.
* **Unternehmensprozesse** in der vertikalen Dimension skizzieren die wesentlichen Geschäftsprozesse eines Finanzdienstleisters. Zu unterscheiden sind Führungs-, Leistungs- und Unterstützungsprozesse, wobei sich die Leistungsprozesse in Vertriebs- und Ausführungs-/Abwicklungsprozesse sowie transaktionsbezogene und -übergreifende Prozesse aufgliedern lassen. Eine Unterscheidung zwischen Banken und Versicherungen ist in der vertikalen Dimension nicht erforderlich.

\centerline{\includegraphics[width=1\textwidth]{img/1044.png}}

Grundsätzlich unterscheiden Finanzdienstleister zwei Anwendungsbereiche:

* **Frontoffice-Anwendungen** unterstützen Vertriebsprozesse zur Kundenberatung und -betreuung „vor Ort“, die in einer (physischen) Filiale ebenso wie im Call Center oder im Bereich der elektronischen Medien (Social, Online oder Mobile Banking) angesiedelt sein können.
* **Backoffice-Anwendungen** bezeichnen die kundenfernen Anwendungen, die z. B. die Abwicklung und Verwaltung von Krediten, Kapitalanlagen und Zahlungen vornehmen. Die Anwendungen besitzen Schnittstellen zur Bankenwertschöpfungskette, etwa anderen Spezialdienstleistern (z. B. für das Scanning von papierhaften Belegen) oder Dienstleistern aus dem Interbankenbereich (z. B. Swift, Target, Finanzbörsen).

Grundsätzlich sollte sich die Strukturierung von Anwendungen an fachlichen und weniger an technischen oder physischen Aspekten, wie z. B. „Filiale“ oder „Zentralrechenzentrum“, orientieren. Damit stehen längerfristig stabile Dimensionen wie Funktionalitäten, Datenverwendung und Verantwortlichkeiten im Vordergrund, auf denen Entwicklungs-, Integrations- und Architekturprojekte aufbauen können. Mögliche Ausnahmen entstehen, wenn Funktionen, Daten und Verantwortlichkeiten kanalspezifisch ausfallen (z. B. Social Media, Bankschalter in Abb. 10.44). Die IS-Architekturplanung versucht gewachsene, und durch viele Überschneidungen und Lücken gekennzeichnete Anwendungslandschaften in Richtung einer „sauberen“ Zielarchitektur zu entwickeln.Eine solche Anwendungslandschaft besteht aus folgenden Komponenten:

* **Vertikale Anwendungen** unterstützen produktspezifische Abwicklungsprozesse, die meist mit bestimmten Organisationsbereichen verbunden sind (z. B. Kredite, Zahlungsverkehr, Wertpapiere, Lebensversicherung, Nicht-Lebensversicherung).
* **Horizontale Anwendungen** unterstützen produktübergreifende Zugangs- und Vertriebsprozesse, die an einen bestimmten Kanal gebunden sind, d. h. um bestimmte Funktionalitäten herum integriert sind (z. B. Vertriebsprozesse, transaktionsübergreifende Prozesse).
* **Analytische Anwendungen** unterstützen Führungsprozesse durch Bereitstellung von aufbereiteten Informationen auf Basis von Daten aus operativen Anwendungen (z. B. Führungsprozesse, Kundensegmentierung).

#### Telekommunikationsdienstleister

Als Basis zur Identifikation und Systematisierung relevanter Prozesse von Telekommunikationsdienstleistern hat die **enhanced Telecom Operations Map (eTOM)** weite Verbreitung gefunden. Dabei handelt es sich um einen Ordnungsrahmen für Geschäftsprozesse (Business Process Framework). Einen Überblick über das eTOM-Modell liefert Abb. 10.45.

\centerline{\includegraphics[width=1\textwidth]{img/1045.png}}

Im eTOM-Modell werden drei Hauptprozessgruppen für Telekommunikationsdienstleister unterschieden:

* Managementprozesse des Unternehmens (**Enterprise Management**),
* Entwicklungsprozesse (**Strategy, Infrastructure & Product**), und
* operative Prozesse des Betriebs (**Operations**).

Die erste Hauptprozessgruppe **Enterprise Management** umfasst Tätigkeiten, die generell – d. h. unabhängig vom betrachteten Sektor – zur Führung eines Unternehmens erforderlich sind und in jedem größeren Unternehmen anzutreffen sind.

Die zweite Hauptprozessgruppe hat solche Tätigkeiten zum Gegenstand, die der langfristigen, lebenszyklusübergreifenden Entwicklung und Ausrichtung von Strategien, Infrastrukturen sowie Produkten dienen (**Strategy, Infrastructure & Product**). In diesem Bereich findet auch eine vertikale Aufgliederung in unterschiedliche Ebenen statt, die auf unterschiedliche Phasen der Wertschöpfung vom Lieferanten bis hin zum Kunden Bezug nehmen:

* Die unterste Ebene umfasst den strategischen Einkauf bzw. die Beschaffung notwendiger Ressourcen (Supply Chain Development & Management).
* Die beschafften Ressourcen fließen dem Unternehmen zu und werden als Komponenten zum Aufbau von Kommunikationsnetzen eingesetzt (Resource Development & Management). Typische Komponenten sind z. B. systemtechnische Elemente wie Router, Ports und Einschubkarten.
* Im Bereich Service Development & Management findet die Entwicklung von Services statt, die als funktionelle Einheiten zur Abdeckung von Kundenanforderungen dienen. Typische Services von Telekommunikationsdienstleistern sind z. B. Internetzugänge, Telefonanschlüsse, Web Space und E-Mail-Adressen.
* Auf der Ebene Marketing & Offer Management werden die Services schließlich zu Produkten gebündelt und als kundengerichtete Leistungsangebote am Markt platziert.

Diese vertikale Aufgliederung wird auch in der Hauptprozessgruppe **Operations** berücksichtigt. Gegenstand dieser Gruppe sind die operativen Prozesse der Leistungserstellung, deren inhaltlich-funktionalen Schwerpunkte in der horizontalen Aufgliederung zum Ausdruck gelangen. Neben Supportaktivitäten (Operations Support & Readiness) gehören hierzu vor allem Prozesse zur Belieferung (Fulfillment), Qualitätssicherung (Assurance) und Fakturierung (Billing). Diese drei Prozessbereiche bilden die sog. FAB-Prozesse, die direkt mit dem Kunden interagieren und im operativen Tagesgeschäft von Telekommunikationsdienstleistern von erheblicher Bedeutung sind:

* *Fulfillment-Prozesse* beinhalten solche Tätigkeiten, mit denen bestellte Produkte bzw. deren Services konfiguriert und anschließend an den Kunden bzw. Endanwender ausgeliefert bzw. geschaltet werden.
* *Assurance-Prozesse* stellen sicher, dass die produktspezifischen Services zur Verfügung stehen und den vertraglichen Vereinbarungen (Service Level Agreements) entsprechen. Hierzu kann z. B. ein proaktives Performance Monitoring erfolgen, das die Verfügbarkeit der zugesicherten Services kontinuierlich überwacht.
* *Billing-Prozesse* haben die Erstellung und den Versand von Rechnungen zum Inhalt. In diese Fakturierungsprozesse können auch mengenorientierte Daten wie z. B. übertragene Datenvolumina einfließen, die auf der Ressourcen- bzw. Netzwerkebene erhoben worden sind und zur Tarifermittlung dienen.

In der Telekommunikationsindustrie werden üblicherweise Operations- und Business-Support-Systeme unterschieden:

* **Operations-Support-Systeme (OSS)** dienen der Unterstützung von Betrieb und Wartung der Telekommunikationsinfrastruktur. Hierzu gehören Elemente der Linientechnik, wie etwa Erdkabel und Verteiler, sowie Komponenten der Systemtechnik zur Vermittlung und Dienstbereitstellung.
* **Business-Support-Systeme (BSS)** werden eingesetzt, um kundenorientierte Prozesse zu unterstützen. Hierzu gehören insbesondere Aufgabenstellungen des Vertriebs und des Kundenservice, sodass der Kern eines BSS durch ein CRM-System gebildet wird.

#### Energiewirtschaft

Die für den Energiesektor wesentlichen Prozesse und Akteure werden in Abb. 10.46 dargestellt.

\centerline{\includegraphics[width=1\textwidth]{img/1046.png}}

Aus der Darstellung wird deutlich, dass Energiehandelstransaktionen entweder zentral über die Börse – z. B. die European Energy Exchange in Leipzig (EEX) – oder außerbörslich als Folge einer Direktvermarktung (als OTC-Geschäft, Over the Counter) zustande kommen. Die Abwicklung des börslichen Energiehandels wird von einem Clearinghaus übernommen. Die Aufgabe des Clearinghouse besteht darin, als neutraler, zentraler Kontrahent (Central Counterparty, CCP) zwischen den Vertragspartnern für die Erfüllung der Geschäfte zu sorgen. Zu diesem Zweck werden etwa die gegenseitigen Forderungen und Verbindlichkeiten von Anbietern und Nachfragern gegeneinander aufgerechnet (Netting) und schließlich finanziell ausgeglichen.

Zur physischen Abwicklung der Transaktion ist die gehandelte Strommenge über Netze zu liefern, die durch Netzbetreiber zur Verfügung gestellt werden. Während Übertragungsnetzbetreiber (Transmission System Operator, TSO) die Höchstspannungsnetze zur überregionalen Energieübertragung operativ betreiben, dient das Verteilnetz zur Anbindung von Endverbrauchern (z. B. private Haushalte, Unternehmen).

Zur Koordination der Lieferprozesse erfolgt eine Fahrplananmeldung, mit der die Netzbetreiber über die aus den Handelstransaktionen resultierenden Stromlieferungen informiert werden. Die Produktion der erforderlichen Strommengen findet durch dedizierte Stromerzeuger bzw. Kraftwerke oder aber auch durch dezentrale Haushalte statt, die durch die Nutzung regenerativer Energiequellen als Prosumer auftreten. Die Verbrauchserfassung erfolgt durch entsprechende Messgeräte (z. B. Smart Meter), die von Messstellenbetreibern (MSB) installiert, betrieben und abgelesen werden. Diese Daten bilden schließlich auch die Abrechnungsgrundlage für den Verteilnetzbetreiber, der die verbrauchte Strommenge den Endverbrauchern in Rechnung stellt.

Weitere Impulse erhalten IS in der Energiewirtschaft aktuell durch die Nutzung von Blockchain-Technologien. Mithilfe der Blockchain wird es möglich, direkte Handelstransaktionen (Peer-to-Peer-Transaktionen) mithilfe von Smart Contracts zu initiieren. Ein Smart Contract ist ein Programmcode, der auf einer Blockchain ausgeführt wird und digitale Güter oder Rechte zwischen mehreren Akteuren regelbasiert zuordnet. Ein vereinfachtes Beispiel für einen solchen Smart Contract zeigt die nächste Abbildung.

\centerline{\includegraphics[width=1\textwidth]{img/1047.png}}

In diesem Smart Contract wird mithilfe von Wenn-Dann-Regeln gesteuert, wie selbst erzeugte Energie – etwa aus einem Windkraftwerk – zu handhaben ist. Für jede erzeugte Kilowattstunde (kWh) wird zunächst ein Token als Abrechnungseinheit erzeugt. Anschließend wird geprüft, ob die erzeugte Energie am Markt verkauft werden soll, oder aber einem Speicher zuzuführen ist. Diese Entscheidung erfolgt in Abhängigkeit vom aktuellen Strompreis, der z. B. über die Börse bereitgestellt wird.

### Einführung von ERP-Systemen als Standardsoftware
#### Vorgehensmodell zur ERP-Einführung

Die Realisierung von ERP-Systemen erfolgt in der Regel auf Grundlage von Standardsoftwareprodukten,
die am Softwaremarkt verfügbar sind. Ein projektorientiertes
Vorgehensmodell für die ERP-Einführung zeigt Abb. 10.48.

\centerline{\includegraphics[width=1\textwidth]{img/1048.png}}

Kriterien für die Auswahl von Standardsoftware:

* **Anbieterqualifikation**: Wie hoch ist die Reputation des Anbieters, die Qualifikation seiner Entwickler und Berater sowie die Wahrscheinlichkeit, dass das Softwareprodukt über einen langen Zeitraum weiterentwickelt wird? Gibt es Updates bzw. Upgrades und müssen diese gesondert bestellt und bezahlt werden (Releasepolitik)?
* **Schnittstellen**: Sind Standardschnittstellen zu umgebenden Systemen vorhanden? Erzielt man eine gewisse Unabhängigkeit von der eingesetzten Betriebssystem- und Kommunikationssoftware? Gibt es Schnittstellen zu bereits in dem Unternehmen vorhandenen Anwendungen bzw. wie hoch sind die Kosten, um diese zu realisieren? Werden die bereits eingesetzten elektronischen Systeme (z. B. Electronic Mail, Workflow- Systeme, EDI) unterstützt?
* **Endbenutzerfähigkeit**: Wird die Bedienung durch Funktionstasten/Shortcuts und Menüsteuerung unterstützt? Gibt es Auswertungsmöglichkeiten ohne Programmiersprachenkenntnisse?
* **Softwareanpassungen**: Wie gut werden individuelle Anpassungen unterstützt? Gibt es eine Entwicklungsumgebung bzw. Schnittstellen zu einer Standard-CASE-Umgebung? Sind für einfache Anpassungen Programmierkenntnisse notwendig?
* **Zugriffsschutz, Datensicherheit**: Wie differenziert und flexibel ist das Berechtigungsund Sicherungskonzept des Softwareprodukts?
* **Performance**: Ist das Softwareprodukt in der Lage, die aufkommenden Datenvolumina zu bewältigen? Welche Zugriffs- bzw. Laufzeiten können garantiert werden?
* **Kosten/Nutzen**: Wie hoch sind die Kosten für Softwarelizenz, Wartung und notwendige Hardwareplattform? Wie stark steigert das Softwareprodukt die Effektivität und Effizienz der Geschäftsprozessausführung? Welche finanziellen und personellen Ressourcen müssen für Einführung, Wartung, Schulung und Beratung bereitgestellt werden?

Anpassung von Standardsoftware (Customizing):

* Durch **Parametereinstellung** werden Softwareanpassungen an individuelle Bedürfnisse ohne Programmänderungen vorgenommen. Die gewünschten Anpassungen werden durch Veränderung bestimmter Parameter (z. B. Systemtabellen) erreicht. Voraussetzung ist, dass möglichst viele Programmfunktionen in der Software enthalten sind, deren Ausführung parametrisiert wurde.
* Unter **Ergänzungsprogrammierung** (oder allgemeiner **Individualprogrammierung**) ist eine Softwareanpassung durch individuell erstellte Programmänderungen zu verstehen. Mit Individualprogrammierung lassen sich zwar spezifische, funktionale Anforderungen am besten realisieren. Es handelt sich aber um eine kostenintensive Anpassung, durch die darüber hinaus die Fähigkeit verloren gehen kann, an Weiterentwicklungen der Standardsoftware durch Einspielen von Upgrades oder Patches automatisch zu partizipieren (sog. **Releasefähigkeit**).
* Bei der **Konfigurierung** (Modularisierung) wird die Standardsoftware durch die Auswahl benötigter Programmbausteine (Module) und die Definition der Beziehungen zwischen den Programmbausteinen gebildet.

Einführung und Integration von Standardsoftware: Die Einführung von Standardsoftware kann

* zu einem Stichtag unter Ablösung der alten Systeme (welche gegebenenfalls noch eine Zeitlang im Parallelbetrieb laufen) erfolgen, wobei alle abgedeckten Geschäftsprozesse betroffen sind („Big Bang“).
* stufenweise für einzelne Geschäftsprozesse oder Softwaremodule erfolgen,
* stufenweise für einzelne Unternehmensbereiche erfolgen (z. B. erst Mutterkonzern und dann die Töchter und Vertriebsgesellschaften).

#### SAP Activate als Vorgehensmodell zur Einführung von SAP ERP

**SAP Activate** ist ein Vorgehensmodell zur Einführung von SAP ERP-Systemen. Dieses basiert auf einem agilen Entwicklungsansatz und wird in der nächsten Abbildung dargestellt. Hervorzuheben ist, dass dieses Vorgehensmodell keine Auswahl zwischen unterschiedlichen Systemalternativen vorsieht, sondern bereits die Entscheidung für ein SAP-System voraussetzt.

\centerline{\includegraphics[width=1\textwidth]{img/1049.png}}

In der ersten Phase **Discover** wird die SAP-Lösung zunächst in einer Cloud-basierten Versuchsumgebung getestet, um erste Erfahrungen mit dem IS zu sammeln. In der anschließenden Phase **Prepare** erfolgt die eigentliche Projektvorbereitung und Projektplanung, die insbesondere auch die notwendigen ERP-Infrastrukturen (z. B. Auslegung von Hardware und Netzwerkressourcen) umfasst. Im Anschluss findet die Definition der geschäftskritischen Anforderungen statt, die ausführlich zu  dokumentieren sind (**Explore**). Die Realisierung (Phase **Realize**) bildet die eigentliche Entwicklungsphase im Vorgehensmodell, in der die SAP ERP-Lösung konfiguriert wird und die notwendigen Anpassungen durchgeführt werden. Sofern die Geschäftsprozessanforderungen durch das ERP-System erfüllt werden, erfolgt die Produktionsvorbereitung (**Deploy**), womit das System mit den notwendigen Daten für den Produktivbetrieb vorbereitet wird. In der letzten Phase (**Run**) wird von der vorproduktiven Umgebung in den Dauerbetrieb gewechselt.

Projektphasen von ASAP (Accelerated SAP – ein Vorgehensmodell, das den schnellen Einstieg in das SAP ERP Einführungsprojekt ermöglichen soll):

* Projektvorbereitung: Ein klares Projektziel und eine effiziente Vorgehensweise werden durch die Entscheidungsträger definiert. Der Projektauftrag wird erstellt, die Einführungsstrategie festgelegt und das Projektteam und das Arbeitsumfeld gebildet.
* Business Blueprint: Die Dokumentation und Definition der SAP ERP Einführung, der sogenannte Business Blueprint wird erstellt. Der Business Blueprint dient dem Verständnis des Prozessablaufes im SAP ERP. D.h. das Projektteam entwickelt ein Konzept, wie das Handlungsprodukt aussehen soll bzw. wie die Dienstleistung umgesetzt und wie der Lösungsweg aussehen wird.
* Realisierung: Ziel dieser Phase ist das Customizing des SAP ERP Systems, um zu einer den Geschäftsanforderungen passenden Lösung zu kommen.
* Produktionsvorbereitung: Mit dem Testen und der Benutzerschulung wird das ERP System auf die Produktivphase vorbereitet.
* Go live und Support:  In dieser Phase starten bereits Nachfolgeprojekte, um neue Anwendungskomponenten zu implementieren oder Geschäftsprozesse zu automatisieren und zu verbessern.

#### Open Source Software

Bei der Einführung von ERP-Systemen entscheiden sich Unternehmen häufig für kommerzielle Standardsoftwareprodukte spezieller Anbieterunternehmen, für die entsprechende Lizenzen erworben werden müssen. Eine Alternative hierzu bildet Open Source Software, die für unterschiedliche Anwendungsfelder zur Verfügung steht.

**Open Source Software (OSS)** bezeichnet Software, deren Programme als Quellcode (Source Code) in verständlicher Form frei verfügbar sind und bei der die Nutzer auch das Recht haben, den Programmcode zu verändern und ohne Zahlung eines Kaufpreises zu nutzen. Die Nutzer bzw. nutzenden Unternehmen können diese Programme für ihre Zwecke verändern, Verbesserungen entwickeln und Fehler beseitigen. Die Nutzer haben das Recht, alle Änderungen und Verbesserungen am Quellcode weiterzugeben. Kein Unternehmen besitzt die Exklusivrechte an der Software, d. h. die Open Source Software steht allen offen.

Beispiele für Open Source Programme:

* Betriebssysteme: GNU/LINUX, Android
* Betriebliche Standardsoftware (z. B. ERP Software): ADempiere, Apache OFBiz, Metasfresh
* Customer Relationship Management Systeme : Vtiger, SuiteCRM, FreeCRM
* Geschäftsprozess und Workflowmanagement: Bonita BPM, Camunda, Activiti
* Content Management Systeme : Drupal, Joomla!, Neos, Plone, TYPO3
* E Learning Software: Moodle, ILIAS, Sakai
* Büroanwendungen: OpenOffice, LibreOffice, Calligra Suite, NeoOffice
* Grafikanwendungen: GIMP, Scribus
* Datenbanken: MySQL, PostgreSQL, Interbase
* Programmiersprachen: Perl, PHP, Python, Ruby, Free Pascal, FreeBasic
* Entwicklungswerkzeuge: Ant, Make, Maven, GIMP Toolkit, KDevelop, Eclipse, GNU Compile Collection (GCC), CVS

Die folgenden Stärken von Open-Source-Software beeinflussen die Entscheidung für eine OSS-Lösung in dem Unternehmen:

* Der offene Quellcode der OSS erhöht die Unabhängigkeit von einem Hersteller.
* Geringerer Lock-In-Effekt, da keine prinzipielle marktbeherrschende Position eines Anbieters vorliegt.
* Keine Lizenzkosten und geringere Erweiterungs- und Wartungskosten als bei vielen proprietären Programmen.
* Etwaige Softwarefehler können von der Entwicklergemeinschaft, die sich dem Open-Source-Gedanken verpflichtet fühlen, behoben werden.
* OSS kann durch unmittelbare Änderung des Quellcode an eigene Bedürfnisse angepasst werden.
* Das Unternehmen kann gegebenenfalls von fremden Erweiterungen der OSS profitieren.
* Größere Zukunftssicherheit, da kein einzelnes Unternehmen, sondern eine Gemeinschaft die Weiterentwicklung unabhängig von finanziellen Aspekten sicherstellen kann.

Die folgenden Schwächen von OSS sollten berücksichtigt werden:

* Ggf. Schwierigkeiten beim Daten- und Dokumentenaustausch zwischen einzelnen Lösungen.
* Die Hardwareunterstützung weist in manchen Fällen, z. B. bei hardwarebeschleunigten Grafikkarten oder bei Multimedia-Geräten, wie z. B. Scannern, Mängel auf.
* Beschaffung von Informationen zu einzelnen OSS-Lösungen ist teilweise problematisch.

Folgende Punkte sollten bei der Auswahl einer OSS-Lösung bedacht werden:

* *Support*: Da für Anpassung und Support qualifiziertes Personal notwendig ist, muss geprüft werden, ob Dienstleister beauftragt werden können oder hinreichende interne Ressourcen zur Verfügung stehen. Für verbreitete OSS stehen häufig Dienstleistungen über das Internet zur Verfügung.
* *Dokumentation*: Nicht immer ist eine umfangreiche Nutzerdokumentation zu der OSS verfügbar.
* *Verbreitungsgrad*: Die Verbreitung der OSS beeinflusst die Größe der Entwicklergemeinschaft.

## Kapitel 11: Anwendungen zur Entscheidungsunterstützung

Dieses Kapitel stellt solche Anwendungen dar, die der Rationalitätssicherung von Entscheidungsprozessen in Unternehmen dienen. Aufbauend auf den allgemeinen Komponenten solcher dispositiven bzw. analytischen Anwendungen werden Anwendungsbeispiele für aufgabenorientierte Lösungen zur betrieblichen Entscheidungsunterstützung vorgestellt.

### Überblick

Unter dem Begriff **Entscheidungsunterstützungssystem (EUS)** werden Anwendungen verstanden, die Entscheidungsträger zur Rationalitätssicherung in Entscheidungsprozessen einsetzen. EUS sind zur Kategorie der *Systems of Insight* zu zählen, da sie – aufbauend auf verfügbaren Realdaten – zur Gewinnung neuer Erkenntnisse beitragen.

Kategorien von EUS:

* **Datenorientierte EUS** dienen der Überwachung (Monitoring), Beschaffung, Aufbereitung und Verdichtung von Daten. Im Verarbeitungsfokus solcher datenorientierter Systeme steht die Ermittlung betriebswirtschaftlicher Kennzahlen, die beispielsweise in Form von Berichten (Reports) bereitgestellt werden. Solche EUS werden in der Initialphase von Entscheidungsprozessen eingesetzt, um die Problemidentifikation zu unterstützen, oder aber in der Kontrollphase verwendet, um Abweichungsanalysen durchzuführen.
* **Modell- bzw. methodenorientierte EUS** gestatten die Anwendung komplexer, formaler Methoden zur Konstruktion problemorientierter Modelle. Hierbei können z. B. Simulations-, Optimierungs- oder auch explorative Methoden zur Anwendung kommen. Solche Verfahren werden vorzugsweise in den späteren Teilphasen des Entscheidungsprozesses eingesetzt, um die Alternativensuche, die Alternativenbewertung sowie die Finalentscheidung zu unterstützen.

Bei der Gestaltung von EUS ist daher kritisch zu hinterfragen, ob deren Informationsangebot am **subjektiven Informationsbedarf** der Entscheidungsträger auszurichten ist, oder aber am **objektiven Informationsbedarf**, der beispielsweise durch den State of the Art in der betriebswirtschaftlichen Literatur, Referenzmodelle oder fachkundige Experten für das jeweilige Entscheidungsproblem vorgegeben wird. Zur Erhebung des subjektiven Informationsbedarfs betrieblicher Entscheidungsträger stehen unterschiedliche Datengewinnungsmethoden zur Verfügung:

* **Befragung** der Entscheidungsträger in Form von Interviews oder schriftlichen Befragungen,
* **Beobachtung** des Informationsbeschaffungsverhaltens von Entscheidungsträgern in direkter und indirekter Form (z. B. durch Protokollierung des Suchverhaltens im Intranet), und
* **Inhaltsanalyse** von relevanten Dokumenten (z. B. Prozessbeschreibungen für Planungs- und Entscheidungsprozesse).

Der Nutzerkreis von EUS umfasst grundsätzlich sämtliche Personen der *Leitungsebene*, die in der betrieblichen Praxis mit der Handhabung und Lösung von Entscheidungsproblemen beauftragt sind.

Die aktuelle Diskussion von EUS wird in der Wirtschaftsinformatik durch den Oberbegriff **Business Analytics** geprägt. Dabei werden drei unterschiedliche Ausrichtungen von EUS differenziert:

* **Descriptive Analytics**: Deskriptive Analysesysteme gestatten eine kennzahlenorientierte Auswertung großvolumiger Daten. Ein exemplarischer Anwendungsfall solcher EUS ist etwa die Berichterstattung über diejenigen Kunden, die ihre Geschäftsbeziehung aufgelöst haben (Abwanderer).
* **Predictive Analytics**: Mithilfe multivariater Analyseverfahren können Modelle generiert werden, die anschließend zur Prognose (Prädiktion) und Klassifikation von Geschäftsobjekten (z. B. Kunden, Aufträge, Maschinen) dienen. Auf diese Weise kann beispielsweise das künftige Abwanderungsverhalten von Kunden prognostiziert werden.
* **Prescriptive Analytics**: Diese Kategorie umfasst die Konstruktion normativer (präskriptiver) Entscheidungs- bzw. Optimierungsmodelle, die in gut strukturierten Entscheidungssituationen konkrete Handlungsempfehlungen liefern. Mit solchen Techniken können beispielsweise Empfehlungen generiert werden, wie abwanderungsgefährdete Kunden am besten an das Unternehmen gebunden werden können.

Zwar greifen EUS auf die operativen Datenbestände des Unternehmens zu (Systems of Record), doch unterscheiden sie sich in der Art der Verarbeitung dieser Daten erheblich von operativen Anwendungen. Während die operativen Systeme auf dem Grundsatz der transaktionsorientierten Verarbeitung von Massendaten (Online Transaction Processing, OLTP) basieren, fokussieren EUS eine entscheidungsorientierte Verarbeitung von Massendaten. Die Unterschiede dieser beiden Verarbeitungsparadigmen werden in Tab. 11.1 dargestellt.

\centerline{\includegraphics[width=1\textwidth]{img/111.png}}

Unter **Business Intelligence (BI)** ist ein Gesamtansatz zu verstehen, mit dem Komponenten für die Beschaffung, Aufbereitung und Bereitstellung von gut strukturierten, tabellarischen Daten zur Unterstützung betrieblicher Entscheidungsprozesse zusammengeführt werden. Der generelle Aufbau eines BI-Systems stellt die nächste Abbildung dar.

\centerline{\includegraphics[width=1\textwidth]{img/BI.png}}

Die Grundlage von BI-Systemen bildet die **originäre Datenschicht**. Diese umfasst sämtliche Datenbestände, die für die Entscheidungsunterstützung aufzubereiten sind und aus unternehmensinternen bzw. -externen Quellen stammen können. Die Datenbestände werden in einem Data-Warehouse-System abgelegt, das als zentraler Datenspeicher dient und somit die **Bereitstellungsschicht** darstellt. Die bereitgestellten Daten können anschließend mithilfe von Anwendungsprogrammen verarbeitet werden, die auf der **Dialog- und Analyseschicht** angesiedelt sind. Neben Data-Mining-Systemen werden zu diesem Zweck häufig Berichtssysteme und Systeme für das Online Analytical Processing (OLAP) eingesetzt.

### Allegemeine Komponente von EUS
#### Data-Warehouse-Konzept

Ein **Data Warehouse** ist ein themenorientierter, integrierter, nicht flüchtiger und zeitvarianter Datenspeicher.

So bedeutet die themenorientierte Datenhaltung, dass die Informationsobjekte eine abbildungsorientierte Aufbereitung der realen Informationsobjekte hergestellt wird. Das Data Warehouse integriert sämtliche Daten aus den verfügbaren Datenbeständen des Unternehmens. Durch diesen Prozess wird im Gegensatz zur klassischen Datenhaltung eine einheitliche Sicht auf den gesamten Unternehmensdatenbestand ermöglicht. Als weiteres Merkmal sind die Datenelemente des Data Warehouse als nicht flüchtig anzusehen, d. h., sie können nicht durch den Eingriff der operativen Systeme gelöscht oder manipuliert werden. Zudem erfolgt im Data Warehouse die explizite Erfassung des Faktors Zeit als Bezugsgröße. Durch dieses Merkmal der Zeitabhängigkeit können dynamische Entwicklungen einzelner Datenelemente verdeutlicht werden.

Beim Data Warehouse handelt es sich nicht um ein monolithisches Element, sondern um ein komplexes System, das in der BI-Architektur zwischen den Analysewerkzeugen und den originären Datenquellen eingegliedert ist.

\centerline{\includegraphics[width=1\textwidth]{img/114.png}}

Bei den *internen Datenquellen* handelt es sich um Daten, die in den operativen Systemen des betreffenden Unternehmens gespeichert werden. Bei den *externen Datenquellen* handelt es sich um Daten, die durch Fernübertragung von externen Anbietern in das Unternehmen gelangen, beispielsweise über das Internet.

Flows in DWH:

* Damit die operativen Daten oder auch Daten aus externen Quellen ins Data Warehouse integriert werden können und dort in einer einheitlichen Form vorliegen (**In-Flow**), sind Extraktions-, Transformations- und Ladeprozesse (ETL-Prozesse) erforderlich.
* Sind die Daten aus den operativen Systemen herausgezogen und bereinigt, stellt sich die Frage, wo und in welcher Form sie im Data Warehouse abgelegt werden sollen. Diese Aufgabenstellung wird als **Up-Flow** bezeichnet.
* **Meta Flow**: Bezieht sich auf (Meta)Daten, die die Nutzdaten und ihre Entstehung beschreiben.
* **Down Flow**: Bezieht sich auf das interne Informationsmanagement innerhalb der DWH Ebene und insb. auf die Archivierung älterer Daten.
* **Out Flow**: Data Warehouse Prozess, der die Daten dem Anwender durch Export aus dem DWH zur Verfügung stellt.

Der Zweck des Data-Warehouse-Datenbestands, der auch als **Kerndatenbestand** bzw. **Core Data Warehouse** bezeichnet wird, besteht darin, eine möglichst universelle, vielfältig auswertbare Datenbasis zur betrieblichen Entscheidungsunterstützung zur Verfügung zu stellen.

Entscheidungsträger werden mit dispositiven Daten entweder durch unmittelbaren Zugriff auf den Kerndatenbestand oder aber mithilfe von **Data Marts** versorgt, die als abhängige Teildatenbestände aus dem Kerndatenbestand abgeleitet werden.

**Metadaten** dienen der Dokumentation fachlicher und technischer Sachverhalte über die im Data Warehouse vorgehaltenen Daten und der zu deren Erzeugung erforderlichen Prozesse. Sie dienen nicht nur der Steuerung des Data-Warehouse-Betriebs, sondern können auch Endbenutzer bei der Interpretation und Suche nach Daten unterstützen.

Das **Archivierungssystem** übernimmt hingegen die Funktion, (Meta-)Datenbestände des Data-Warehouse-Systems zu sichern. Hiermit wird einerseits die Zielsetzung der Datensicherung verfolgt, sodass nach Eintritt von Fehlern eine Rekonstruktion des Data Warehouse erfolgen kann. Andererseits können im Zuge der Archivierung gezielt solche Daten aus dem Kerndatenbestand ausgelagert werden, die nur selten benötigt werden.

#### Berichtssysteme

Die in diesen Berichtssystemen erzeugten Berichte (Reports) sollen der Leitungsebene inhaltlich richtige und relevante Informationen zur Verfügung stellen.

In **aktiven Berichtssystemen** erfolgt die automatische Erstellung der Reports zu bestimmten Zeitpunkten oder bei bestimmten Datenkonstellationen. Wird die Berichtserstellung periodisch, wird das Ergebnis als **Standardbericht** bezeichnet. Erfolgt die Auslösung der Reportgenerierung hingegen aperiodisch und in Abhängigkeit von bestimmten Datenkonstellationen, werden die erzeugten Berichte als **Ausnahmebericht (Exception Reporting)** charakterisiert.

Dagegen wird in **passiven Berichtssystemen** die Berichtserstellung durch den Benutzer ausgelöst. In derartigen Systemen hat der Benutzer die Möglichkeit, durch Interaktion mit dem Berichtssystem individuelle Reports zu erstellen, die auf die gewünschte Fragestellung Antwort geben. Um die Anfertigung zu erleichtern, stellen Berichtssysteme hierfür häufig vorgefertigte, parametrisierbare Standardberichte zur Verfügung, die in sog. **Berichtsheften (Briefing Books)** verwaltet werden.

Eine grundlegende Eigenschaft von Berichtssystemen ist darin zu sehen, dass Berichte lediglich in der Lage sind, vorab fest definierte Sichten auf die zugrunde liegenden Daten zu erschließen. Eine freie Analyse der Datenbasis wird nicht unterstützt. Diese Möglichkeit wird hingegen von OLAP-Systemen erschlossen, die nun zu erörtern sind.

#### OLAP-Konzept

Während OLTP für die Verwaltung operativer Daten entwickelt wurde, zielt das OLAP-Konzept darauf ab, Daten (auch aus OLTP-Systemen) speziell für *analytische multidimensionale Fragestellungen* aufzubereiten. Das OLAP-Konzept setzt sich aus spezifischen Bausteinen zusammen, die in Abb. 11.6 dargestellt werden.

\centerline{\includegraphics[width=1\textwidth]{img/116.png}}

Im Zentrum der Architektur steht der **OLAP-Server**. Bei diesem System handelt es sich um einen leistungsfähigen Datenbankserver, der die Daten aus Datenquellen extrahiert und in einer multidimensionalen Datenbank (OLAP-Datenbank) speichert. Bei den Datenquellen kann es sich z. B. um Data Marts handeln, die durch das Data-Warehouse-System zur Verfügung gestellt werden. Darüber hinaus können auch weitere Datenquellen angebunden werden, wie z. B. die Datenbestände operativer Anwendungen. Bei den **OLAP Frontends** handelt es sich um Werkzeuge, mit denen die Datenbestände des OLAP Servers interaktiv untersucht werden können.

Die zentralen Funktionalitäten von OLAP Frontends bestehen darin, die verfügbaren Datenbestände für eine dimensionsorientierte Analyse zu erschließen. Zu diesem Zweck werden die Erfolgsgrößen des Unternehmens so strukturiert, dass logisch unabhängige Dimensionen zur Verfügung gestellt werden, in denen der Endanwender über Konsolidierungspfade schrittweise navigieren kann. Der Ausgangspunkt eines Konsolidierungspfads ist die Dimension. Eine Dimension ist eine Menge mit mindestens zwei Elementen, nach der sich Daten eindeutig einordnen und gliedern lassen. Sie eröffnet für den Anwender eine Perspektive, nach der die Daten in der Analyse betrachtet werden. In der Praxis wird eine Vielzahl von Dimensionen benötigt, um alle relevanten Erfolgsgrößen des Unternehmens gliedern zu können. So werden typischerweise die Dimensionen Produkte, Regionen und Vertriebskanäle gebildet und hierarchisiert. Die einzelnen Dimensionen lassen sich miteinander kombinieren.

Um spezifische Sichten aus dem multidimensionalen Datenmodell abzuleiten, sind die Techniken des **Slicing** und **Dicing** anzuwenden. Diese Techniken stellen Sichten in Form von Scheiben bzw. Würfeln dar.

Die Anwendung der **Dicing-Technik** wird in Abb. 11.8 dargestellt. Der Würfel umfasst Elemente für die Dimensionen Zeit, Produkte und Regionen. Durch die Dicing-Technik wird die Extraktion von Teilwürfeln aus dem Würfelkomplex ermöglicht. Dies wird in der Abbildung für den Teilwürfel (Süd, Saft, Quartal 4) durchgeführt. Diesem Teilwürfel wird dabei mindestens eine Erfolgsgröße (z. B. Umsatz oder Deckungsbeitrag) zugeordnet.

\centerline{\includegraphics[width=1\textwidth]{img/dicing.png}}

Die **Slicing-Technik** ermittelt Scheiben, die aus dem Würfel herausgeschnitten werden. Eine Scheibe zeigt beispielsweise den Umsatz im dritten Quartal von sämtlichen Produkten in allen Regionen. Durch Rotation des Würfels zeigt eine andere Scheibe den Umsatz aller Quartale in sämtlichen Regionen des Produkts Saft. Die Anwendung der Slicing-Technik wird in Abb. 11.9 dargestellt.

\centerline{\includegraphics[width=1\textwidth]{img/slicing.png}}

Zur Erstellung solcher multidimensionaler Sichten sind die analyserelevanten Daten zuvor in geeigneter Form zu speichern. In relationalen Datenbankmanagementsystemen wird hierzu das **Sternschema (Star Schema)** eingesetzt. Im Sternschema werden **Faktentabellen** angelegt, welche die relevanten quantitativen Datenwerte (**Fakten**) enthalten, sowie **Dimensionstabellen**, in denen die Elemente einer Dimension mit den zugehörigen Attributen und hierarchischen Zuordnungen gespeichert sind. Die Abb. 11.11 zeigt ein exemplarisches Sternschema für den Handelsbereich zur multidimensionalen Repräsentation von Verkäufen.

\centerline{\includegraphics[width=1\textwidth]{img/star.png}}

Eine Darstellungstechnik zur multidimensionalen Modellierung ist die ADAPT-Notation (Application Design for Analytical Processing Technologies). Die beiden grundlegenden Objekttypen von ADAPT-Modellen sind der Würfel (Cube) und die Dimension. In einem Würfel wird festgehalten, welche Kennzahl abgebildet wird und durch welche Dimensionen dieser strukturiert wird. Im ADAPT-Modell in Abb. 11.12 wird der Würfel Umsatz durch die Dimensionen Zeit, Artikel und Kunde näher bestimmt.

\centerline{\includegraphics[width=1\textwidth]{img/1112.png}}

Eine Stärke der ADAPT-Notation besteht darin, differenzierte Beschreibungsmittel zur Modellierung der einzelnen Dimensionen und deren Konsolidierungspfade bereitzustellen, welche die Grundlage für Drill-Down- und Roll-Up-Operationen sind. Als Beispiel hierfür wird zunächst die Dimension Zeit aus dem oben stehenden Modellbeispiel in Abb. 11.13 detailliert aufgegliedert.

\centerline{\includegraphics[width=1\textwidth]{img/1113.png}}

Neben der Modellierung von Hierarchien gestattet ADAPT die Beschreibung einzelner Elemente durch Attribute und Kategorisierung. Diese beiden Möglichkeiten werden in Abb. 11.14 anhand der beiden Dimensionen Artikel und Kunde des Umsatzwürfels verdeutlicht.

\centerline{\includegraphics[width=1\textwidth]{img/1114.png}}

#### Mobile Business Intelligence

Im Mittelpunkt der Mobile BI steht die Unterstützung mobiler Entscheidungsprozesse, bei denen der Zugriff auf dispositive Daten des Data Warehouse über mobile Endgeräte und unterschiedliche Kommunikationsnetze abgewickelt werden muss.

Mit der Gestaltung mobiler BI-Systeme entsteht die Herausforderung, bestehende BI-Lösungen an die unterschiedlichen Eigenschaften mobiler Umgebungen und Kontexte anzupassen. Hierbei sind nicht nur die teils sehr unterschiedlichen Kommunikationseigenschaften drahtloser Netze zu berücksichtigen, sondern auch die Heterogenität der Endgeräte. Die nächste Abbildung illustriert die Struktur mobiler BI-Systeme, in denen der Zugang sowohl über zellulare Mobilfunknetze (z. B. LTE, 5G) als auch Hotspots (WLAN) stattfinden kann.

\centerline{\includegraphics[width=1\textwidth]{img/1115.png}}

#### BI-Systembeispiel: Microsoft Power BI

Hier wird Microsoft Power BI vorgestellt, das insbesondere BI-Funktionalitäten für Endanwender bereitstellt. Grundgedanke ist dabei, dass der Anwender – z. B. der Entscheidungsträger oder ein Assistent – seine eigenen Analysen (z. B. Berichte, OLAP-Abfragen, Dashboards) entwickelt und ausführt, ohne dass Mitarbeiter der IT-Abteilung involviert sind. Diese Organisationsform der BI-Entwicklung wird auch als **Self Service BI (SSBI)** bezeichnet. Die entsprechenden SSBI-Werkzeuge können von der IT Organisation bereitgestellt, überwacht und betrieben werden. Hinsichtlich der Funktionalitäten von SSBI-Werkzeugen sind drei grundlegende Kategorien zu unterscheiden:

* Eine grundlegende Funktionalität von SSBI-Werkzeugen ist die Unterstützung des Zugriffs und der Navigation in bestehenden Berichten. Diese Funktionalitäten zielen auf Geschäftsanwender (Business User), die vorwiegend als Informationskonsumenten agieren und BI-Anwendungen zur Deckung ihres Informationsbedarfs nutzen.
* Außerdem unterstützten SSBI-Werkzeuge auch die Konstruktion neuer Berichte und richten sich damit an Kernanwender (Power User), die im oder unmittelbar für den Fachbereich einer Organisation arbeiten, ein tiefes Verständnis über die Geschäftsprozesse sowie die damit verbundenen Datenflüssen besitzen, und darauf aufbauend BI-Anwendungen entwickeln. Dieser Anwenderkreis nutzt SSBI-Werkzeuge vorwiegend in der Rolle des Informationsproduzenten.
* Mit der zunehmenden Verfügbarkeit und Vielfalt neuer Datenquellen steigt die Notwendigkeit, auch diese für Entscheidungszwecke zu erschließen. Hierfür bieten SSBI-Werkzeuge die Möglichkeit, neue Datenquellen zu importieren und mit bereits vorhandenen Datenbeständen des Unternehmens zu integrieren.

#### Big Data

Unter dem Sammelbegriff Big Data werden Ansätze und Techniken subsumiert, die sich mit der Speicherung, Verwaltung, Analyse und Visualisierung solcher Datenbestände beschäftigen, die aufgrund ihrer quantitativen und qualitativen Eigenschaften mit traditionellen, analytischen Informationssystemen nicht handhabbar sind.

Die charakteristischen Merkmale der skizzierten Datenkategorien des Big Data und die damit verbundenen Herausforderungen für deren Verarbeitung können mithilfe des 3V-Modells anhand der Dimensionen Volume, Velocity sowie Variety systematisiert werden:

* Die kontinuierliche Sammlung von Daten führt dazu, dass sich in Unternehmen Datenkollektionen anhäufen, die zunehmend höhere **Speichervolumina (Volume)** beanspruchen. Hierfür sind Infrastrukturen notwendig, die eine kostengünstige Speicherung gestatten und geeignete Mechanismen bereitstellen, um benötigte Daten in analysefähiger Form zur Verfügung zu stellen.
* Durch die Nutzung neuer Datengewinnungsinstrumente nimmt die **Geschwindigkeit (Velocity)** zu, mit der Daten in Unternehmen erzeugt werden. Um zeitnah auf kritische Ereignisse reagieren zu können, sind Techniken erforderlich, welche die anfallenden Daten in Echtzeit analysieren.
* Unternehmen sind zunehmend mit einer höheren **Datenvielfalt (Variety)** konfrontiert. Traditionell konzentriert sich das betriebliche Datenmanagement auf stark strukturierte Datenbestände, die sich mithilfe von RDBMS effizient verwalten und auswerten lassen. Internetbasierte Inhalte (z. B. Blogs, Diskussionsforen, Bilder, Videos) und Sensordaten besitzen jedoch nur einen geringen Strukturierungsgrad, sodass alternative Speicher- und Auswertungstechniken erforderlich werden.

Big-Data-Anwendungen müssen größere, unterschiedlich strukturierte Datenmengen schnell und wirtschaftlich verarbeiten können. Traditionelle BI-Architekturen sind hierfür jedoch nur begrenzt geeignet. Infolgedessen wurden neue Konzepte und Techniken entwickelt, die diesen Anforderungen gerecht werden können. Wesentliche Komponenten eines Big-Data-Systems zeigt die nächste Abbildung.

\centerline{\includegraphics[width=1\textwidth]{img/1119.png}}

Den Kern des dargestellten Architekturmodells bildet ein **Datenspeicher (Data Store)**, der unterschiedliche Datenkategorien speichert. Big-Data-Lösungen basieren schwerpunktmäßig auf **NoSQL (Not Only SQL)**-Datenbanken, die zumeist eine verteilte Datenhaltung unstrukturierter Daten ermöglichen. Durch Verzicht auf eine tabellenorientierte Datenorganisation, wie sie für RDBMS typisch ist, erzielen NoSQL-Datenbanken in Big-Data-Anwendungen eine tendenziell höhere Leistungsfähigkeit und Skalierbarkeit.

Zur Speicherung web-basierter Inhalte (z. B. in Form von HTML- oder XMLDokumenten) werden Dokumentendatenbanken (Document Stores) genutzt, in denen Dokumente beliebiger Länge in Form von Objekten abgelegt werden. Eine einfache und performante Speichertechnik bieten Schlüssel/Werte-Speicher (Key/Value Stores) an. Diese ordnen einem bestimmten Schlüssel (Key) einen Wert zu, der beliebige Datentypen (z. B. Zeichenfolgen, Messdaten, Bilder) besitzen kann. In-Memory-Datenbanken (IMDB) halten die Daten im Arbeitsspeicher und stellen auf diese Weise eine hohe Performanz sicher.

Zur Bewirtschaftung dieser Datenspeicher verfügen Big-Data-Systeme über Komponenten zur **Datenaufnahme (Big Data Ingestion)**. Ähnlich wie ETL-Systeme übernehmen diese Aufgaben zur Extraktion, Transformation und Laden von Daten in den Zieldatenspeicher. Im Unterschied zu traditionellen Data-Warehouse-Systemen müssen diese Komponenten in der Lage sein, unterschiedlich strukturierte Daten mit hoher Geschwindigkeit zu verarbeiten.

Die *Analyseschicht* von Big-Data-Systemen umfasst Komponenten zur Auswertung der Datenbestände. Im Gegensatz zu traditionellen Data-Warehouse-Systemen steht dabei nicht die Erstellung vordefinierter Berichte oder OLAP-Datenbestände mit ex ante definierten Kennzahlen im Mittelpunkt, sondern die explorative Datenanalyse, die häufig ad hoc erfolgt. Analytische Komponenten sind aufgrund der hohen Datenvolumina so ausgelegt, dass eine parallele Verarbeitung der Analyseoperationen auf mehreren Rechnersystemen stattfinden kann.

Zur Erkundung von Datenbeständen werden Instrumente für die **Datenvisualisierung** eingesetzt, die mithilfe von Techniken der grafischen Datenverarbeitung die Präsentation großvolumiger und hochdimensionaler Datenräume gestatten. Im Unterschied zum klassischen Berichtswesen, in dem die visualisierten Sachverhalte durch das Informationsdesign fixiert sind, zeichnen sich Visual-Analytics-Anwendungen dadurch aus, dass die Nutzer die Daten frei und interaktiv explorieren können.

Darüber hinaus verfügen Big-Data-Architekturen über Komponenten, die mithilfe statistisch- mathematischer Methoden Muster in Datenbeständen entdecken können (**Big Data Mining**). Diese Werkzeuge bieten Verfahren an, die der Segmentierung (Clustering), Klassifikation und Regression dienen, und meist nur stark strukturierte, quantitative Daten verarbeiten (s. Kapitel 2 Arten von IS).

Zur Erschließung von Textdokumenten, deren Inhalte nur relativ schwach ausgeprägte Beziehungen zueinander aufweisen, sind hingegen linguistische Ansätze für die **Textanalyse (Text Analytics)** erforderlich. Als grundlegende Aufgabenstellungen bei der Textanalyse sind die folgenden zu nennen:

* Mithilfe der **Textklassifikation** können einzelne Dokumente bestimmten Klassen zugeordnet werden. Ein Anwendungsfeld in Unternehmen ist beispielsweise die Zuordnung von eingehenden E-Mails zu vordefinierten Klassen (z. B. Bestellung, Beschwerde, Stornierung). Zur Textklassifikation stehen Verfahren des maschinellen Lernens zur Verfügung, die mithilfe einer Trainingsmenge von Dokumenten (z. B. historische E-Mails mit bekannter Klassenzugehörigkeit) angelernt werden.
* Bei der **Textsegmentierung (Clustering)** werden Dokumentkollektionen in Klassen eingeteilt, wobei die Klassen aus den Merkmalen der Dokumente selbst abgeleitet werden und nicht durch den Anwender vorgegeben werden. Auf diese Weise können beispielsweise interessante Subgruppen in bestehenden Dokumentkollektionen aufgedeckt werden, die über ähnliche Inhalte verfügen. Ein exemplarisches Anwendungsfeld der Textsegmentierung ist die Analyse von Störungsmeldungen (Incidents) in einem IT-Servicecenter. Durch Clustering können beispielsweise Störungsmeldungen mit gleichen Inhalten (z. B. mit den Substantiven Login, Anmeldung, Passwort) automatisch erkannt werden.
* Mithilfe der **Sentimentanalyse (Stimmungsanalyse, Sentiment Detection)** werden Texte im Hinblick auf die positive, neutrale oder negative Einstellung des Autoren gegenüber bestimmten Bewertungsobjekten (z. B. Produkte, Dienstleistungen) untersucht. Ein etabliertes Anwendungsfeld der Sentimentanalyse bildet die Untersuchung, ob der Kursverlauf einer Aktie mit der veröffentlichten Meinung (z. B. Twitter) korreliert.

Unter einem **Datenstrom** ist dabei eine in der Länge meist unbeschränkte Sequenz von Datenelementen zu verstehen, die in Echtzeit verarbeitet werden muss. Solche Datenströme können z. B. Einzelhandels- und Finanzmarkttransaktionen, Ereignisse in Telekommunikationsnetzen oder Messdaten aus Sensornetzwerken abbilden. Zur Analyse solcher „fließender Daten“ dienen Instrumente des **Streaming Analytics**. Diese sind in der Lage, bestimmte Ereignisse und Bedingungskonstellationen in Datenströmen fortlaufend zu erkennen und daraufhin bestimmte Aktionen durchzuführen. Im Mittelpunkt der Entwicklung solcher Analysesysteme steht die Formulierung entsprechender Reaktionen, die bei Erkennung kritischer Ereignisse auszulösen sind, wie etwa die gezielte Steuerung operativer Geschäftsprozesse.

Unter einem **Data Lake** ist ein zentralisierter Datenspeicher zu verstehen, der Datenbestände aus unterschiedlichen Quellen zusammenführt und für analytische Operationen zur Verfügung stellt.

\centerline{\includegraphics[width=1\textwidth]{img/1121.png}}

Der Aufbau eines Data Lake wird in Abb. 11.21 dargestellt. Aus der Abbildung wird deutlich, dass ein Data Lake mit der IT-Landschaft des Unternehmens sowie anderen Data Lakes verknüpft ist. Auf diese Weise können nicht nur die Daten aus operativen Anwendungen (z. B. ERP- und E-Business-Systemen) extrahiert und im Data Lake vorgehalten werden, sondern etwa auch öffentliche Daten (Open Data) integriert und zur Anreicherung genutzt werden. Die Verwaltung der vorgehaltenen Daten übernehmen Informationskuratoren, zu deren Aufgaben auch die Pflege des Datenkatalogs gehört. Das Governance & Compliance Team hat demgegenüber dafür zu sorgen, dass die unternehmensinternen Richtlinien und Regularien für das Datenmanagement auch im Umfeld des Data Lake eingehalten werden. Nach diesen Vorgaben erfolgt auch der Betrieb des Data Lakes als Teil der betrieblichen IT-Infrastruktur. Die Nutzung der bereitgestellten Daten erfolgt einerseits durch die analytischen Anwendungen der Fachabteilungen auf Basis von Self-Service-Schnittstellen. Andererseits nutzen Data Scientists und Big-Data-Analysten das Repositorium zur Konstruktion und Anwendung von Entscheidungsmodellen.

#### Big-Data-Systembeispiel: SAP HANA

Um die unterschiedlichen Anforderungskriterien bei der analytischen und operativen Datenverarbeitung zu erfüllen, werden verstärkt hybride Datenbankarchitekturen eingesetzt, in denen diverse Technologien miteinander kombiniert werden (Färber et al. 2010, S. 81). Als Produktbeispiel für einen solchen hybriden Ansatz wird hier **SAP HANA (High Performance Analytic Appliance)** vorgestellt, das von der SAP SE als Technologie- und Entwicklungsplattform für die operative und dispositive Datenverarbeitung positioniert wird. Die grundlegende Architektur von SAP HANA zeigt Abb. 11.22.

\centerline{\includegraphics[width=1\textwidth]{img/1122.png}}

Zentrale Grundlage von SAP HANA als Big-Data-System bildet die technische Fähigkeit, Daten aus unterschiedlichen Quellsystemen (**Source**) mit verschiedenen Datentypen speichern und verarbeiten zu können. Diese Daten werden in der Speicherschicht (**Store**) des SAP HANA-Systems verfügbar gemacht, wobei unterschiedliche Speichertechnologien zum Einsatz gelangen können.

Zur Analyse von Daten (**Compute**) stellt SAP HANA unterschiedliche Komponenten zur Verfügung:

* **Stream Processing** dient der analytischen Verarbeitung von Datenströmen. Zu diesem Zweck können kontinuierliche Abfragen definiert werden, die dauerhaft auf die eingehenden Datenströme angewendet werden und beispielsweise zur Detektion kritischer Ereignisfolgen dienen.
* Die Komponente **Analytics Engine** wird eingesetzt, um multidimensionale Auswertungsrechnungen (Abschn. 11.2.3) zu erstellen.
* Die **Predictive Engine** stellt Verfahren des maschinellen Lernens und der multivariaten Datenanalyse zur Verfügung (z. B. für die Zeitreihenanalyse, Klassifikation und Segmentierung).
* Zur Analyse von Textdaten bietet die **Text Engine** entsprechende Verfahren an, die ein breites Spektrum unterschiedlicher Aufgabenstellungen unterstützen.
* Die Komponente **Spatial Processing** enthält Funktionalitäten zur Verarbeitung raumbezogener Daten (Spatial Data). Hiermit kann etwa eine Geokodierung von Adressdaten durchgeführt werden oder aber raumbezogene Relationen (z. B. Distanzen, Nachbarschaften) zwischen Objekten aufgedeckt werden.

### Anwendungsbeispiele für aufgabenorientierte EUS

#### Integrierte Erfolgs-, Finanz- und Bilanzplanung

Die Planung von erfolgs- und finanzwirtschaftlichen Zielen gehört zu den traditionellen Aufgaben des Controllings. Häufig fehlt eine sachliche Abstimmung zwischen Bilanz-, Erfolgs- und Finanzrechnung. Außerdem ist die Unternehmensplanung regelmäßig durch Brüche zwischen der kurz-, mittel- und langfristigen Planung gekennzeichnet. Zur Handhabung dieser Problematik bietet sich die Anwendung eines integrierten EUS zur Ergebnis- und Finanzplanung und -kontrolle an. Die integrierte Planung umfasst die zielgerichtete Abstimmung in sachlicher, zeitlicher und organisatorischer Hinsicht (s. Abb. 11.24).

\centerline{\includegraphics[width=1\textwidth]{img/1124.png}}

Die strategische Planung hat die gegenwärtige und zukünftige Entwicklungsfähigkeit des Unternehmens zum Inhalt. Der Aufbau strategischer Erfolgspotenziale erfolgt durch die Entwicklung und Realisierung von Gesamtunternehmens- und Geschäftsbereichsstrategien. Im Rahmen der operativen Planung werden die angestrebten Erfolgspotenziale konkretisiert und in quantitative Erfolgsgrößen umgesetzt. Ein zentrales Instrument hierfür stellt die Budgetierung dar. Dabei werden Funktions- oder Geschäftsbereichsbudgets ermittelt und als Vorgaben für die Budgetperiode verwendet. Die anschließende Budgetkontrolle dient der Überwachung der Zielgrößen, um bei Bedarf Anpassungsmaßnahmen und ggf. Budgetkorrekturen einzuleiten.

#### Unternehmensplanung

Anders als bei der starren Planung, bei der der Planende bereits zum Planungszeitpunkt festlegt, wie er sich in den zukünftigen Perioden verhalten will, werden bei der Flexiblen Planung optimale bedingte Pläne für zukünftige Datensituationen festgelegt. Diese mehrstufigen Entscheidungsprobleme unter Unsicherheit können durch Verwendung von Entscheidungsbäumen visualisiert werden. Dabei werden zunächst alle künftig denkbaren Umweltzustände mit ihren Eintrittswahrscheinlichkeiten dargestellt. Danach werden die Wahrscheinlichkeiten mit den Entscheidungskonsequenzen verknüpft und zu Zielwerten (z. B. zum Erwartungswert des Gewinns) verdichtet. Durch die Bewertung der einzelnen Äste des Baums soll eine Aussage über die zu treffenden Entscheidungen gewonnen und so die Unternehmensplanung beim Treffen der richtigen Entscheidung unterstützt werden.

#### Investitionscontrolling mit Simulationswerkzeugen

Investitionsentscheidungen stellen Entscheidungen unter Unsicherheit dar. Zur Handhabung der damit verbundenen Problematik wird in der Investitionsrechnung die Risiko-Chancen-Analyse empfohlen. Bei der Risiko-Chancen-Analyse werden Einflussgrößen (z. B. Absatzmengen) zur Bewertung von Investitionsalternativen anhand von Pseudozufallszahlen unter Verwendung der Monte-Carlo-Simulation quantifiziert. Die simulierten Einflussgrößen werden zu Zielgrößen, wie beispielsweise dem Endwert einer Investitionsalternative, verdichtet und in Risiko-Chancen-Profilen dargestellt. An einem Risiko-Chancen-Profil kann die Wahrscheinlichkeit abgelesen werden, mit der ein Zielwert unter Zugrundelegung der Eingabedaten *mindestens* erreicht wird. Risiko-Chancen-Profile ermöglichen dem Entscheidungsträger den Vergleich unterschiedlicher Alternativen unter expliziter Berücksichtigung der Unsicherheit.

## Kapitel 12: Anwendungen zur Vernetzung mit Kunden und Lieferanten
### Überblick
### Überbetriebliche Anwendungen
### Nutzen vernetzter Anwendungen
